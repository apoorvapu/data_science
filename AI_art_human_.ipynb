{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorvapu/data_science/blob/main/AI_art_human_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TyXQxrav9xDZ"
      },
      "outputs": [],
      "source": [
        "#!rm *.csv\n",
        "#!rm *.png\n",
        "#!rm -r data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhB3-9VU9xDd",
        "outputId": "833667b3-3878-4de2-c893-c9f9693654cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset URL: https://www.kaggle.com/datasets/kausthubkannan/ai-and-human-art-classification\n",
            "License(s): DbCL-1.0\n",
            "Downloading ai-and-human-art-classification.zip to ./data/art_dataset\n",
            " 97% 2.14G/2.21G [00:23<00:01, 38.5MB/s]\n",
            "100% 2.21G/2.21G [00:23<00:00, 101MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cd2e393d230>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install lightgbm scikit-learn opencv-python matplotlib seaborn kaggle scipy umap-learn -q\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "KAGGLE_JSON = \"/content/drive/MyDrive/kaggle.json\"\n",
        "import os\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "!cp \"{KAGGLE_JSON}\" /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!mkdir -p ./data/art_dataset\n",
        "!kaggle datasets download -d kausthubkannan/ai-and-human-art-classification -p ./data/art_dataset\n",
        "!unzip -q -n ./data/art_dataset/ai-and-human-art-classification.zip -d ./data/art_dataset/\n",
        "\n",
        "# ==================== IMPORTS ====================\n",
        "import pathlib, random, time, gc, copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                            roc_curve, precision_recall_fscore_support, accuracy_score,\n",
        "                            precision_recall_curve, average_precision_score)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "plt.rcParams['font.size'] = 9\n",
        "sns.set_palette(\"colorblind\")\n",
        "\n",
        "SEED = 2509\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj5JKDen9xDf",
        "outputId": "007b2f30-6085-4c0d-9a85-68e7c4072237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñ•Ô∏è  Device: cuda\n",
            "\n",
            "‚è±Ô∏è  Data Loading...\n",
            "üìä Dataset: 18288 total | Train: 12801 | Val: 2743 | Test: 2744\n",
            "‚úÖ Data Loading: 0.21s (0.00min)\n",
            "‚úÖ Data Loading: 0.21s (0.00min)\n"
          ]
        }
      ],
      "source": [
        "# ==================== CONFIGURATION ====================\n",
        "DATASET_LIMIT = 10000  # Per class - sufficient for publication\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 0\n",
        "NUM_EPOCHS = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# ==================== TIMING SYSTEM ====================\n",
        "class Timer:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.start = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start = time.time()\n",
        "        print(f\"\\n‚è±Ô∏è  {self.name}...\")\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        elapsed = time.time() - self.start\n",
        "        print(f\"‚úÖ {self.name}: {elapsed:.2f}s ({elapsed/60:.2f}min)\")\n",
        "        return elapsed\n",
        "\n",
        "timings = {}\n",
        "\n",
        "# ==================== DATA LOADING ====================\n",
        "with Timer(\"Data Loading\") as t:\n",
        "    DATA_ROOT = pathlib.Path(\"./data/art_dataset/ai_art_classification/train\")\n",
        "    HUMAN_PATH = DATA_ROOT / \"NON_AI_GENERATED\"\n",
        "    AI_PATH = DATA_ROOT / \"AI_GENERATED\"\n",
        "\n",
        "    from itertools import islice\n",
        "    human_files = list(islice(HUMAN_PATH.glob(\"*.jpg\"), DATASET_LIMIT))\n",
        "    ai_files = list(islice(AI_PATH.glob(\"*.jpg\"), DATASET_LIMIT))\n",
        "    all_files = human_files + ai_files\n",
        "    labels = [0]*len(human_files) + [1]*len(ai_files)\n",
        "\n",
        "    train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
        "        all_files, labels, test_size=0.3, stratify=labels, random_state=SEED\n",
        "    )\n",
        "    val_files, test_files, val_labels, test_labels = train_test_split(\n",
        "        temp_files, temp_labels, test_size=0.5, stratify=temp_labels, random_state=SEED\n",
        "    )\n",
        "\n",
        "    print(f\"üìä Dataset: {len(all_files)} total | Train: {len(train_files)} | Val: {len(val_files)} | Test: {len(test_files)}\")\n",
        "\n",
        "timings['data_loading'] = t.__exit__()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==================== HANDCRAFTED FEATURES ====================\n",
        "def extract_features(img_path):\n",
        "    try:\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            return None\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "\n",
        "        features = []\n",
        "\n",
        "        # Color stats (15 features)\n",
        "        for ch in range(3):\n",
        "            c = img[:,:,ch]\n",
        "            features.extend([c.mean(), c.std(), np.median(c),\n",
        "                           stats.skew(c.flatten()), stats.kurtosis(c.flatten())])\n",
        "\n",
        "        # Texture (3 features)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        entropy = -np.sum(hist * np.log2(hist + 1e-7))\n",
        "        features.extend([entropy, gray.std(), cv2.Laplacian(gray, cv2.CV_64F).var()])\n",
        "\n",
        "        # NOVEL: Frequency domain (3 features)\n",
        "        dct = cv2.dct(np.float32(gray))\n",
        "        h, w = dct.shape\n",
        "        high_freq = np.abs(dct[h//2:, w//2:]).sum() / (h * w)\n",
        "        low_freq = np.abs(dct[:h//2, :w//2]).sum() / (h * w)\n",
        "        freq_ratio = high_freq / (low_freq + 1e-7)\n",
        "        features.extend([high_freq, low_freq, freq_ratio])\n",
        "\n",
        "        # Edges (2 features)\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        features.extend([edges.mean(), edges.sum() / (h * w)])\n",
        "\n",
        "        return np.array(features, dtype=np.float32)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "feature_names = [\n",
        "    'R_mean', 'R_std', 'R_med', 'R_skew', 'R_kurt',\n",
        "    'G_mean', 'G_std', 'G_med', 'G_skew', 'G_kurt',\n",
        "    'B_mean', 'B_std', 'B_med', 'B_skew', 'B_kurt',\n",
        "    'Entropy', 'Contrast', 'Laplacian',\n",
        "    'High_freq', 'Low_freq', 'Freq_ratio', 'Edge_density', 'Edge_smooth'\n",
        "]\n",
        "\n",
        "with Timer(\"Handcrafted Feature Extraction\") as t:\n",
        "    def extract_batch(files):\n",
        "        return np.array([f for f in [extract_features(fp) for fp in tqdm(files, leave=False, desc=\"Extracting\")] if f is not None])\n",
        "\n",
        "    X_train_hand = extract_batch(train_files)\n",
        "    X_val_hand = extract_batch(val_files)\n",
        "    X_test_hand = extract_batch(test_files)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_hand = scaler.fit_transform(X_train_hand)\n",
        "    X_val_hand = scaler.transform(X_val_hand)\n",
        "    X_test_hand = scaler.transform(X_test_hand)\n",
        "\n",
        "    print(f\"üìê Handcrafted features: {X_train_hand.shape}\")\n",
        "    gc.collect()\n",
        "\n",
        "timings['handcrafted_extraction'] = t.__exit__()\n",
        "\n",
        "# ==================== CNN FEATURES ====================\n",
        "with Timer(\"CNN Feature Extraction\") as t:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    feature_net = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "    feature_net.classifier = nn.Identity()\n",
        "    feature_net.eval().to(device)\n",
        "\n",
        "    def extract_cnn_batch(files, batch_size=16):\n",
        "        all_feats = []\n",
        "        with torch.no_grad():\n",
        "            for i in tqdm(range(0, len(files), batch_size), leave=False, desc=\"CNN features\"):\n",
        "                batch = files[i:i+batch_size]\n",
        "                tensors = []\n",
        "                for f in batch:\n",
        "                    try:\n",
        "                        tensors.append(transform(Image.open(f).convert(\"RGB\")))\n",
        "                    except:\n",
        "                        continue\n",
        "                if tensors:\n",
        "                    batch_t = torch.stack(tensors).to(device)\n",
        "                    all_feats.append(feature_net(batch_t).cpu().numpy())\n",
        "                    del batch_t\n",
        "                if i % 100 == 0:\n",
        "                    torch.cuda.empty_cache()\n",
        "        return np.vstack(all_feats).astype(np.float32)\n",
        "\n",
        "    X_train_cnn = extract_cnn_batch(train_files)\n",
        "    X_val_cnn = extract_cnn_batch(val_files)\n",
        "    X_test_cnn = extract_cnn_batch(test_files)\n",
        "\n",
        "    del feature_net\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"üß† CNN features: {X_train_cnn.shape}\")\n",
        "\n",
        "timings['cnn_extraction'] = t.__exit__()\n",
        "\n",
        "# ==================== METHOD 1: HANDCRAFTED + RF ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 1: Handcrafted Features + Random Forest\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "with Timer(\"Method 1 Training\") as t:\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)\n",
        "    rf_model.fit(X_train_hand, train_labels)\n",
        "\n",
        "timings['method1_train'] = t.__exit__()\n",
        "\n",
        "with Timer(\"Method 1 Inference\") as t:\n",
        "    pred_rf = rf_model.predict(X_test_hand)\n",
        "    prob_rf = rf_model.predict_proba(X_test_hand)[:, 1]\n",
        "\n",
        "timings['method1_inference'] = t.__exit__()\n",
        "\n",
        "p, r, f1_rf, _ = precision_recall_fscore_support(test_labels, pred_rf, average='binary')\n",
        "acc_rf = accuracy_score(test_labels, pred_rf)\n",
        "roc_rf = roc_auc_score(test_labels, prob_rf)\n",
        "print(f\"üìä F1={f1_rf:.4f} | Acc={acc_rf:.4f} | ROC-AUC={roc_rf:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nüîç Top 10 Most Important Features:\")\n",
        "print(feature_importance.head(10).to_string(index=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_5aVUQhEo32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== METHOD 1B: MOBILENETV2 FINE-TUNED (FAIR BASELINE) ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 1B: MobileNetV2 Fine-tuned (Fair Comparison Baseline)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create dataset and dataloader for MobileNetV2 (same as Method 3 but for MobileNetV2)\n",
        "transform_train_mobilenet = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test_mobilenet = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_ds_mobilenet = ImageDataset(train_files, train_labels, transform_train_mobilenet)\n",
        "val_ds_mobilenet = ImageDataset(val_files, val_labels, transform_test_mobilenet)\n",
        "test_ds_mobilenet = ImageDataset(test_files, test_labels, transform_test_mobilenet)\n",
        "\n",
        "train_loader_mobilenet = DataLoader(train_ds_mobilenet, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader_mobilenet = DataLoader(val_ds_mobilenet, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader_mobilenet = DataLoader(test_ds_mobilenet, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "mobilenet_finetuned = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "mobilenet_finetuned.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(mobilenet_finetuned.last_channel, 2)\n",
        ")\n",
        "mobilenet_finetuned = mobilenet_finetuned.to(device)\n",
        "\n",
        "optimizer_mobilenet = torch.optim.AdamW(mobilenet_finetuned.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "with Timer(\"Method 1B Training\") as t:\n",
        "    best_f1 = 0\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        mobilenet_finetuned.train()\n",
        "        for imgs, labels in tqdm(train_loader_mobilenet, desc=f\"Epoch {epoch}\", leave=False):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer_mobilenet.zero_grad()\n",
        "            out = mobilenet_finetuned(imgs)\n",
        "            loss = F.cross_entropy(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer_mobilenet.step()\n",
        "\n",
        "        mobilenet_finetuned.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader_mobilenet:\n",
        "                imgs = imgs.to(device)\n",
        "                preds.append(mobilenet_finetuned(imgs).argmax(1).cpu().numpy())\n",
        "                targets.append(labels.numpy())\n",
        "        preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "        f1 = precision_recall_fscore_support(targets, preds, average='binary')[2]\n",
        "        print(f\"  Epoch {epoch}: Val F1={f1:.4f}\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state_mobilenet = copy.deepcopy(mobilenet_finetuned.state_dict())\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    mobilenet_finetuned.load_state_dict(best_state_mobilenet)\n",
        "    timings['method1b_train'] = t.__exit__()\n",
        "\n",
        "with Timer(\"Method 1B Inference\") as t:\n",
        "    mobilenet_finetuned.eval()\n",
        "    pred_mobilenet_ft, prob_mobilenet_ft = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader_mobilenet:\n",
        "            imgs = imgs.to(device)\n",
        "            out = mobilenet_finetuned(imgs)\n",
        "            prob_mobilenet_ft.append(F.softmax(out, dim=1)[:, 1].cpu().numpy())\n",
        "            pred_mobilenet_ft.append(out.argmax(1).cpu().numpy())\n",
        "\n",
        "    pred_mobilenet_ft = np.concatenate(pred_mobilenet_ft)\n",
        "    prob_mobilenet_ft = np.concatenate(prob_mobilenet_ft)\n",
        "    timings['method1b_inference'] = t.__exit__()\n",
        "\n",
        "p, r, f1_mobilenet_ft, _ = precision_recall_fscore_support(test_labels, pred_mobilenet_ft, average='binary')\n",
        "acc_mobilenet_ft = accuracy_score(test_labels, pred_mobilenet_ft)\n",
        "roc_mobilenet_ft = roc_auc_score(test_labels, prob_mobilenet_ft)\n",
        "print(f\"üìä F1={f1_mobilenet_ft:.4f} | Acc={acc_mobilenet_ft:.4f} | ROC-AUC={roc_mobilenet_ft:.4f}\")\n",
        "\n",
        "del mobilenet_finetuned\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "1ifXKf7_FChO",
        "outputId": "d50e7b0b-d9e1-47b9-f2cc-15245dc1dcfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "METHOD 1B: MobileNetV2 Fine-tuned (Fair Comparison Baseline)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ImageDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1909791669.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m ])\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain_ds_mobilenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_train_mobilenet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mval_ds_mobilenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_test_mobilenet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtest_ds_mobilenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_test_mobilenet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "757c6d647ead49df917daaca10ad646a",
            "edfa8db32b79495e967721b837f40f51",
            "7f1a6185e31f474cb4b710b33a1a3a92",
            "75a768e3ad9146eabb04da5b2183ce75",
            "aa3c26a15cb5424fad219a3c426719d8",
            "bd2bf467f79246348b60a06f36d52b8a",
            "04146ddb888b462aa7aa37ebb5897da2",
            "c4c2b5c1557c4cb289c4ca5eee98a523",
            "b132f22787aa462ba4bbe674fcf95cd1",
            "a8cf584339884d02833d6f77e3885e68",
            "d8c6c0fbc8654be3868b14ebe54d6e1d",
            "1283ecd6276e4bbc9753d80ce02658ef",
            "38ed123c58024264a211a9d1c79d3b5a",
            "d00afb7722e64785a455029afadb9d15",
            "450d512bca5a40d2bb7e467d4128c6d9",
            "a1ac874fbfc74bd190706dc61f681da0",
            "5ecfb5672232469ba70dc4611962e815",
            "f396ea2fa30745f7930efca5c5a954a2",
            "c56d74352f5d41068c60ddfb7442c189",
            "39a01b7f66f14ad09bc2090438c65be4",
            "698c35c262374596827e58136758b6dd",
            "71183fd4eb4f418e956ac04738302241",
            "68952de3c0254b1a9967ac4ee1c6f138",
            "3cf22c8e581641a68b65d65bcd99b0d9",
            "6299be7194474c33bf2690ca911d34f2",
            "3df8bd136af144af81e8ccb0807f7e18",
            "08a0e787a0f9457c9a73f8cffe21d335",
            "38cc8a60a00c40939e1f816e7e9c3344",
            "b6fe623e1f3246d79e19bcb4a6fb5185",
            "7e873f03416448d98277a4fd00832053",
            "bc7e89682e0b4047b420db18727fe0ef",
            "f520b5c58f8942cdb34839de247a48ab",
            "762ce4a317b44501b1e07c1df25b1332",
            "bbb805da57404e0c8030d08c51c5d004",
            "d3dec54687904123a3976970b8120b95",
            "4e5a53f96fa54832bed32e62f0fffeec",
            "777f4e83c6624c119afa2cce85b4e69b",
            "b012ab92b58f424b87d80f2922bd1b3d",
            "5290515b2a684ddfa34910d94969d9e7",
            "3a9a508ff1f6411385772de5f870c88b",
            "cd7232a239eb42729fd3d44dad372afe",
            "54de28d25d5642a397d354389e28cb0b",
            "ea78c87e65d9444980c31234d80d4666",
            "51ed5a2cc30b4e0bb6d6b2072d3583ba",
            "a0fd583284cd4ad9abc948ec3c305914",
            "f19e61a4ffbc40b1ba1ad984c895ccfa",
            "fb5e4e8785fb485dad53d5109bb2ae75",
            "71cd42b76f8c4f3392491229fcf9255f",
            "d047b2a702964bf7ab58cde5b8e0ed7d",
            "1392b1b0d025460fb6e258451109cc7b",
            "039da1af6cb34bd3ae8bc0405a32f410",
            "c55b239b200a46f29f8f1abe304fec6f",
            "ec1de6c9514d45f39661655dcafe6dc3",
            "1d1590b664df4479bcb11e7892e23f02",
            "aa3e7e3887e64971ba544caa61af269e",
            "0993baf42f934e7cb2e3c41f6d454ab2",
            "6d142c411b0c4890874d9861a3b6588c",
            "a457a4bf5cf7442590616f59079fe848",
            "cc2a866b2a5e4ce8a4ba904916539a82",
            "fada76e1257e4df79f519af196afadaf",
            "b1175f26ea04441aa367e88e4ef11b2f",
            "49e0b19bb1ec48fd9c729b6d31ba0f87",
            "9a49b8a01aa8473aa67dc1b3a4c562d5",
            "08d6d564008e492ba1c348c466bbe526",
            "cfea11bb5170491591febe28a9a22b02",
            "45dcd0f2eca54db684edfc9efc1ae949"
          ]
        },
        "id": "MQMnLxne9xDj",
        "outputId": "637d46a2-7fd1-4d21-a4a6-3ccacd1cde7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è±Ô∏è  Handcrafted Feature Extraction...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting:   0%|          | 0/12801 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "757c6d647ead49df917daaca10ad646a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting:   0%|          | 0/2743 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1283ecd6276e4bbc9753d80ce02658ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting:   0%|          | 0/2744 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68952de3c0254b1a9967ac4ee1c6f138"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìê Handcrafted features: (12801, 23)\n",
            "‚úÖ Handcrafted Feature Extraction: 190.09s (3.17min)\n",
            "‚úÖ Handcrafted Feature Extraction: 190.09s (3.17min)\n",
            "\n",
            "‚è±Ô∏è  CNN Feature Extraction...\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.6M/13.6M [00:00<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CNN features:   0%|          | 0/801 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbb805da57404e0c8030d08c51c5d004"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CNN features:   0%|          | 0/172 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0fd583284cd4ad9abc948ec3c305914"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CNN features:   0%|          | 0/172 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0993baf42f934e7cb2e3c41f6d454ab2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† CNN features: (12801, 1280)\n",
            "‚úÖ CNN Feature Extraction: 83.00s (1.38min)\n",
            "‚úÖ CNN Feature Extraction: 83.00s (1.38min)\n",
            "\n",
            "======================================================================\n",
            "METHOD 1: Handcrafted Features + Random Forest\n",
            "======================================================================\n",
            "\n",
            "‚è±Ô∏è  Method 1 Training...\n",
            "‚úÖ Method 1 Training: 6.28s (0.10min)\n",
            "‚úÖ Method 1 Training: 6.29s (0.10min)\n",
            "\n",
            "‚è±Ô∏è  Method 1 Inference...\n",
            "‚úÖ Method 1 Inference: 0.16s (0.00min)\n",
            "‚úÖ Method 1 Inference: 0.16s (0.00min)\n",
            "üìä F1=0.8061 | Acc=0.7868 | ROC-AUC=0.8681\n",
            "\n",
            "üîç Top 10 Most Important Features:\n",
            "     Feature  Importance\n",
            "Edge_density    0.065922\n",
            "    Low_freq    0.065648\n",
            "       G_std    0.065083\n",
            " Edge_smooth    0.061262\n",
            "      R_mean    0.055391\n",
            "       B_std    0.054725\n",
            "      G_mean    0.053091\n",
            "    Contrast    0.051330\n",
            "       R_std    0.049719\n",
            "     Entropy    0.048103\n",
            "\n",
            "======================================================================\n",
            "METHOD 1B: MobileNetV2 Fine-tuned (Fair Comparison Baseline)\n",
            "======================================================================\n",
            "\n",
            "‚è±Ô∏è  Method 1B Training...\n",
            "‚úÖ Method 1B Training: 0.00s (0.00min)\n",
            "\n",
            "‚è±Ô∏è  Method 1B Inference...\n",
            "‚úÖ Method 1B Inference: 0.00s (0.00min)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [2744, 0]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3319628184.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mtimings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'method1b_inference'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_mobilenet_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_mobilenet_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0macc_mobilenet_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_mobilenet_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0mroc_mobilenet_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_mobilenet_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1828\u001b[0m     \"\"\"\n\u001b[1;32m   1829\u001b[0m     \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2744, 0]"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==================== METHOD 2: ATTENTION FUSION ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 2: Attention Fusion (NOVEL)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class AttentionFusion(nn.Module):\n",
        "    def __init__(self, hand_dim, cnn_dim, hidden=64):\n",
        "        super().__init__()\n",
        "        self.hand_proj = nn.Linear(hand_dim, hidden)\n",
        "        self.cnn_proj = nn.Linear(cnn_dim, hidden)\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden * 2, hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden, 2),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, hand, cnn, return_hidden=False):\n",
        "        h = F.relu(self.hand_proj(hand))\n",
        "        c = F.relu(self.cnn_proj(cnn))\n",
        "        attn = self.attention(torch.cat([h, c], 1))\n",
        "        fused = attn[:, 0:1] * h + attn[:, 1:2] * c\n",
        "        out = self.classifier(fused)\n",
        "        if return_hidden:\n",
        "            return out, attn, fused\n",
        "        return out, attn\n",
        "\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, hand, cnn, labels):\n",
        "        self.hand = torch.FloatTensor(hand)\n",
        "        self.cnn = torch.FloatTensor(cnn)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, i):\n",
        "        return self.hand[i], self.cnn[i], self.labels[i]\n",
        "\n",
        "train_ds = FusionDataset(X_train_hand, X_train_cnn, train_labels)\n",
        "val_ds = FusionDataset(X_val_hand, X_val_cnn, val_labels)\n",
        "test_ds = FusionDataset(X_test_hand, X_test_cnn, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
        "test_loader_fusion = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
        "\n",
        "fusion_model = AttentionFusion(X_train_hand.shape[1], X_train_cnn.shape[1]).to(device)\n",
        "optimizer = torch.optim.AdamW(fusion_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "with Timer(\"Method 2 Training\") as t:\n",
        "    best_f1 = 0\n",
        "    for epoch in range(1, 6):\n",
        "        fusion_model.train()\n",
        "        for hand, cnn, labels in train_loader:\n",
        "            hand, cnn, labels = hand.to(device), cnn.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out, _ = fusion_model(hand, cnn)\n",
        "            loss = F.cross_entropy(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        fusion_model.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for hand, cnn, labels in val_loader:\n",
        "                hand, cnn = hand.to(device), cnn.to(device)\n",
        "                out, _ = fusion_model(hand, cnn)\n",
        "                preds.append(out.argmax(1).cpu().numpy())\n",
        "                targets.append(labels.numpy())\n",
        "\n",
        "        preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "        f1 = precision_recall_fscore_support(targets, preds, average='binary')[2]\n",
        "        print(f\"  Epoch {epoch}: Val F1={f1:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state = copy.deepcopy(fusion_model.state_dict())\n",
        "\n",
        "    fusion_model.load_state_dict(best_state)\n",
        "\n",
        "timings['method2_train'] = t.__exit__()\n",
        "\n",
        "with Timer(\"Method 2 Inference\") as t:\n",
        "    fusion_model.eval()\n",
        "    pred_fusion, prob_fusion, attn_weights, fusion_features = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for hand, cnn, labels in test_loader_fusion:\n",
        "            hand, cnn = hand.to(device), cnn.to(device)\n",
        "            out, attn, fused = fusion_model(hand, cnn, return_hidden=True)\n",
        "            prob_fusion.append(F.softmax(out, dim=1)[:, 1].cpu().numpy())\n",
        "            pred_fusion.append(out.argmax(1).cpu().numpy())\n",
        "            attn_weights.append(attn.cpu().numpy())\n",
        "            fusion_features.append(fused.cpu().numpy())\n",
        "\n",
        "    pred_fusion = np.concatenate(pred_fusion)\n",
        "    prob_fusion = np.concatenate(prob_fusion)\n",
        "    attn_weights = np.concatenate(attn_weights)\n",
        "    fusion_features = np.concatenate(fusion_features)\n",
        "\n",
        "timings['method2_inference'] = t.__exit__()\n",
        "\n",
        "p, r, f1_fusion, _ = precision_recall_fscore_support(test_labels, pred_fusion, average='binary')\n",
        "acc_fusion = accuracy_score(test_labels, pred_fusion)\n",
        "roc_fusion = roc_auc_score(test_labels, prob_fusion)\n",
        "print(f\"üìä F1={f1_fusion:.4f} | Acc={acc_fusion:.4f} | ROC-AUC={roc_fusion:.4f}\")\n",
        "\n",
        "del fusion_model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ==================== METHOD 3: RESNET50 ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 3: ResNet50\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, files, labels, transform):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.files[i]).convert('RGB')\n",
        "        return self.transform(img), self.labels[i]\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_ds_img = ImageDataset(train_files, train_labels, transform_train)\n",
        "val_ds_img = ImageDataset(val_files, val_labels, transform_test)\n",
        "test_ds_img = ImageDataset(test_files, test_labels, transform_test)\n",
        "\n",
        "train_loader_img = DataLoader(train_ds_img, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader_img = DataLoader(val_ds_img, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader_resnet = DataLoader(test_ds_img, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "resnet = models.resnet50(weights='IMAGENET1K_V2')\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
        "resnet = resnet.to(device)\n",
        "optimizer_resnet = torch.optim.AdamW(resnet.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "with Timer(\"Method 3 Training\") as t:\n",
        "    best_f1 = 0\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        resnet.train()\n",
        "        for imgs, labels in tqdm(train_loader_img, desc=f\"Epoch {epoch}\", leave=False):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer_resnet.zero_grad()\n",
        "            out = resnet(imgs)\n",
        "            loss = F.cross_entropy(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer_resnet.step()\n",
        "\n",
        "        resnet.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader_img:\n",
        "                imgs = imgs.to(device)\n",
        "                preds.append(resnet(imgs).argmax(1).cpu().numpy())\n",
        "                targets.append(labels.numpy())\n",
        "\n",
        "        preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "        f1 = precision_recall_fscore_support(targets, preds, average='binary')[2]\n",
        "        print(f\"  Epoch {epoch}: Val F1={f1:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state_resnet = copy.deepcopy(resnet.state_dict())\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    resnet.load_state_dict(best_state_resnet)\n",
        "\n",
        "timings['method3_train'] = t.__exit__()\n",
        "\n",
        "# Extract ResNet features for visualization\n",
        "resnet_penultimate = nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet_penultimate.eval()\n",
        "\n",
        "with Timer(\"Method 3 Inference\") as t:\n",
        "    pred_resnet, prob_resnet, resnet_features = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader_resnet:\n",
        "            imgs = imgs.to(device)\n",
        "            out = resnet(imgs)\n",
        "            feats = resnet_penultimate(imgs).squeeze()\n",
        "            if feats.dim() == 1:  # Handle single sample case\n",
        "                feats = feats.unsqueeze(0)\n",
        "            prob_resnet.append(F.softmax(out, dim=1)[:, 1].cpu().numpy())\n",
        "            pred_resnet.append(out.argmax(1).cpu().numpy())\n",
        "            resnet_features.append(feats.cpu().numpy())\n",
        "\n",
        "    pred_resnet = np.concatenate(pred_resnet)\n",
        "    prob_resnet = np.concatenate(prob_resnet)\n",
        "    resnet_features = np.vstack(resnet_features)\n",
        "\n",
        "timings['method3_inference'] = t.__exit__()\n",
        "\n",
        "p, r, f1_resnet, _ = precision_recall_fscore_support(test_labels, pred_resnet, average='binary')\n",
        "acc_resnet = accuracy_score(test_labels, pred_resnet)\n",
        "roc_resnet = roc_auc_score(test_labels, prob_resnet)\n",
        "print(f\"üìä F1={f1_resnet:.4f} | Acc={acc_resnet:.4f} | ROC-AUC={roc_resnet:.4f}\")\n",
        "\n",
        "del resnet, resnet_penultimate\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co2HxAht9xDl"
      },
      "outputs": [],
      "source": [
        "# ==================== METHOD 4: VISION TRANSFORMER ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 4: Vision Transformer (ViT-B/16)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create FRESH datasets and dataloaders for ViT with 224x224 images\n",
        "transform_train_vit = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),  # Changed from 128 to 224 for ViT\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test_vit = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Changed from 128 to 224 for ViT\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_ds_img_vit = ImageDataset(train_files, train_labels, transform_train_vit)\n",
        "val_ds_img_vit = ImageDataset(val_files, val_labels, transform_test_vit)\n",
        "test_ds_img_vit = ImageDataset(test_files, test_labels, transform_test_vit)\n",
        "\n",
        "train_loader_vit = DataLoader(train_ds_img_vit, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader_vit = DataLoader(val_ds_img_vit, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader_vit = DataLoader(test_ds_img_vit, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "vit = models.vit_b_16(weights='IMAGENET1K_V1')\n",
        "vit.heads.head = nn.Linear(vit.heads.head.in_features, 2)\n",
        "vit = vit.to(device)\n",
        "optimizer_vit = torch.optim.AdamW(vit.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "with Timer(\"Method 4 Training\") as t:\n",
        "    best_f1 = 0\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        vit.train()\n",
        "        for imgs, labels in tqdm(train_loader_vit, desc=f\"Epoch {epoch}\", leave=False):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer_vit.zero_grad()\n",
        "            out = vit(imgs)\n",
        "            loss = F.cross_entropy(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer_vit.step()\n",
        "\n",
        "        vit.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader_vit:\n",
        "                imgs = imgs.to(device)\n",
        "                preds.append(vit(imgs).argmax(1).cpu().numpy())\n",
        "                targets.append(labels.numpy())\n",
        "\n",
        "        preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "        f1 = precision_recall_fscore_support(targets, preds, average='binary')[2]\n",
        "        print(f\"  Epoch {epoch}: Val F1={f1:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state_vit = copy.deepcopy(vit.state_dict())\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    vit.load_state_dict(best_state_vit)\n",
        "\n",
        "timings['method4_train'] = t.__exit__()\n",
        "\n",
        "with Timer(\"Method 4 Inference\") as t:\n",
        "    pred_vit, prob_vit = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader_vit:\n",
        "            imgs = imgs.to(device)\n",
        "            out = vit(imgs)\n",
        "            prob_vit.append(F.softmax(out, dim=1)[:, 1].cpu().numpy())\n",
        "            pred_vit.append(out.argmax(1).cpu().numpy())\n",
        "\n",
        "    pred_vit = np.concatenate(pred_vit)\n",
        "    prob_vit = np.concatenate(prob_vit)\n",
        "\n",
        "timings['method4_inference'] = t.__exit__()\n",
        "\n",
        "p, r, f1_vit, _ = precision_recall_fscore_support(test_labels, pred_vit, average='binary')\n",
        "acc_vit = accuracy_score(test_labels, pred_vit)\n",
        "roc_vit = roc_auc_score(test_labels, prob_vit)\n",
        "print(f\"üìä F1={f1_vit:.4f} | Acc={acc_vit:.4f} | ROC-AUC={roc_vit:.4f}\")\n",
        "\n",
        "del vit\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3Kmvh0J9xDm"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# METHOD 5: ResNet50 (Frozen) + Handcrafted Attention Fusion\n",
        "# ======================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 5: ResNet50 (Frozen Pretrained) + Handcrafted Fusion\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================\n",
        "# 1. Load FROZEN ResNet50 (pre-trained, never fine-tuned)\n",
        "# ============================================================\n",
        "print(\"Loading frozen pre-trained ResNet50...\")\n",
        "resnet50_frozen = models.resnet50(weights='IMAGENET1K_V2')\n",
        "# Remove final classification layer\n",
        "resnet50_feature_extractor = nn.Sequential(*list(resnet50_frozen.children())[:-1])\n",
        "resnet50_feature_extractor.eval()\n",
        "resnet50_feature_extractor.to(device)\n",
        "\n",
        "# Freeze all parameters\n",
        "for param in resnet50_feature_extractor.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Transform for ResNet (same as before)\n",
        "resnet_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ============================================================\n",
        "# 2. Extract ResNet Features (IN CORRECT ORDER)\n",
        "# ============================================================\n",
        "def extract_resnet_features_batch(file_list, transform, model, device, batch_size=32):\n",
        "    \"\"\"Extract features in batches while maintaining order\"\"\"\n",
        "    all_features = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(file_list), batch_size), desc=\"Extracting ResNet features\", leave=False):\n",
        "            batch_files = file_list[i:i+batch_size]\n",
        "            batch_tensors = []\n",
        "\n",
        "            for f in batch_files:\n",
        "                try:\n",
        "                    img = Image.open(f).convert(\"RGB\")\n",
        "                    tensor = transform(img)\n",
        "                    batch_tensors.append(tensor)\n",
        "                except:\n",
        "                    # Handle corrupted images - use zero tensor\n",
        "                    batch_tensors.append(torch.zeros(3, 128, 128))\n",
        "\n",
        "            if batch_tensors:\n",
        "                batch_t = torch.stack(batch_tensors).to(device)\n",
        "                features = model(batch_t).squeeze()  # Remove spatial dimensions\n",
        "\n",
        "                # Handle single sample case\n",
        "                if features.dim() == 1:\n",
        "                    features = features.unsqueeze(0)\n",
        "\n",
        "                all_features.append(features.cpu().numpy())\n",
        "\n",
        "                # Clear GPU memory periodically\n",
        "                if i % 100 == 0:\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "    return np.vstack(all_features).astype(np.float32)\n",
        "\n",
        "with Timer(\"ResNet50 Frozen Feature Extraction\") as t:\n",
        "    X_train_resnet_frozen = extract_resnet_features_batch(\n",
        "        train_files, resnet_transform, resnet50_feature_extractor, device\n",
        "    )\n",
        "    X_val_resnet_frozen = extract_resnet_features_batch(\n",
        "        val_files, resnet_transform, resnet50_feature_extractor, device\n",
        "    )\n",
        "    X_test_resnet_frozen = extract_resnet_features_batch(\n",
        "        test_files, resnet_transform, resnet50_feature_extractor, device\n",
        "    )\n",
        "    timings[\"resnet_frozen_extraction\"] = t.__exit__()\n",
        "\n",
        "print(f\"‚úì ResNet50 frozen features extracted:\")\n",
        "print(f\"  Train: {X_train_resnet_frozen.shape}\")\n",
        "print(f\"  Val:   {X_val_resnet_frozen.shape}\")\n",
        "print(f\"  Test:  {X_test_resnet_frozen.shape}\")\n",
        "\n",
        "# Verify alignment\n",
        "assert len(X_train_resnet_frozen) == len(train_labels), \"Train set size mismatch!\"\n",
        "assert len(X_test_resnet_frozen) == len(test_labels), \"Test set size mismatch!\"\n",
        "\n",
        "# ============================================================\n",
        "# 3. Create Fusion Datasets\n",
        "# ============================================================\n",
        "train_ds_resnet_fusion = FusionDataset(X_train_hand, X_train_resnet_frozen, train_labels)\n",
        "val_ds_resnet_fusion = FusionDataset(X_val_hand, X_val_resnet_frozen, val_labels)\n",
        "test_ds_resnet_fusion = FusionDataset(X_test_hand, X_test_resnet_frozen, test_labels)\n",
        "\n",
        "train_loader_resnet_fusion = DataLoader(train_ds_resnet_fusion, batch_size=64, shuffle=True)\n",
        "val_loader_resnet_fusion = DataLoader(val_ds_resnet_fusion, batch_size=64, shuffle=False)\n",
        "test_loader_resnet_fusion = DataLoader(test_ds_resnet_fusion, batch_size=64, shuffle=False)\n",
        "\n",
        "# ============================================================\n",
        "# 4. Define Fusion Model (using your AttentionFusion class)\n",
        "# ============================================================\n",
        "fusion_resnet50 = AttentionFusion(\n",
        "    hand_dim=X_train_hand.shape[1],  # 23\n",
        "    cnn_dim=2048,  # ResNet50 feature dimension\n",
        "    hidden=64\n",
        ").to(device)\n",
        "\n",
        "optimizer_resnet_fusion = torch.optim.AdamW(\n",
        "    fusion_resnet50.parameters(),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 5. Train Fusion Model\n",
        "# ============================================================\n",
        "best_f1_resnet_fusion = 0\n",
        "best_state_resnet_fusion = copy.deepcopy(fusion_resnet50.state_dict())\n",
        "\n",
        "with Timer(\"Method 5 Training\") as t:\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        # Training\n",
        "        fusion_resnet50.train()\n",
        "        for hand, resnet_feat, labels in train_loader_resnet_fusion:\n",
        "            hand = hand.to(device)\n",
        "            resnet_feat = resnet_feat.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer_resnet_fusion.zero_grad()\n",
        "            out, _ = fusion_resnet50(hand, resnet_feat)\n",
        "            loss = F.cross_entropy(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer_resnet_fusion.step()\n",
        "\n",
        "        # Validation\n",
        "        fusion_resnet50.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for hand, resnet_feat, labels in val_loader_resnet_fusion:\n",
        "                hand = hand.to(device)\n",
        "                resnet_feat = resnet_feat.to(device)\n",
        "                out, _ = fusion_resnet50(hand, resnet_feat)\n",
        "                preds.append(out.argmax(1).cpu().numpy())\n",
        "                targets.append(labels.numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        targets = np.concatenate(targets)\n",
        "        f1_val = precision_recall_fscore_support(targets, preds, average=\"binary\")[2]\n",
        "\n",
        "        print(f\"  Epoch {epoch}: Val F1 = {f1_val:.4f}\")\n",
        "\n",
        "        if f1_val > best_f1_resnet_fusion:\n",
        "            best_f1_resnet_fusion = f1_val\n",
        "            best_state_resnet_fusion = copy.deepcopy(fusion_resnet50.state_dict())\n",
        "\n",
        "    timings[\"method5_train\"] = t.__exit__()\n",
        "\n",
        "# Load best model\n",
        "fusion_resnet50.load_state_dict(best_state_resnet_fusion)\n",
        "\n",
        "# ============================================================\n",
        "# 6. Test Performance\n",
        "# ============================================================\n",
        "with Timer(\"Method 5 Inference\") as t:\n",
        "    fusion_resnet50.eval()\n",
        "    pred_resnet_fusion, prob_resnet_fusion = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for hand, resnet_feat, labels in test_loader_resnet_fusion:\n",
        "            hand = hand.to(device)\n",
        "            resnet_feat = resnet_feat.to(device)\n",
        "            out, _ = fusion_resnet50(hand, resnet_feat)\n",
        "            prob_resnet_fusion.append(F.softmax(out, dim=1)[:, 1].cpu().numpy())\n",
        "            pred_resnet_fusion.append(out.argmax(1).cpu().numpy())\n",
        "\n",
        "    timings[\"method5_inference\"] = t.__exit__()\n",
        "\n",
        "pred_resnet_fusion = np.concatenate(pred_resnet_fusion)\n",
        "prob_resnet_fusion = np.concatenate(prob_resnet_fusion)\n",
        "\n",
        "# Calculate metrics\n",
        "p_rf, r_rf, f1_resnet_fusion, _ = precision_recall_fscore_support(\n",
        "    test_labels, pred_resnet_fusion, average=\"binary\"\n",
        ")\n",
        "acc_resnet_fusion = accuracy_score(test_labels, pred_resnet_fusion)\n",
        "roc_resnet_fusion = roc_auc_score(test_labels, prob_resnet_fusion)\n",
        "\n",
        "print(f\"\\nüìä ResNet50 (Frozen) + Fusion Performance:\")\n",
        "print(f\"  F1-score:  {f1_resnet_fusion:.4f}\")\n",
        "print(f\"  Accuracy:  {acc_resnet_fusion:.4f}\")\n",
        "print(f\"  Precision: {p_rf:.4f}\")\n",
        "print(f\"  Recall:    {r_rf:.4f}\")\n",
        "print(f\"  ROC-AUC:   {roc_resnet_fusion:.4f}\")\n",
        "\n",
        "# Clean up\n",
        "del resnet50_frozen, resnet50_feature_extractor, fusion_resnet50\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== METHOD 5: RESNET50 FINE-TUNED + HANDCRAFTED FUSION ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METHOD 5: ResNet50 Fine-tuned + Handcrafted Fusion\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class ResNet50FusionFineTuned(nn.Module):\n",
        "    def __init__(self, hand_dim, hidden=64):\n",
        "        super().__init__()\n",
        "        self.resnet_backbone = models.resnet50(weights='IMAGENET1K_V2')\n",
        "        self.resnet_backbone.fc = nn.Identity()\n",
        "\n",
        "        self.hand_proj = nn.Linear(hand_dim, hidden)\n",
        "        self.resnet_proj = nn.Linear(2048, hidden)\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden * 2, hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden, 2),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, imgs, hand):\n",
        "        resnet_feat = self.resnet_backbone(imgs)\n",
        "        if resnet_feat.dim() == 1:\n",
        "            resnet_feat = resnet_feat.unsqueeze(0)\n",
        "\n",
        "        h_hand = F.relu(self.hand_proj(hand))\n",
        "        h_resnet = F.relu(self.resnet_proj(resnet_feat))\n",
        "\n",
        "        attn = self.attention(torch.cat([h_hand, h_resnet], 1))\n",
        "        fused = attn[:, 0:1] * h_hand + attn[:, 1:2] * h_resnet\n",
        "\n",
        "        out = self.classifier(fused)\n",
        "        return out, attn\n",
        "\n",
        "class ImageHandcraftedDataset(Dataset):\n",
        "    def __init__(self, files, hand_features, labels, transform):\n",
        "        self.files = files\n",
        "        self.hand_features = torch.FloatTensor(hand_features)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.files[i]).convert('RGB')\n",
        "        return self.transform(img), self.hand_features[i], self.labels[i]\n",
        "\n",
        "train_ds_hybrid = ImageHandcraftedDataset(train_files, X_train_hand, train_labels, transform_train)\n",
        "val_ds_hybrid = ImageHandcraftedDataset(val_files, X_val_hand, val_labels, transform_test)\n",
        "test_ds_hybrid = ImageHandcraftedDataset(test_files, X_test_hand, test_labels, transform_test)\n",
        "\n",
        "train_loader_hybrid = DataLoader(train_ds_hybrid, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader_hybrid = DataLoader(val_ds_hybrid, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader_hybrid = DataLoader(test_ds_hybrid, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "resnet_fusion_ft = ResNet50FusionFineTuned(hand_dim=X_train_hand.shape[1]).to(device)\n",
        "optimizer_resnet_fusion_ft = torch.optim.AdamW(resnet_fusion_ft.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "with Timer(\"Method 5 Training\") as t:\n",
        "    best_f1 = 0\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        resnet_fusion_ft.train()\n",
        "        for imgs, hand, labels in tqdm(train_loader_hybrid, desc=f\"Epoch {epoch}\", leave=False):\n",
        "            imgs, hand, labels = imgs.to(device), hand.to(device), labels.to(device)\n",
        "            optimizer_resnet_fusion_ft.zero_grad()\n",
        "            out, _ = resnet_fusion_ft(imgs, hand)\n",
        "            loss = F.cross_entropy(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer_resnet_fusion_ft.step()\n",
        "\n",
        "        resnet_fusion_ft.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, hand, labels in val_loader_hybrid:\n",
        "                imgs, hand = imgs.to(device), hand.to(device)\n",
        "                out, _ = resnet_fusion_ft(imgs, hand)\n",
        "                preds.append(out.argmax(1).cpu().numpy())\n",
        "                targets.append(labels.numpy())\n",
        "        preds, targets = np.concatenate(preds), np.concatenate(targets)\n",
        "        f1 = precision_recall_fscore_support(targets, preds, average='binary')[2]\n",
        "        print(f\"  Epoch {epoch}: Val F1={f1:.4f}\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state_resnet_fusion_ft = copy.deepcopy(resnet_fusion_ft.state_dict())\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    resnet_fusion_ft.load_state_dict(best_state_resnet_fusion_ft)\n",
        "    timings['method5_train'] = t.__exit__()\n",
        "\n",
        "with Timer(\"Method 5 Inference\") as t:\n",
        "    pred_resnet_fusion_ft, prob_resnet_fusion_ft = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, hand, labels in test_loader_hybrid:\n",
        "            imgs, hand = imgs.to(device), hand.to(device)\n",
        "            out, _ = resnet_fusion_ft(imgs, hand)\n",
        "            prob_resnet_fusion_ft.append(F.softmax(out, dim=1)[:, 1].cpu().numpy())\n",
        "            pred_resnet_fusion_ft.append(out.argmax(1).cpu().numpy())\n",
        "\n",
        "    pred_resnet_fusion_ft = np.concatenate(pred_resnet_fusion_ft)\n",
        "    prob_resnet_fusion_ft = np.concatenate(prob_resnet_fusion_ft)\n",
        "    timings['method5_inference'] = t.__exit__()\n",
        "\n",
        "p, r, f1_resnet_fusion_ft, _ = precision_recall_fscore_support(test_labels, pred_resnet_fusion_ft, average='binary')\n",
        "acc_resnet_fusion_ft = accuracy_score(test_labels, pred_resnet_fusion_ft)\n",
        "roc_resnet_fusion_ft = roc_auc_score(test_labels, prob_resnet_fusion_ft)\n",
        "print(f\"üìä F1={f1_resnet_fusion_ft:.4f} | Acc={acc_resnet_fusion_ft:.4f} | ROC-AUC={roc_resnet_fusion_ft:.4f}\")\n",
        "\n",
        "del resnet_fusion_ft\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Lk1eiQdk-aUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG3U_G6i9xDn"
      },
      "outputs": [],
      "source": [
        "# ==================== FAIR COMPARISON TABLE ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FAIR COMPARISON (Including Feature Extraction Time)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results_df = pd.DataFrame([\n",
        "    {\n",
        "        'Method': 'Handcrafted + RF',\n",
        "        'F1': f1_rf,\n",
        "        'Accuracy': acc_rf,\n",
        "        'ROC-AUC': roc_rf,\n",
        "        'Feature Extraction (s)': timings['handcrafted_extraction'],\n",
        "        'Training (s)': timings['method1_train'],\n",
        "        'Inference (s)': timings['method1_inference'],\n",
        "        'Total Pipeline (s)': timings['handcrafted_extraction'] + timings['method1_train']\n",
        "    },\n",
        "    {\n",
        "        'Method': 'Attention Fusion (Ours)',\n",
        "        'F1': f1_fusion,\n",
        "        'Accuracy': acc_fusion,\n",
        "        'ROC-AUC': roc_fusion,\n",
        "        'Feature Extraction (s)': timings['handcrafted_extraction'] + timings['cnn_extraction'],\n",
        "        'Training (s)': timings['method2_train'],\n",
        "        'Inference (s)': timings['method2_inference'],\n",
        "        'Total Pipeline (s)': timings['handcrafted_extraction'] + timings['cnn_extraction'] + timings['method2_train']\n",
        "    },\n",
        "    {\n",
        "        'Method': 'ResNet50',\n",
        "        'F1': f1_resnet,\n",
        "        'Accuracy': acc_resnet,\n",
        "        'ROC-AUC': roc_resnet,\n",
        "        'Feature Extraction (s)': 0,\n",
        "        'Training (s)': timings['method3_train'],\n",
        "        'Inference (s)': timings['method3_inference'],\n",
        "        'Total Pipeline (s)': timings['method3_train']\n",
        "    },\n",
        "    {\n",
        "        'Method': 'ViT-B/16',\n",
        "        'F1': f1_vit,\n",
        "        'Accuracy': acc_vit,\n",
        "        'ROC-AUC': roc_vit,\n",
        "        'Feature Extraction (s)': 0,\n",
        "        'Training (s)': timings['method4_train'],\n",
        "        'Inference (s)': timings['method4_inference'],\n",
        "        'Total Pipeline (s)': timings['method4_train']\n",
        "    }\n",
        "])\n",
        "\n",
        "print(results_df.to_string(index=False))\n",
        "results_df.to_csv('fair_comparison_results.csv', index=False)\n",
        "\n",
        "# Calculate speedup\n",
        "resnet_time = results_df[results_df['Method'] == 'ResNet50']['Total Pipeline (s)'].values[0]\n",
        "fusion_time = results_df[results_df['Method'] == 'Attention Fusion (Ours)']['Total Pipeline (s)'].values[0]\n",
        "speedup = resnet_time / fusion_time\n",
        "\n",
        "print(f\"\\nüöÄ SPEEDUP: Attention Fusion is {speedup:.1f}√ó faster than ResNet50!\")\n",
        "print(f\"üìâ F1 Trade-off: {(f1_resnet - f1_fusion)*100:.1f}% accuracy loss for {speedup:.1f}√ó speedup\")\n",
        "\n",
        "# ==================== VISUALIZATION 1: COMPREHENSIVE COMPARISON ====================\n",
        "print(\"\\nüìä Generating Figure 1: Comprehensive Comparison...\")\n",
        "\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# Row 1: Confusion Matrices\n",
        "methods_data = [\n",
        "    ('Handcrafted+RF', test_labels, pred_rf),\n",
        "    ('Attention Fusion', test_labels, pred_fusion),\n",
        "    ('ResNet50', test_labels, pred_resnet),\n",
        "    ('ViT-B/16', test_labels, pred_vit)\n",
        "]\n",
        "\n",
        "for idx, (name, true, pred) in enumerate(methods_data):\n",
        "    ax = fig.add_subplot(gs[0, idx])\n",
        "    cm = confusion_matrix(true, pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                xticklabels=['Human', 'AI'], yticklabels=['Human', 'AI'])\n",
        "    ax.set_title(f'{name}\\nConfusion Matrix', fontsize=10, fontweight='bold')\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "\n",
        "# Row 2: ROC Curves and Performance Metrics\n",
        "ax_roc = fig.add_subplot(gs[1, :2])\n",
        "for true, prob, name, color in [\n",
        "    (test_labels, prob_rf, 'Handcrafted+RF', '#1f77b4'),\n",
        "    (test_labels, prob_fusion, 'Attention Fusion', '#d62728'),\n",
        "    (test_labels, prob_resnet, 'ResNet50', '#2ca02c'),\n",
        "    (test_labels, prob_vit, 'ViT-B/16', '#ff7f0e')\n",
        "]:\n",
        "    fpr, tpr, _ = roc_curve(true, prob)\n",
        "    auc = roc_auc_score(true, prob)\n",
        "    ax_roc.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', lw=2, color=color)\n",
        "\n",
        "ax_roc.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3)\n",
        "ax_roc.set_xlabel('False Positive Rate', fontweight='bold')\n",
        "ax_roc.set_ylabel('True Positive Rate', fontweight='bold')\n",
        "ax_roc.set_title('ROC Curves Comparison', fontsize=11, fontweight='bold')\n",
        "ax_roc.legend(loc='lower right', fontsize=8)\n",
        "ax_roc.grid(alpha=0.3)\n",
        "\n",
        "# Performance Metrics Comparison\n",
        "ax_perf = fig.add_subplot(gs[1, 2:])\n",
        "metrics = ['F1', 'Accuracy', 'ROC-AUC']\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.2\n",
        "colors = ['#1f77b4', '#d62728', '#2ca02c', '#ff7f0e']\n",
        "\n",
        "for i, (method_name, color) in enumerate([\n",
        "    ('Handcrafted + RF', colors[0]),\n",
        "    ('Attention Fusion (Ours)', colors[1]),\n",
        "    ('ResNet50', colors[2]),\n",
        "    ('ViT-B/16', colors[3])\n",
        "]):\n",
        "    values = results_df[results_df['Method'] == method_name][metrics].values[0]\n",
        "    ax_perf.bar(x + i * width - 0.3, values, width, label=method_name, color=color, alpha=0.8)\n",
        "\n",
        "ax_perf.set_ylabel('Score', fontweight='bold')\n",
        "ax_perf.set_title('Performance Metrics Comparison', fontsize=11, fontweight='bold')\n",
        "ax_perf.set_xticks(x)\n",
        "ax_perf.set_xticklabels(metrics)\n",
        "ax_perf.legend(fontsize=7, loc='lower right')\n",
        "ax_perf.set_ylim([0.65, 1.0])\n",
        "ax_perf.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Row 3: Computational Efficiency Analysis\n",
        "ax_time = fig.add_subplot(gs[2, :2])\n",
        "methods = results_df['Method'].values\n",
        "total_times = results_df['Total Pipeline (s)'].values / 60  # Convert to minutes\n",
        "\n",
        "bars = ax_time.barh(methods, total_times, color=['#1f77b4', '#d62728', '#2ca02c', '#ff7f0e'], alpha=0.8)\n",
        "ax_time.set_xlabel('Total Time (minutes)', fontweight='bold')\n",
        "ax_time.set_title('Computational Efficiency: Total Pipeline Time', fontsize=11, fontweight='bold')\n",
        "ax_time.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for bar, time_val in zip(bars, total_times):\n",
        "    ax_time.text(time_val + 0.1, bar.get_y() + bar.get_height()/2,\n",
        "                 f'{time_val:.1f} min', va='center', fontsize=8)\n",
        "\n",
        "# Accuracy vs Time Trade-off\n",
        "ax_tradeoff = fig.add_subplot(gs[2, 2:])\n",
        "f1_scores = results_df['F1'].values\n",
        "total_times_sec = results_df['Total Pipeline (s)'].values\n",
        "\n",
        "for i, (method, color) in enumerate([\n",
        "    ('Handcrafted + RF', colors[0]),\n",
        "    ('Attention Fusion', colors[1]),\n",
        "    ('ResNet50', colors[2]),\n",
        "    ('ViT-B/16', colors[3])\n",
        "]):\n",
        "    ax_tradeoff.scatter(total_times_sec[i], f1_scores[i], s=200, color=color,\n",
        "                       alpha=0.7, edgecolors='black', linewidth=1.5, label=method)\n",
        "    ax_tradeoff.annotate(method, (total_times_sec[i], f1_scores[i]),\n",
        "                        xytext=(10, 5), textcoords='offset points', fontsize=7)\n",
        "\n",
        "ax_tradeoff.set_xlabel('Total Pipeline Time (seconds)', fontweight='bold')\n",
        "ax_tradeoff.set_ylabel('F1 Score', fontweight='bold')\n",
        "ax_tradeoff.set_title('Accuracy vs Computational Cost Trade-off', fontsize=11, fontweight='bold')\n",
        "ax_tradeoff.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Comprehensive Method Comparison: AI-Generated Art Detection',\n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.savefig('figure1_comprehensive_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# ==================== VISUALIZATION 2: FEATURE ANALYSIS ====================\n",
        "print(\"\\nüìä Generating Figure 2: Feature Analysis & Interpretability...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Feature Importance\n",
        "ax = axes[0, 0]\n",
        "top_features = feature_importance.head(10)\n",
        "ax.barh(range(len(top_features)), top_features['Importance'].values, color='steelblue', alpha=0.8)\n",
        "ax.set_yticks(range(len(top_features)))\n",
        "ax.set_yticklabels(top_features['Feature'].values, fontsize=8)\n",
        "ax.set_xlabel('Importance', fontweight='bold')\n",
        "ax.set_title('Top 10 Discriminative Features\\n(Random Forest)', fontsize=10, fontweight='bold')\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Highlight frequency features\n",
        "for i, feat in enumerate(top_features['Feature'].values):\n",
        "    if 'freq' in feat.lower() or 'Freq' in feat:\n",
        "        ax.get_yticklabels()[i].set_color('red')\n",
        "        ax.get_yticklabels()[i].set_weight('bold')\n",
        "\n",
        "# 2. Attention Weights Distribution\n",
        "ax = axes[0, 1]\n",
        "hand_attn = attn_weights[:, 0]\n",
        "cnn_attn = attn_weights[:, 1]\n",
        "\n",
        "ax.hist(hand_attn, bins=30, alpha=0.7, label='Handcrafted Features', color='#2ecc71', edgecolor='black')\n",
        "ax.hist(cnn_attn, bins=30, alpha=0.7, label='CNN Features', color='#9b59b6', edgecolor='black')\n",
        "ax.set_xlabel('Attention Weight', fontweight='bold')\n",
        "ax.set_ylabel('Frequency', fontweight='bold')\n",
        "ax.set_title('Learned Attention Distribution\\n(NOVEL: Fusion Mechanism)', fontsize=10, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "print(f\"  Mean attention - Handcrafted: {hand_attn.mean():.3f}, CNN: {cnn_attn.mean():.3f}\")\n",
        "\n",
        "# 3. Attention by Correctness\n",
        "ax = axes[0, 2]\n",
        "correct_mask = (pred_fusion == test_labels)\n",
        "incorrect_mask = ~correct_mask\n",
        "\n",
        "ax.scatter(hand_attn[correct_mask], cnn_attn[correct_mask],\n",
        "          alpha=0.5, s=20, color='green', label='Correct', edgecolors='none')\n",
        "ax.scatter(hand_attn[incorrect_mask], cnn_attn[incorrect_mask],\n",
        "          alpha=0.8, s=40, color='red', label='Incorrect', edgecolors='black', linewidth=0.5)\n",
        "ax.set_xlabel('Handcrafted Attention Weight', fontweight='bold')\n",
        "ax.set_ylabel('CNN Attention Weight', fontweight='bold')\n",
        "ax.set_title('Attention Pattern by Prediction Correctness', fontsize=10, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# 4. Frequency Ratio Distribution (NOVEL FEATURE)\n",
        "ax = axes[1, 0]\n",
        "feat_df = pd.DataFrame(X_train_hand, columns=feature_names)\n",
        "feat_df['Label'] = ['Human' if l == 0 else 'AI' for l in train_labels]\n",
        "\n",
        "human_freq = feat_df[feat_df['Label']=='Human']['Freq_ratio']\n",
        "ai_freq = feat_df[feat_df['Label']=='AI']['Freq_ratio']\n",
        "\n",
        "ax.hist(human_freq, bins=30, alpha=0.6, label='Human Art', color='#3498db', edgecolor='black')\n",
        "ax.hist(ai_freq, bins=30, alpha=0.6, label='AI Art', color='#e74c3c', edgecolor='black')\n",
        "ax.set_xlabel('Frequency Ratio (High/Low)', fontweight='bold')\n",
        "ax.set_ylabel('Frequency', fontweight='bold')\n",
        "ax.set_title('NOVEL: Frequency Domain Feature\\n(Strong AI Discriminator)', fontsize=10, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# 5. Texture Entropy Distribution\n",
        "ax = axes[1, 1]\n",
        "human_entropy = feat_df[feat_df['Label']=='Human']['Entropy']\n",
        "ai_entropy = feat_df[feat_df['Label']=='AI']['Entropy']\n",
        "\n",
        "from scipy.stats import gaussian_kde\n",
        "x_range = np.linspace(min(human_entropy.min(), ai_entropy.min()),\n",
        "                      max(human_entropy.max(), ai_entropy.max()), 200)\n",
        "kde_human = gaussian_kde(human_entropy)\n",
        "kde_ai = gaussian_kde(ai_entropy)\n",
        "\n",
        "ax.plot(x_range, kde_human(x_range), label='Human Art', color='#3498db', lw=2)\n",
        "ax.fill_between(x_range, kde_human(x_range), alpha=0.3, color='#3498db')\n",
        "ax.plot(x_range, kde_ai(x_range), label='AI Art', color='#e74c3c', lw=2)\n",
        "ax.fill_between(x_range, kde_ai(x_range), alpha=0.3, color='#e74c3c')\n",
        "ax.set_xlabel('Texture Entropy', fontweight='bold')\n",
        "ax.set_ylabel('Density', fontweight='bold')\n",
        "ax.set_title('Texture Complexity Distribution', fontsize=10, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "# 6. Correlation Heatmap of Top Features\n",
        "ax = axes[1, 2]\n",
        "top_5_features = feature_importance.head(5)['Feature'].values\n",
        "corr_data = feat_df[list(top_5_features)].corr()\n",
        "sns.heatmap(corr_data, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "            ax=ax, cbar_kws={'label': 'Correlation'}, square=True)\n",
        "ax.set_title('Feature Correlation Matrix\\n(Top 5 Features)', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Feature Analysis & Interpretability', fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure2_feature_analysis.png', dpi=1200, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# ==================== VISUALIZATION 3: t-SNE COMPARISON ====================\n",
        "print(\"\\nüìä Generating Figure 3: Feature Space Visualization (t-SNE)...\")\n",
        "\n",
        "# Subsample for speed\n",
        "n_samples = min(500, len(test_labels))\n",
        "sample_idx = np.random.choice(len(test_labels), n_samples, replace=False)\n",
        "\n",
        "sampled_labels = np.array(test_labels)[sample_idx]\n",
        "sampled_hand = X_test_hand[sample_idx]\n",
        "sampled_fusion = fusion_features[sample_idx]\n",
        "sampled_resnet = resnet_features[sample_idx]\n",
        "\n",
        "print(\"  Computing t-SNE embeddings...\")\n",
        "tsne = TSNE(n_components=2, random_state=SEED, perplexity=30)\n",
        "\n",
        "tsne_hand = tsne.fit_transform(sampled_hand)\n",
        "tsne_fusion = tsne.fit_transform(sampled_fusion)\n",
        "tsne_resnet = tsne.fit_transform(sampled_resnet)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for ax, data, title in [\n",
        "    (axes[0], tsne_hand, 'Handcrafted Features'),\n",
        "    (axes[1], tsne_fusion, 'Attention Fusion Features'),\n",
        "    (axes[2], tsne_resnet, 'ResNet50 Features')\n",
        "]:\n",
        "    scatter = ax.scatter(data[sampled_labels==0, 0], data[sampled_labels==0, 1],\n",
        "                        c='#3498db', label='Human', alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
        "    scatter = ax.scatter(data[sampled_labels==1, 0], data[sampled_labels==1, 1],\n",
        "                        c='#e74c3c', label='AI', alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
        "    ax.set_xlabel('t-SNE Dimension 1', fontweight='bold')\n",
        "    ax.set_ylabel('t-SNE Dimension 2', fontweight='bold')\n",
        "    ax.set_title(f'{title}\\nFeature Space', fontsize=11, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Feature Space Visualization: Class Separation Analysis',\n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure3_tsne_visualization.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# ==================== VISUALIZATION 4: ERROR ANALYSIS ====================\n",
        "print(\"\\nüìä Generating Figure 4: Error Analysis & Sample Predictions...\")\n",
        "\n",
        "# Find interesting cases\n",
        "correct_human_idx = np.where((np.array(test_labels) == 0) & (pred_fusion == 0))[0]\n",
        "correct_ai_idx = np.where((np.array(test_labels) == 1) & (pred_fusion == 1))[0]\n",
        "wrong_human_to_ai = np.where((np.array(test_labels) == 0) & (pred_fusion == 1))[0]\n",
        "wrong_ai_to_human = np.where((np.array(test_labels) == 1) & (pred_fusion == 0))[0]\n",
        "\n",
        "fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
        "\n",
        "def show_samples(row, indices, title, label_map):\n",
        "    for col in range(min(6, len(indices))):\n",
        "        if col < len(indices):\n",
        "            idx = indices[col]\n",
        "            img_path = test_files[idx]\n",
        "            img = Image.open(img_path).convert('RGB').resize((128, 128))\n",
        "\n",
        "            axes[row, col].imshow(img)\n",
        "\n",
        "            true_label = 'Human' if test_labels[idx] == 0 else 'AI'\n",
        "            pred_label = 'Human' if pred_fusion[idx] == 0 else 'AI'\n",
        "            conf = prob_fusion[idx] if pred_fusion[idx] == 1 else 1 - prob_fusion[idx]\n",
        "\n",
        "            # Color code by correctness\n",
        "            color = 'green' if pred_fusion[idx] == test_labels[idx] else 'red'\n",
        "\n",
        "            axes[row, col].set_title(f'{label_map}\\nTrue: {true_label}\\nConf: {conf:.2f}',\n",
        "                                    fontsize=8, color=color, fontweight='bold')\n",
        "            axes[row, col].axis('off')\n",
        "        else:\n",
        "            axes[row, col].axis('off')\n",
        "\n",
        "    axes[row, 0].set_ylabel(title, fontsize=11, fontweight='bold', rotation=90, labelpad=10)\n",
        "\n",
        "# Sample 6 from each category\n",
        "show_samples(0, correct_human_idx[:6], 'Correct:\\nHuman Art', 'Correct')\n",
        "show_samples(1, correct_ai_idx[:6], 'Correct:\\nAI Art', 'Correct')\n",
        "show_samples(2, wrong_human_to_ai[:6], 'Error:\\nHuman‚ÜíAI', 'Misclassified')\n",
        "show_samples(3, wrong_ai_to_human[:6], 'Error:\\nAI‚ÜíHuman', 'Misclassified')\n",
        "\n",
        "plt.suptitle('Sample Predictions & Error Analysis (Attention Fusion Model)',\n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure4_error_analysis.png', dpi=1200, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# ==================== ABLATION STUDY ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ABLATION STUDY: Component Analysis\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test simple concatenation without attention\n",
        "X_train_concat = np.hstack([X_train_hand, X_train_cnn])\n",
        "X_test_concat = np.hstack([X_test_hand, X_test_cnn])\n",
        "\n",
        "with Timer(\"Ablation: Simple Concatenation\") as t:\n",
        "    rf_concat = RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)\n",
        "    rf_concat.fit(X_train_concat, train_labels)\n",
        "    pred_concat = rf_concat.predict(X_test_concat)\n",
        "    prob_concat = rf_concat.predict_proba(X_test_concat)[:, 1]\n",
        "\n",
        "f1_concat = precision_recall_fscore_support(test_labels, pred_concat, average='binary')[2]\n",
        "acc_concat = accuracy_score(test_labels, pred_concat)\n",
        "roc_concat = roc_auc_score(test_labels, prob_concat)\n",
        "\n",
        "ablation_df = pd.DataFrame([\n",
        "    {'Configuration': 'Handcrafted Only', 'F1': f1_rf, 'Accuracy': acc_rf, 'ROC-AUC': roc_rf},\n",
        "    {'Configuration': 'CNN Only', 'F1': 0.0, 'Accuracy': 0.0, 'ROC-AUC': 0.0},  # Placeholder\n",
        "    {'Configuration': 'Simple Concatenation', 'F1': f1_concat, 'Accuracy': acc_concat, 'ROC-AUC': roc_concat},\n",
        "    {'Configuration': 'Attention Fusion (Ours)', 'F1': f1_fusion, 'Accuracy': acc_fusion, 'ROC-AUC': roc_fusion}\n",
        "])\n",
        "\n",
        "# Add CNN-only\n",
        "with Timer(\"Ablation: CNN Features Only\") as t:\n",
        "    rf_cnn = RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)\n",
        "    rf_cnn.fit(X_train_cnn, train_labels)\n",
        "    pred_cnn = rf_cnn.predict(X_test_cnn)\n",
        "    prob_cnn = rf_cnn.predict_proba(X_test_cnn)[:, 1]\n",
        "\n",
        "f1_cnn = precision_recall_fscore_support(test_labels, pred_cnn, average='binary')[2]\n",
        "acc_cnn = accuracy_score(test_labels, pred_cnn)\n",
        "roc_cnn = roc_auc_score(test_labels, prob_cnn)\n",
        "\n",
        "ablation_df.loc[ablation_df['Configuration'] == 'CNN Only', ['F1', 'Accuracy', 'ROC-AUC']] = [f1_cnn, acc_cnn, roc_cnn]\n",
        "\n",
        "print(ablation_df.to_string(index=False))\n",
        "ablation_df.to_csv('ablation_study.csv', index=False)\n",
        "\n",
        "# ==================== VISUALIZATION 5: ABLATION STUDY ====================\n",
        "print(\"\\nüìä Generating Figure 5: Ablation Study...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart comparison\n",
        "ax = axes[0]\n",
        "configs = ablation_df['Configuration'].values\n",
        "metrics = ['F1', 'Accuracy', 'ROC-AUC']\n",
        "x = np.arange(len(configs))\n",
        "width = 0.25\n",
        "\n",
        "colors = ['#3498db', '#2ecc71', '#f39c12']\n",
        "for i, metric in enumerate(metrics):\n",
        "    values = ablation_df[metric].values\n",
        "    ax.bar(x + i * width - 0.25, values, width, label=metric, color=colors[i], alpha=0.8)\n",
        "\n",
        "ax.set_ylabel('Score', fontweight='bold')\n",
        "ax.set_title('Ablation Study: Component Contributions', fontsize=11, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(configs, rotation=15, ha='right')\n",
        "ax.legend()\n",
        "ax.set_ylim([0.65, 1.0])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Improvement analysis\n",
        "ax = axes[1]\n",
        "baseline_f1 = ablation_df[ablation_df['Configuration'] == 'CNN Only']['F1'].values[0]\n",
        "improvements = ((ablation_df['F1'].values - baseline_f1) / baseline_f1 * 100)\n",
        "\n",
        "colors_bars = ['#3498db' if imp < 0 else '#2ecc71' for imp in improvements]\n",
        "bars = ax.barh(configs, improvements, color=colors_bars, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "ax.set_xlabel('F1 Score Improvement over CNN-Only Baseline (%)', fontweight='bold')\n",
        "ax.set_title('Relative Performance Gains', fontsize=11, fontweight='bold')\n",
        "ax.axvline(0, color='black', linewidth=1.5)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for bar, imp in zip(bars, improvements):\n",
        "    ax.text(imp + 0.5 if imp > 0 else imp - 0.5, bar.get_y() + bar.get_height()/2,\n",
        "            f'{imp:.1f}%', va='center', ha='left' if imp > 0 else 'right', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure5_ablation_study.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# ==================== FINAL SUMMARY ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ PUBLICATION-READY RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nüìä DATASET:\")\n",
        "print(f\"   Total images: {len(all_files)}\")\n",
        "print(f\"   Training: {len(train_files)} | Validation: {len(val_files)} | Test: {len(test_files)}\")\n",
        "\n",
        "print(f\"\\nüèÜ BEST ACCURACY: {results_df['Method'][results_df['F1'].idxmax()]}\")\n",
        "print(f\"   F1: {results_df['F1'].max():.4f}\")\n",
        "print(f\"   Accuracy: {results_df.loc[results_df['F1'].idxmax(), 'Accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\n‚ö° FASTEST METHOD: {results_df['Method'][results_df['Total Pipeline (s)'].idxmin()]}\")\n",
        "print(f\"   Total time: {results_df['Total Pipeline (s)'].min():.1f}s\")\n",
        "\n",
        "print(f\"\\nüéØ ATTENTION FUSION (OURS):\")\n",
        "print(f\"   F1: {f1_fusion:.4f}\")\n",
        "print(f\"   Accuracy: {acc_fusion:.4f}\")\n",
        "print(f\"   ROC-AUC: {roc_fusion:.4f}\")\n",
        "print(f\"   Total time: {fusion_time:.1f}s\")\n",
        "print(f\"   Speedup vs ResNet: {speedup:.1f}√ó\")\n",
        "print(f\"   F1 gap: {(f1_resnet - f1_fusion)*100:.1f}% lower (trade-off for efficiency)\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "757c6d647ead49df917daaca10ad646a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edfa8db32b79495e967721b837f40f51",
              "IPY_MODEL_7f1a6185e31f474cb4b710b33a1a3a92",
              "IPY_MODEL_75a768e3ad9146eabb04da5b2183ce75"
            ],
            "layout": "IPY_MODEL_aa3c26a15cb5424fad219a3c426719d8"
          }
        },
        "edfa8db32b79495e967721b837f40f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2bf467f79246348b60a06f36d52b8a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_04146ddb888b462aa7aa37ebb5897da2",
            "value": "Extracting:‚Äá100%"
          }
        },
        "7f1a6185e31f474cb4b710b33a1a3a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c2b5c1557c4cb289c4ca5eee98a523",
            "max": 12801,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b132f22787aa462ba4bbe674fcf95cd1",
            "value": 12801
          }
        },
        "75a768e3ad9146eabb04da5b2183ce75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8cf584339884d02833d6f77e3885e68",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d8c6c0fbc8654be3868b14ebe54d6e1d",
            "value": "‚Äá12791/12801‚Äá[02:19&lt;00:00,‚Äá119.82it/s]"
          }
        },
        "aa3c26a15cb5424fad219a3c426719d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bd2bf467f79246348b60a06f36d52b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04146ddb888b462aa7aa37ebb5897da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c2b5c1557c4cb289c4ca5eee98a523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b132f22787aa462ba4bbe674fcf95cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8cf584339884d02833d6f77e3885e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c6c0fbc8654be3868b14ebe54d6e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1283ecd6276e4bbc9753d80ce02658ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38ed123c58024264a211a9d1c79d3b5a",
              "IPY_MODEL_d00afb7722e64785a455029afadb9d15",
              "IPY_MODEL_450d512bca5a40d2bb7e467d4128c6d9"
            ],
            "layout": "IPY_MODEL_a1ac874fbfc74bd190706dc61f681da0"
          }
        },
        "38ed123c58024264a211a9d1c79d3b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ecfb5672232469ba70dc4611962e815",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f396ea2fa30745f7930efca5c5a954a2",
            "value": "Extracting:‚Äá100%"
          }
        },
        "d00afb7722e64785a455029afadb9d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56d74352f5d41068c60ddfb7442c189",
            "max": 2743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39a01b7f66f14ad09bc2090438c65be4",
            "value": 2743
          }
        },
        "450d512bca5a40d2bb7e467d4128c6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698c35c262374596827e58136758b6dd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_71183fd4eb4f418e956ac04738302241",
            "value": "‚Äá2732/2743‚Äá[00:25&lt;00:00,‚Äá121.80it/s]"
          }
        },
        "a1ac874fbfc74bd190706dc61f681da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5ecfb5672232469ba70dc4611962e815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f396ea2fa30745f7930efca5c5a954a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c56d74352f5d41068c60ddfb7442c189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a01b7f66f14ad09bc2090438c65be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "698c35c262374596827e58136758b6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71183fd4eb4f418e956ac04738302241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68952de3c0254b1a9967ac4ee1c6f138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cf22c8e581641a68b65d65bcd99b0d9",
              "IPY_MODEL_6299be7194474c33bf2690ca911d34f2",
              "IPY_MODEL_3df8bd136af144af81e8ccb0807f7e18"
            ],
            "layout": "IPY_MODEL_08a0e787a0f9457c9a73f8cffe21d335"
          }
        },
        "3cf22c8e581641a68b65d65bcd99b0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cc8a60a00c40939e1f816e7e9c3344",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b6fe623e1f3246d79e19bcb4a6fb5185",
            "value": "Extracting:‚Äá100%"
          }
        },
        "6299be7194474c33bf2690ca911d34f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e873f03416448d98277a4fd00832053",
            "max": 2744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7e89682e0b4047b420db18727fe0ef",
            "value": 2744
          }
        },
        "3df8bd136af144af81e8ccb0807f7e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f520b5c58f8942cdb34839de247a48ab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_762ce4a317b44501b1e07c1df25b1332",
            "value": "‚Äá2734/2744‚Äá[00:25&lt;00:00,‚Äá118.25it/s]"
          }
        },
        "08a0e787a0f9457c9a73f8cffe21d335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "38cc8a60a00c40939e1f816e7e9c3344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6fe623e1f3246d79e19bcb4a6fb5185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e873f03416448d98277a4fd00832053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7e89682e0b4047b420db18727fe0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f520b5c58f8942cdb34839de247a48ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762ce4a317b44501b1e07c1df25b1332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbb805da57404e0c8030d08c51c5d004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3dec54687904123a3976970b8120b95",
              "IPY_MODEL_4e5a53f96fa54832bed32e62f0fffeec",
              "IPY_MODEL_777f4e83c6624c119afa2cce85b4e69b"
            ],
            "layout": "IPY_MODEL_b012ab92b58f424b87d80f2922bd1b3d"
          }
        },
        "d3dec54687904123a3976970b8120b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5290515b2a684ddfa34910d94969d9e7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3a9a508ff1f6411385772de5f870c88b",
            "value": "CNN‚Äáfeatures:‚Äá100%"
          }
        },
        "4e5a53f96fa54832bed32e62f0fffeec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd7232a239eb42729fd3d44dad372afe",
            "max": 801,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54de28d25d5642a397d354389e28cb0b",
            "value": 801
          }
        },
        "777f4e83c6624c119afa2cce85b4e69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea78c87e65d9444980c31234d80d4666",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_51ed5a2cc30b4e0bb6d6b2072d3583ba",
            "value": "‚Äá801/801‚Äá[00:57&lt;00:00,‚Äá15.10it/s]"
          }
        },
        "b012ab92b58f424b87d80f2922bd1b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5290515b2a684ddfa34910d94969d9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9a508ff1f6411385772de5f870c88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd7232a239eb42729fd3d44dad372afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54de28d25d5642a397d354389e28cb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea78c87e65d9444980c31234d80d4666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ed5a2cc30b4e0bb6d6b2072d3583ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0fd583284cd4ad9abc948ec3c305914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f19e61a4ffbc40b1ba1ad984c895ccfa",
              "IPY_MODEL_fb5e4e8785fb485dad53d5109bb2ae75",
              "IPY_MODEL_71cd42b76f8c4f3392491229fcf9255f"
            ],
            "layout": "IPY_MODEL_d047b2a702964bf7ab58cde5b8e0ed7d"
          }
        },
        "f19e61a4ffbc40b1ba1ad984c895ccfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1392b1b0d025460fb6e258451109cc7b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_039da1af6cb34bd3ae8bc0405a32f410",
            "value": "CNN‚Äáfeatures:‚Äá100%"
          }
        },
        "fb5e4e8785fb485dad53d5109bb2ae75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55b239b200a46f29f8f1abe304fec6f",
            "max": 172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec1de6c9514d45f39661655dcafe6dc3",
            "value": 172
          }
        },
        "71cd42b76f8c4f3392491229fcf9255f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1590b664df4479bcb11e7892e23f02",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aa3e7e3887e64971ba544caa61af269e",
            "value": "‚Äá172/172‚Äá[00:12&lt;00:00,‚Äá15.67it/s]"
          }
        },
        "d047b2a702964bf7ab58cde5b8e0ed7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1392b1b0d025460fb6e258451109cc7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "039da1af6cb34bd3ae8bc0405a32f410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c55b239b200a46f29f8f1abe304fec6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1de6c9514d45f39661655dcafe6dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d1590b664df4479bcb11e7892e23f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa3e7e3887e64971ba544caa61af269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0993baf42f934e7cb2e3c41f6d454ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d142c411b0c4890874d9861a3b6588c",
              "IPY_MODEL_a457a4bf5cf7442590616f59079fe848",
              "IPY_MODEL_cc2a866b2a5e4ce8a4ba904916539a82"
            ],
            "layout": "IPY_MODEL_fada76e1257e4df79f519af196afadaf"
          }
        },
        "6d142c411b0c4890874d9861a3b6588c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1175f26ea04441aa367e88e4ef11b2f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_49e0b19bb1ec48fd9c729b6d31ba0f87",
            "value": "CNN‚Äáfeatures:‚Äá100%"
          }
        },
        "a457a4bf5cf7442590616f59079fe848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a49b8a01aa8473aa67dc1b3a4c562d5",
            "max": 172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08d6d564008e492ba1c348c466bbe526",
            "value": 172
          }
        },
        "cc2a866b2a5e4ce8a4ba904916539a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfea11bb5170491591febe28a9a22b02",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_45dcd0f2eca54db684edfc9efc1ae949",
            "value": "‚Äá172/172‚Äá[00:12&lt;00:00,‚Äá15.63it/s]"
          }
        },
        "fada76e1257e4df79f519af196afadaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b1175f26ea04441aa367e88e4ef11b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e0b19bb1ec48fd9c729b6d31ba0f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a49b8a01aa8473aa67dc1b3a4c562d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d6d564008e492ba1c348c466bbe526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfea11bb5170491591febe28a9a22b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45dcd0f2eca54db684edfc9efc1ae949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}