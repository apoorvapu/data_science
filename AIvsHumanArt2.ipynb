{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8cud3T7imbjCfxmjw/DHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorvapu/data_science/blob/main/AIvsHumanArt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Latent Aesthetics: Comparing AI-Generated Art and Human Artworks Using CLIP Embeddings\n",
        "Complete analysis pipeline for publication-ready results\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, silhouette_score, adjusted_rand_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "# Handle optional imports\n",
        "try:\n",
        "    import umap\n",
        "    UMAP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"UMAP not available. Install with: pip install umap-learn\")\n",
        "    UMAP_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    import clip\n",
        "    from PIL import Image\n",
        "    CLIP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"CLIP not available. Install with: pip install ftfy regex tqdm\")\n",
        "    print(\"pip install git+https://github.com/openai/CLIP.git\")\n",
        "    CLIP_AVAILABLE = False\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Configure matplotlib for publication-quality figures\n",
        "plt.rcParams.update({\n",
        "    'figure.figsize': (12, 8),\n",
        "    'font.size': 12,\n",
        "    'axes.titlesize': 14,\n",
        "    'axes.labelsize': 12,\n",
        "    'xtick.labelsize': 10,\n",
        "    'ytick.labelsize': 10,\n",
        "    'legend.fontsize': 11,\n",
        "    'figure.titlesize': 16,\n",
        "    'font.family': 'serif',\n",
        "    'figure.dpi': 300,\n",
        "    'savefig.dpi': 300,\n",
        "    'savefig.bbox': 'tight'\n",
        "})\n",
        "\n",
        "class LatentAestheticsAnalyzer:\n",
        "    \"\"\"\n",
        "    Comprehensive analysis pipeline for comparing AI-generated and human artworks\n",
        "    using CLIP embeddings and advanced statistical methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "        self.device = device\n",
        "        self.embeddings = None\n",
        "        self.metadata = None\n",
        "        self.results = {}\n",
        "\n",
        "        if CLIP_AVAILABLE:\n",
        "            try:\n",
        "                self.model, self.preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "                print(f\"CLIP model loaded successfully on {device}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading CLIP model: {e}\")\n",
        "                print(\"Using synthetic embeddings for demonstration\")\n",
        "                self.model = None\n",
        "                self.preprocess = None\n",
        "        else:\n",
        "            print(\"CLIP not available. Using synthetic embeddings for demonstration\")\n",
        "            self.model = None\n",
        "            self.preprocess = None\n",
        "\n",
        "    def load_and_process_images(self, data_config):\n",
        "        \"\"\"\n",
        "        Load images and extract CLIP embeddings with comprehensive metadata tracking.\n",
        "\n",
        "        Args:\n",
        "            data_config: Dictionary containing paths and metadata for human and AI artworks\n",
        "        \"\"\"\n",
        "        all_embeddings = []\n",
        "        all_metadata = []\n",
        "\n",
        "        print(\"Loading and processing human artworks...\")\n",
        "        for movement, artworks in data_config['human_art'].items():\n",
        "            for artwork_path in artworks:\n",
        "                try:\n",
        "                    image = Image.open(artwork_path).convert('RGB')\n",
        "                    embedding = self._extract_clip_embedding(image)\n",
        "                    all_embeddings.append(embedding)\n",
        "                    all_metadata.append({\n",
        "                        'source': 'human',\n",
        "                        'movement': movement,\n",
        "                        'model': 'human',\n",
        "                        'path': artwork_path,\n",
        "                        'filename': os.path.basename(artwork_path)\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {artwork_path}: {e}\")\n",
        "\n",
        "        print(\"Loading and processing AI-generated artworks...\")\n",
        "        for model_name, artworks in data_config['ai_art'].items():\n",
        "            for artwork_path in artworks:\n",
        "                try:\n",
        "                    image = Image.open(artwork_path).convert('RGB')\n",
        "                    embedding = self._extract_clip_embedding(image)\n",
        "                    all_embeddings.append(embedding)\n",
        "                    all_metadata.append({\n",
        "                        'source': 'ai',\n",
        "                        'movement': 'ai_generated',\n",
        "                        'model': model_name,\n",
        "                        'path': artwork_path,\n",
        "                        'filename': os.path.basename(artwork_path)\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {artwork_path}: {e}\")\n",
        "\n",
        "        self.embeddings = np.array(all_embeddings)\n",
        "        self.metadata = pd.DataFrame(all_metadata)\n",
        "\n",
        "        # Normalize embeddings to unit length for cosine similarity\n",
        "        self.embeddings = self.embeddings / np.linalg.norm(self.embeddings, axis=1, keepdims=True)\n",
        "\n",
        "        print(f\"Successfully processed {len(self.embeddings)} artworks\")\n",
        "        print(f\"Human artworks: {sum(self.metadata['source'] == 'human')}\")\n",
        "        print(f\"AI artworks: {sum(self.metadata['source'] == 'ai')}\")\n",
        "\n",
        "    def _extract_clip_embedding(self, image):\n",
        "        \"\"\"Extract CLIP embedding for a single image.\"\"\"\n",
        "        if self.model is None:\n",
        "            # Return synthetic embedding if CLIP not available\n",
        "            return np.random.randn(512) / np.sqrt(512)\n",
        "\n",
        "        if CLIP_AVAILABLE and hasattr(image, 'convert'):\n",
        "            image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                embedding = self.model.encode_image(image_input)\n",
        "                embedding = embedding / embedding.norm(dim=-1, keepdim=True)\n",
        "            return embedding.cpu().numpy().flatten()\n",
        "        else:\n",
        "            # Fallback for demonstration\n",
        "            return np.random.randn(512) / np.sqrt(512)\n",
        "\n",
        "    def compute_aesthetic_distinctiveness_index(self, group1_mask, group2_mask):\n",
        "        \"\"\"\n",
        "        Compute the Aesthetic Distinctiveness Index (ADI) between two groups.\n",
        "\n",
        "        ADI = (μ_inter - μ_intra) / (σ_inter + σ_intra)\n",
        "        \"\"\"\n",
        "        # Intra-group distances\n",
        "        group1_embeddings = self.embeddings[group1_mask]\n",
        "        group2_embeddings = self.embeddings[group2_mask]\n",
        "\n",
        "        intra_distances_1 = pdist(group1_embeddings, metric='cosine')\n",
        "        intra_distances_2 = pdist(group2_embeddings, metric='cosine')\n",
        "        intra_distances = np.concatenate([intra_distances_1, intra_distances_2])\n",
        "\n",
        "        # Inter-group distances\n",
        "        inter_distances = []\n",
        "        for i, emb1 in enumerate(group1_embeddings):\n",
        "            for j, emb2 in enumerate(group2_embeddings):\n",
        "                dist = 1 - np.dot(emb1, emb2)  # cosine distance\n",
        "                inter_distances.append(dist)\n",
        "        inter_distances = np.array(inter_distances)\n",
        "\n",
        "        # Compute ADI\n",
        "        mu_inter = np.mean(inter_distances)\n",
        "        mu_intra = np.mean(intra_distances)\n",
        "        sigma_inter = np.std(inter_distances)\n",
        "        sigma_intra = np.std(intra_distances)\n",
        "\n",
        "        adi = (mu_inter - mu_intra) / (sigma_inter + sigma_intra)\n",
        "\n",
        "        return adi, {\n",
        "            'mu_inter': mu_inter,\n",
        "            'mu_intra': mu_intra,\n",
        "            'sigma_inter': sigma_inter,\n",
        "            'sigma_intra': sigma_intra,\n",
        "            'n_inter': len(inter_distances),\n",
        "            'n_intra': len(intra_distances)\n",
        "        }\n",
        "\n",
        "    def compute_cross_style_affinity_score(self, ai_mask, movement_weights=None):\n",
        "        \"\"\"Compute Cross-Style Affinity Score (CSAS) for AI artworks.\"\"\"\n",
        "        if movement_weights is None:\n",
        "            movement_weights = {mov: 1.0 for mov in self.metadata['movement'].unique() if mov != 'ai_generated'}\n",
        "\n",
        "        ai_embeddings = self.embeddings[ai_mask]\n",
        "        csas_scores = {}\n",
        "\n",
        "        for movement in movement_weights.keys():\n",
        "            movement_mask = self.metadata['movement'] == movement\n",
        "            movement_embeddings = self.embeddings[movement_mask]\n",
        "\n",
        "            if len(movement_embeddings) == 0:\n",
        "                continue\n",
        "\n",
        "            similarities = []\n",
        "            for ai_emb in ai_embeddings:\n",
        "                # Compute similarity to movement centroid\n",
        "                movement_centroid = np.mean(movement_embeddings, axis=0)\n",
        "                similarity = np.dot(ai_emb, movement_centroid)\n",
        "                similarities.append(similarity)\n",
        "\n",
        "            weighted_score = np.mean(similarities) * movement_weights[movement]\n",
        "            csas_scores[movement] = weighted_score\n",
        "\n",
        "        return csas_scores\n",
        "\n",
        "    def perform_dimensionality_reduction(self):\n",
        "        \"\"\"Apply multiple dimensionality reduction techniques.\"\"\"\n",
        "        print(\"Performing dimensionality reduction...\")\n",
        "\n",
        "        # PCA\n",
        "        print(\"  Computing PCA...\")\n",
        "        pca = PCA(n_components=2)\n",
        "        pca_embeddings = pca.fit_transform(self.embeddings)\n",
        "\n",
        "        # t-SNE\n",
        "        print(\"  Computing t-SNE...\")\n",
        "        tsne = TSNE(n_components=2, perplexity=50, learning_rate=500,\n",
        "                   random_state=42, n_iter=5000)\n",
        "        tsne_embeddings = tsne.fit_transform(self.embeddings)\n",
        "\n",
        "        # UMAP\n",
        "        if UMAP_AVAILABLE:\n",
        "            print(\"  Computing UMAP...\")\n",
        "            umap_reducer = umap.UMAP(n_neighbors=30, min_dist=0.1,\n",
        "                                    metric='cosine', random_state=42)\n",
        "            umap_embeddings = umap_reducer.fit_transform(self.embeddings)\n",
        "        else:\n",
        "            print(\"  UMAP not available, using PCA as fallback...\")\n",
        "            pca_fallback = PCA(n_components=2, random_state=42)\n",
        "            umap_embeddings = pca_fallback.fit_transform(self.embeddings)\n",
        "            umap_reducer = pca_fallback\n",
        "\n",
        "        self.results['dimensionality_reduction'] = {\n",
        "            'pca': {\n",
        "                'embeddings': pca_embeddings,\n",
        "                'explained_variance_ratio': pca.explained_variance_ratio_,\n",
        "                'components': pca.components_\n",
        "            },\n",
        "            'tsne': {\n",
        "                'embeddings': tsne_embeddings,\n",
        "                'kl_divergence': tsne.kl_divergence_\n",
        "            },\n",
        "            'umap': {\n",
        "                'embeddings': umap_embeddings,\n",
        "                'reducer': umap_reducer\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # PCA for 95% variance\n",
        "        pca_full = PCA(n_components=0.95)\n",
        "        pca_full.fit(self.embeddings)\n",
        "        self.results['pca_95_components'] = pca_full.n_components_\n",
        "\n",
        "    def perform_clustering_analysis(self):\n",
        "        \"\"\"Comprehensive clustering analysis with multiple algorithms.\"\"\"\n",
        "        print(\"Performing clustering analysis...\")\n",
        "\n",
        "        # Binary labels for validation\n",
        "        y_true = (self.metadata['source'] == 'ai').astype(int)\n",
        "\n",
        "        # K-means clustering\n",
        "        print(\"  K-means clustering...\")\n",
        "        kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "        kmeans_labels = kmeans.fit_predict(self.embeddings)\n",
        "\n",
        "        # Hierarchical clustering\n",
        "        print(\"  Hierarchical clustering...\")\n",
        "        linkage_matrix = linkage(self.embeddings, method='ward')\n",
        "\n",
        "        # DBSCAN\n",
        "        print(\"  DBSCAN clustering...\")\n",
        "        # Optimize epsilon using k-distance plot\n",
        "        distances = []\n",
        "        for i in range(len(self.embeddings)):\n",
        "            dist_to_others = np.sort(np.linalg.norm(self.embeddings - self.embeddings[i], axis=1))[1:6]\n",
        "            distances.append(np.mean(dist_to_others))\n",
        "        epsilon = np.percentile(distances, 95)\n",
        "\n",
        "        dbscan = DBSCAN(eps=epsilon, min_samples=5)\n",
        "        dbscan_labels = dbscan.fit_predict(self.embeddings)\n",
        "\n",
        "        # Gaussian Mixture Model\n",
        "        print(\"  Gaussian Mixture Model...\")\n",
        "        # Model selection using BIC\n",
        "        bic_scores = []\n",
        "        n_components_range = range(1, 8)\n",
        "        for n_components in n_components_range:\n",
        "            gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
        "            gmm.fit(self.embeddings)\n",
        "            bic_scores.append(gmm.bic(self.embeddings))\n",
        "\n",
        "        optimal_components = n_components_range[np.argmin(bic_scores)]\n",
        "        gmm = GaussianMixture(n_components=optimal_components, random_state=42)\n",
        "        gmm_labels = gmm.fit_predict(self.embeddings)\n",
        "\n",
        "        # Compute clustering metrics\n",
        "        clustering_results = {\n",
        "            'kmeans': {\n",
        "                'labels': kmeans_labels,\n",
        "                'silhouette_score': silhouette_score(self.embeddings, kmeans_labels),\n",
        "                'ari': adjusted_rand_score(y_true, kmeans_labels),\n",
        "                'accuracy': np.mean((kmeans_labels == y_true)) if len(np.unique(kmeans_labels)) == 2 else None\n",
        "            },\n",
        "            'hierarchical': {\n",
        "                'linkage_matrix': linkage_matrix,\n",
        "                'cophenetic_corr': stats.pearsonr(pdist(self.embeddings),\n",
        "                                                 linkage_matrix[:, 2])[0]\n",
        "            },\n",
        "            'dbscan': {\n",
        "                'labels': dbscan_labels,\n",
        "                'n_clusters': len(np.unique(dbscan_labels[dbscan_labels != -1])),\n",
        "                'noise_ratio': np.sum(dbscan_labels == -1) / len(dbscan_labels),\n",
        "                'silhouette_score': silhouette_score(self.embeddings, dbscan_labels)\n",
        "                                  if len(np.unique(dbscan_labels)) > 1 else 0\n",
        "            },\n",
        "            'gmm': {\n",
        "                'labels': gmm_labels,\n",
        "                'n_components': optimal_components,\n",
        "                'bic_scores': bic_scores,\n",
        "                'aic': gmm.aic(self.embeddings),\n",
        "                'bic': gmm.bic(self.embeddings)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.results['clustering'] = clustering_results\n",
        "\n",
        "    def analyze_model_signatures(self):\n",
        "        \"\"\"Analyze model-specific aesthetic signatures.\"\"\"\n",
        "        print(\"Analyzing model-specific signatures...\")\n",
        "\n",
        "        ai_mask = self.metadata['source'] == 'ai'\n",
        "        ai_embeddings = self.embeddings[ai_mask]\n",
        "        ai_models = self.metadata[ai_mask]['model'].values\n",
        "\n",
        "        if len(np.unique(ai_models)) < 2:\n",
        "            print(\"Insufficient AI model diversity for signature analysis\")\n",
        "            return\n",
        "\n",
        "        # Multi-class classification between AI models\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            ai_embeddings, ai_models, test_size=0.3, random_state=42, stratify=ai_models\n",
        "        )\n",
        "\n",
        "        svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "        svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "        accuracy = svm_classifier.score(X_test, y_test)\n",
        "        predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "        # Cross-validation\n",
        "        cv_scores = cross_val_score(svm_classifier, ai_embeddings, ai_models, cv=5)\n",
        "\n",
        "        # Feature importance (SVM weights)\n",
        "        feature_importance = np.abs(svm_classifier.coef_).mean(axis=0)\n",
        "\n",
        "        self.results['model_signatures'] = {\n",
        "            'accuracy': accuracy,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'classification_report': classification_report(y_test, predictions, output_dict=True),\n",
        "            'feature_importance': feature_importance,\n",
        "            'top_features': np.argsort(feature_importance)[-20:][::-1]\n",
        "        }\n",
        "\n",
        "    def analyze_movement_relationships(self):\n",
        "        \"\"\"Analyze relationships between AI art and human artistic movements.\"\"\"\n",
        "        print(\"Analyzing movement relationships...\")\n",
        "\n",
        "        human_mask = self.metadata['source'] == 'human'\n",
        "        ai_mask = self.metadata['source'] == 'ai'\n",
        "\n",
        "        human_movements = self.metadata[human_mask]['movement'].unique()\n",
        "        ai_embeddings = self.embeddings[ai_mask]\n",
        "\n",
        "        movement_similarities = {}\n",
        "        movement_centroids = {}\n",
        "\n",
        "        # Compute movement centroids and similarities\n",
        "        for movement in human_movements:\n",
        "            movement_mask = (self.metadata['movement'] == movement) & human_mask\n",
        "            movement_embeddings = self.embeddings[movement_mask]\n",
        "\n",
        "            if len(movement_embeddings) == 0:\n",
        "                continue\n",
        "\n",
        "            centroid = np.mean(movement_embeddings, axis=0)\n",
        "            movement_centroids[movement] = centroid\n",
        "\n",
        "            # Compute similarities between AI art and this movement\n",
        "            similarities = []\n",
        "            for ai_emb in ai_embeddings:\n",
        "                similarity = np.dot(ai_emb, centroid)\n",
        "                similarities.append(similarity)\n",
        "\n",
        "            movement_similarities[movement] = {\n",
        "                'mean_similarity': np.mean(similarities),\n",
        "                'std_similarity': np.std(similarities),\n",
        "                'similarities': similarities\n",
        "            }\n",
        "\n",
        "        # Compute Cross-Style Affinity Scores\n",
        "        csas_scores = self.compute_cross_style_affinity_score(ai_mask)\n",
        "\n",
        "        # Temporal bias analysis\n",
        "        movement_years = {\n",
        "            'Renaissance': 1500,\n",
        "            'Baroque': 1650,\n",
        "            'Impressionism': 1870,\n",
        "            'Post-Impressionism': 1885,\n",
        "            'Cubism': 1910,\n",
        "            'Abstract Expressionism': 1945,\n",
        "            'Surrealism': 1925,\n",
        "            'Contemporary': 1980\n",
        "        }\n",
        "\n",
        "        temporal_correlations = []\n",
        "        for movement, year in movement_years.items():\n",
        "            if movement in movement_similarities:\n",
        "                similarity = movement_similarities[movement]['mean_similarity']\n",
        "                temporal_correlations.append((year, similarity))\n",
        "\n",
        "        if len(temporal_correlations) > 2:\n",
        "            years, similarities = zip(*temporal_correlations)\n",
        "            temporal_corr, temporal_p = stats.pearsonr(years, similarities)\n",
        "        else:\n",
        "            temporal_corr, temporal_p = None, None\n",
        "\n",
        "        self.results['movement_analysis'] = {\n",
        "            'movement_similarities': movement_similarities,\n",
        "            'movement_centroids': movement_centroids,\n",
        "            'csas_scores': csas_scores,\n",
        "            'temporal_correlation': temporal_corr,\n",
        "            'temporal_p_value': temporal_p,\n",
        "            'temporal_data': temporal_correlations\n",
        "        }\n",
        "\n",
        "    def compute_statistical_comparisons(self):\n",
        "        \"\"\"Comprehensive statistical analysis with effect sizes.\"\"\"\n",
        "        print(\"Computing statistical comparisons...\")\n",
        "\n",
        "        human_mask = self.metadata['source'] == 'human'\n",
        "        ai_mask = self.metadata['source'] == 'ai'\n",
        "\n",
        "        # Compute ADI\n",
        "        adi, adi_details = self.compute_aesthetic_distinctiveness_index(human_mask, ai_mask)\n",
        "\n",
        "        # Intra-group similarity analysis\n",
        "        human_embeddings = self.embeddings[human_mask]\n",
        "        ai_embeddings = self.embeddings[ai_mask]\n",
        "\n",
        "        # Compute pairwise similarities within groups\n",
        "        human_similarities = []\n",
        "        for i in range(len(human_embeddings)):\n",
        "            for j in range(i+1, len(human_embeddings)):\n",
        "                sim = np.dot(human_embeddings[i], human_embeddings[j])\n",
        "                human_similarities.append(sim)\n",
        "\n",
        "        ai_similarities = []\n",
        "        for i in range(len(ai_embeddings)):\n",
        "            for j in range(i+1, len(ai_embeddings)):\n",
        "                sim = np.dot(ai_embeddings[i], ai_embeddings[j])\n",
        "                ai_similarities.append(sim)\n",
        "\n",
        "        # Statistical tests\n",
        "        mannwhitney_stat, mannwhitney_p = stats.mannwhitneyu(\n",
        "            human_similarities, ai_similarities, alternative='two-sided'\n",
        "        )\n",
        "\n",
        "        # Effect size (Cohen's d)\n",
        "        pooled_std = np.sqrt(((len(human_similarities)-1)*np.var(human_similarities) +\n",
        "                             (len(ai_similarities)-1)*np.var(ai_similarities)) /\n",
        "                            (len(human_similarities) + len(ai_similarities) - 2))\n",
        "        cohens_d = (np.mean(human_similarities) - np.mean(ai_similarities)) / pooled_std\n",
        "\n",
        "        self.results['statistical_analysis'] = {\n",
        "            'adi': adi,\n",
        "            'adi_details': adi_details,\n",
        "            'human_similarity_stats': {\n",
        "                'mean': np.mean(human_similarities),\n",
        "                'std': np.std(human_similarities),\n",
        "                'median': np.median(human_similarities),\n",
        "                'n': len(human_similarities)\n",
        "            },\n",
        "            'ai_similarity_stats': {\n",
        "                'mean': np.mean(ai_similarities),\n",
        "                'std': np.std(ai_similarities),\n",
        "                'median': np.median(ai_similarities),\n",
        "                'n': len(ai_similarities)\n",
        "            },\n",
        "            'mannwhitney_test': {\n",
        "                'statistic': mannwhitney_stat,\n",
        "                'p_value': mannwhitney_p\n",
        "            },\n",
        "            'effect_size': {\n",
        "                'cohens_d': cohens_d,\n",
        "                'interpretation': self._interpret_effect_size(cohens_d)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _interpret_effect_size(self, d):\n",
        "        \"\"\"Interpret Cohen's d effect size.\"\"\"\n",
        "        abs_d = abs(d)\n",
        "        if abs_d < 0.2:\n",
        "            return \"negligible\"\n",
        "        elif abs_d < 0.5:\n",
        "            return \"small\"\n",
        "        elif abs_d < 0.8:\n",
        "            return \"medium\"\n",
        "        else:\n",
        "            return \"large\"\n",
        "\n",
        "    def generate_publication_figures(self, output_dir=\"figures\"):\n",
        "        \"\"\"Generate all publication-quality figures.\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Figure 1: Dimensionality reduction visualization\n",
        "        self._plot_dimensionality_reduction(output_dir)\n",
        "\n",
        "        # Figure 2: Clustering analysis\n",
        "        self._plot_clustering_analysis(output_dir)\n",
        "\n",
        "        # Figure 3: Model signature analysis\n",
        "        self._plot_model_signatures(output_dir)\n",
        "\n",
        "        # Figure 4: Movement relationship analysis\n",
        "        self._plot_movement_relationships(output_dir)\n",
        "\n",
        "        # Figure 5: Statistical analysis summary\n",
        "        self._plot_statistical_summary(output_dir)\n",
        "\n",
        "        # Figure 6: PCA component analysis\n",
        "        self._plot_pca_components(output_dir)\n",
        "\n",
        "    def _plot_dimensionality_reduction(self, output_dir):\n",
        "        \"\"\"Create Figure 1: Dimensionality reduction visualization.\"\"\"\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "        # Color mapping\n",
        "        color_map = {\n",
        "            'human': '#1f77b4',\n",
        "            'ai': '#ff7f0e'\n",
        "        }\n",
        "\n",
        "        colors = [color_map[source] for source in self.metadata['source']]\n",
        "\n",
        "        # PCA plot\n",
        "        pca_data = self.results['dimensionality_reduction']['pca']['embeddings']\n",
        "        axes[0].scatter(pca_data[:, 0], pca_data[:, 1], c=colors, alpha=0.7, s=50)\n",
        "        axes[0].set_title('PCA Projection')\n",
        "        axes[0].set_xlabel(f'PC1 ({self.results[\"dimensionality_reduction\"][\"pca\"][\"explained_variance_ratio\"][0]:.1%} variance)')\n",
        "        axes[0].set_ylabel(f'PC2 ({self.results[\"dimensionality_reduction\"][\"pca\"][\"explained_variance_ratio\"][1]:.1%} variance)')\n",
        "\n",
        "        # t-SNE plot\n",
        "        tsne_data = self.results['dimensionality_reduction']['tsne']['embeddings']\n",
        "        axes[1].scatter(tsne_data[:, 0], tsne_data[:, 1], c=colors, alpha=0.7, s=50)\n",
        "        axes[1].set_title('t-SNE Projection')\n",
        "        axes[1].set_xlabel('t-SNE 1')\n",
        "        axes[1].set_ylabel('t-SNE 2')\n",
        "\n",
        "        # UMAP plot\n",
        "        umap_data = self.results['dimensionality_reduction']['umap']['embeddings']\n",
        "        axes[2].scatter(umap_data[:, 0], umap_data[:, 1], c=colors, alpha=0.7, s=50)\n",
        "        axes[2].set_title('UMAP Projection')\n",
        "        axes[2].set_xlabel('UMAP 1')\n",
        "        axes[2].set_ylabel('UMAP 2')\n",
        "\n",
        "        # Add legend\n",
        "        from matplotlib.patches import Patch\n",
        "        legend_elements = [Patch(facecolor='#1f77b4', label='Human Art'),\n",
        "                          Patch(facecolor='#ff7f0e', label='AI Art')]\n",
        "        fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=2)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/figure1_dimensionality_reduction.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.savefig(f\"{output_dir}/figure1_dimensionality_reduction.pdf\", bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_clustering_analysis(self, output_dir):\n",
        "        \"\"\"Create Figure 2: Clustering analysis.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # K-means results\n",
        "        kmeans_labels = self.results['clustering']['kmeans']['labels']\n",
        "        tsne_data = self.results['dimensionality_reduction']['tsne']['embeddings']\n",
        "\n",
        "        scatter = axes[0,0].scatter(tsne_data[:, 0], tsne_data[:, 1],\n",
        "                                  c=kmeans_labels, cmap='Set1', alpha=0.7, s=50)\n",
        "        axes[0,0].set_title(f'K-means Clustering (Silhouette: {self.results[\"clustering\"][\"kmeans\"][\"silhouette_score\"]:.3f})')\n",
        "        axes[0,0].set_xlabel('t-SNE 1')\n",
        "        axes[0,0].set_ylabel('t-SNE 2')\n",
        "\n",
        "        # DBSCAN results\n",
        "        dbscan_labels = self.results['clustering']['dbscan']['labels']\n",
        "        scatter = axes[0,1].scatter(tsne_data[:, 0], tsne_data[:, 1],\n",
        "                                  c=dbscan_labels, cmap='viridis', alpha=0.7, s=50)\n",
        "        axes[0,1].set_title(f'DBSCAN Clustering ({self.results[\"clustering\"][\"dbscan\"][\"n_clusters\"]} clusters)')\n",
        "        axes[0,1].set_xlabel('t-SNE 1')\n",
        "        axes[0,1].set_ylabel('t-SNE 2')\n",
        "\n",
        "        # Hierarchical clustering dendrogram\n",
        "        dendrogram(self.results['clustering']['hierarchical']['linkage_matrix'],\n",
        "                  ax=axes[1,0], truncate_mode='level', p=5)\n",
        "        axes[1,0].set_title('Hierarchical Clustering Dendrogram')\n",
        "\n",
        "        # GMM BIC scores\n",
        "        bic_scores = self.results['clustering']['gmm']['bic_scores']\n",
        "        axes[1,1].plot(range(1, len(bic_scores)+1), bic_scores, 'bo-')\n",
        "        axes[1,1].set_title('GMM Model Selection (BIC)')\n",
        "        axes[1,1].set_xlabel('Number of Components')\n",
        "        axes[1,1].set_ylabel('BIC Score')\n",
        "        axes[1,1].axvline(x=self.results['clustering']['gmm']['n_components'],\n",
        "                         color='red', linestyle='--', label='Optimal')\n",
        "        axes[1,1].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/figure2_clustering_analysis.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.savefig(f\"{output_dir}/figure2_clustering_analysis.pdf\", bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_model_signatures(self, output_dir):\n",
        "        \"\"\"Create Figure 3: Model signature analysis.\"\"\"\n",
        "        if 'model_signatures' not in self.results:\n",
        "            print(\"Model signature analysis not available\")\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # Model distribution in t-SNE space\n",
        "        ai_mask = self.metadata['source'] == 'ai'\n",
        "        ai_metadata = self.metadata[ai_mask]\n",
        "        tsne_data = self.results['dimensionality_reduction']['tsne']['embeddings'][ai_mask]\n",
        "\n",
        "        unique_models = ai_metadata['model'].unique()\n",
        "        colors = plt.cm.Set1(np.linspace(0, 1, len(unique_models)))\n",
        "\n",
        "        for i, model in enumerate(unique_models):\n",
        "            model_mask = ai_metadata['model'] == model\n",
        "            model_data = tsne_data[model_mask]\n",
        "            axes[0,0].scatter(model_data[:, 0], model_data[:, 1],\n",
        "                            c=[colors[i]], label=model, alpha=0.7, s=60)\n",
        "\n",
        "        axes[0,0].set_title('AI Model Distribution in t-SNE Space')\n",
        "        axes[0,0].set_xlabel('t-SNE 1')\n",
        "        axes[0,0].set_ylabel('t-SNE 2')\n",
        "        axes[0,0].legend()\n",
        "\n",
        "        # Feature importance\n",
        "        feature_importance = self.results['model_signatures']['feature_importance']\n",
        "        top_features = self.results['model_signatures']['top_features'][:10]\n",
        "\n",
        "        axes[0,1].bar(range(len(top_features)), feature_importance[top_features])\n",
        "        axes[0,1].set_title('Top Discriminative Features')\n",
        "        axes[0,1].set_xlabel('Feature Index')\n",
        "        axes[0,1].set_ylabel('Importance Score')\n",
        "        axes[0,1].set_xticks(range(len(top_features)))\n",
        "        axes[0,1].set_xticklabels(top_features, rotation=45)\n",
        "\n",
        "        # Classification accuracy\n",
        "        cv_scores = [self.results['model_signatures']['cv_mean']]\n",
        "        cv_stds = [self.results['model_signatures']['cv_std']]\n",
        "\n",
        "        axes[1,0].bar(['Model Classification'], cv_scores, yerr=cv_stds, capsize=5)\n",
        "        axes[1,0].set_title('Cross-Validation Accuracy')\n",
        "        axes[1,0].set_ylabel('Accuracy')\n",
        "        axes[1,0].set_ylim(0, 1)\n",
        "\n",
        "        # Model similarity matrix\n",
        "        ai_embeddings = self.embeddings[ai_mask]\n",
        "        model_names = ai_metadata['model'].values\n",
        "\n",
        "        unique_models = list(set(model_names))\n",
        "        similarity_matrix = np.zeros((len(unique_models), len(unique_models)))\n",
        "\n",
        "        for i, model1 in enumerate(unique_models):\n",
        "            for j, model2 in enumerate(unique_models):\n",
        "                mask1 = model_names == model1\n",
        "                mask2 = model_names == model2\n",
        "\n",
        "                if i == j:\n",
        "                    # Intra-model similarity\n",
        "                    embs = ai_embeddings[mask1]\n",
        "                    if len(embs) > 1:\n",
        "                        similarities = []\n",
        "                        for k in range(len(embs)):\n",
        "                            for l in range(k+1, len(embs)):\n",
        "                                similarities.append(np.dot(embs[k], embs[l]))\n",
        "                        similarity_matrix[i, j] = np.mean(similarities) if similarities else 0\n",
        "                else:\n",
        "                    # Inter-model similarity\n",
        "                    embs1 = ai_embeddings[mask1]\n",
        "                    embs2 = ai_embeddings[mask2]\n",
        "                    similarities = []\n",
        "                    for emb1 in embs1:\n",
        "                        for emb2 in embs2:\n",
        "                            similarities.append(np.dot(emb1, emb2))\n",
        "                    similarity_matrix[i, j] = np.mean(similarities) if similarities else 0\n",
        "\n",
        "        im = axes[1,1].imshow(similarity_matrix, cmap='viridis', aspect='auto')\n",
        "        axes[1,1].set_title('Inter-Model Similarity Matrix')\n",
        "        axes[1,1].set_xticks(range(len(unique_models)))\n",
        "        axes[1,1].set_yticks(range(len(unique_models)))\n",
        "        axes[1,1].set_xticklabels(unique_models, rotation=45)\n",
        "        axes[1,1].set_yticklabels(unique_models)\n",
        "        plt.colorbar(im, ax=axes[1,1])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/figure3_model_signatures.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.savefig(f\"{output_dir}/figure3_model_signatures.pdf\", bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_movement_relationships(self, output_dir):\n",
        "        \"\"\"Create Figure 4: Movement relationship analysis.\"\"\"\n",
        "        if 'movement_analysis' not in self.results:\n",
        "            print(\"Movement analysis not available\")\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # CSAS scores\n",
        "        csas_scores = self.results['movement_analysis']['csas_scores']\n",
        "        movements = list(csas_scores.keys())\n",
        "        scores = list(csas_scores.values())\n",
        "\n",
        "        axes[0,0].barh(movements, scores)\n",
        "        axes[0,0].set_title('Cross-Style Affinity Scores (CSAS)')\n",
        "        axes[0,0].set_xlabel('Affinity Score')\n",
        "\n",
        "        # Temporal correlation\n",
        "        temporal_data = self.results['movement_analysis']['temporal_data']\n",
        "        if temporal_data:\n",
        "            years, similarities = zip(*temporal_data)\n",
        "            axes[0,1].scatter(years, similarities, s=100, alpha=0.7)\n",
        "\n",
        "            # Add trend line\n",
        "            z = np.polyfit(years, similarities, 1)\n",
        "            p = np.poly1d(z)\n",
        "            axes[0,1].plot(years, p(years), \"r--\", alpha=0.8)\n",
        "\n",
        "            corr = self.results['movement_analysis']['temporal_correlation']\n",
        "            p_val = self.results['movement_analysis']['temporal_p_value']\n",
        "\n",
        "            axes[0,1].set_title(f'Temporal Bias Analysis (r={corr:.3f}, p={p_val:.3f})')\n",
        "            axes[0,1].set_xlabel('Movement Year')\n",
        "            axes[0,1].set_ylabel('AI Similarity Score')\n",
        "\n",
        "            # Add movement labels\n",
        "            for year, sim, movement in zip(years, similarities, movements):\n",
        "                axes[0,1].annotate(movement, (year, sim), xytext=(5, 5),\n",
        "                                 textcoords='offset points', fontsize=8)\n",
        "\n",
        "        # Movement similarity heatmap\n",
        "        movement_similarities = self.results['movement_analysis']['movement_similarities']\n",
        "        movements = list(movement_similarities.keys())\n",
        "        similarity_means = [movement_similarities[mov]['mean_similarity'] for mov in movements]\n",
        "\n",
        "        # Create heatmap data\n",
        "        human_mask = self.metadata['source'] == 'human'\n",
        "        ai_mask = self.metadata['source'] == 'ai'\n",
        "\n",
        "        heatmap_data = []\n",
        "        for movement in movements:\n",
        "            movement_mask = (self.metadata['movement'] == movement) & human_mask\n",
        "            if movement_mask.sum() > 0:\n",
        "                movement_embs = self.embeddings[movement_mask]\n",
        "                ai_embs = self.embeddings[ai_mask]\n",
        "\n",
        "                # Compute similarity matrix between movement and AI\n",
        "                similarities = []\n",
        "                for ai_emb in ai_embs:\n",
        "                    mov_similarities = [np.dot(ai_emb, mov_emb) for mov_emb in movement_embs]\n",
        "                    similarities.append(np.mean(mov_similarities))\n",
        "\n",
        "                heatmap_data.append(similarities)\n",
        "\n",
        "        if heatmap_data:\n",
        "            heatmap_array = np.array(heatmap_data)\n",
        "            im = axes[1,0].imshow(heatmap_array, aspect='auto', cmap='viridis')\n",
        "            axes[1,0].set_title('AI-Movement Similarity Matrix')\n",
        "            axes[1,0].set_yticks(range(len(movements)))\n",
        "            axes[1,0].set_yticklabels(movements)\n",
        "            axes[1,0].set_xlabel('AI Artwork Index')\n",
        "            plt.colorbar(im, ax=axes[1,0])\n",
        "\n",
        "        # Distribution of similarities\n",
        "        all_similarities = []\n",
        "        labels = []\n",
        "        for movement, data in movement_similarities.items():\n",
        "            all_similarities.extend(data['similarities'])\n",
        "            labels.extend([movement] * len(data['similarities']))\n",
        "\n",
        "        similarity_df = pd.DataFrame({\n",
        "            'similarity': all_similarities,\n",
        "            'movement': labels\n",
        "        })\n",
        "\n",
        "        sns.boxplot(data=similarity_df, x='movement', y='similarity', ax=axes[1,1])\n",
        "        axes[1,1].set_title('AI Similarity Distribution by Movement')\n",
        "        axes[1,1].set_xticklabels(axes[1,1].get_xticklabels(), rotation=45)\n",
        "        axes[1,1].set_ylabel('Cosine Similarity')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/figure4_movement_relationships.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.savefig(f\"{output_dir}/figure4_movement_relationships.pdf\", bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_statistical_summary(self, output_dir):\n",
        "        \"\"\"Create Figure 5: Statistical analysis summary.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # ADI comparison\n",
        "        human_mask = self.metadata['source'] == 'human'\n",
        "        ai_mask = self.metadata['source'] == 'ai'\n",
        "\n",
        "        adi_ai_human = self.results['statistical_analysis']['adi']\n",
        "\n",
        "        # Compute ADI for inter-movement comparisons\n",
        "        human_movements = self.metadata[human_mask]['movement'].unique()\n",
        "        inter_movement_adis = []\n",
        "\n",
        "        for i, mov1 in enumerate(human_movements):\n",
        "            for j, mov2 in enumerate(human_movements):\n",
        "                if i < j:\n",
        "                    mask1 = (self.metadata['movement'] == mov1) & human_mask\n",
        "                    mask2 = (self.metadata['movement'] == mov2) & human_mask\n",
        "                    if mask1.sum() > 5 and mask2.sum() > 5:\n",
        "                        adi, _ = self.compute_aesthetic_distinctiveness_index(mask1, mask2)\n",
        "                        inter_movement_adis.append(adi)\n",
        "\n",
        "        # ADI bar plot\n",
        "        adi_categories = ['AI vs Human', 'Inter-Movement\\n(Human)']\n",
        "        adi_values = [adi_ai_human, np.mean(inter_movement_adis) if inter_movement_adis else 0]\n",
        "        adi_errors = [0, np.std(inter_movement_adis) if inter_movement_adis else 0]\n",
        "\n",
        "        bars = axes[0,0].bar(adi_categories, adi_values, yerr=adi_errors, capsize=5,\n",
        "                           color=['#ff7f0e', '#1f77b4'], alpha=0.7)\n",
        "        axes[0,0].set_title('Aesthetic Distinctiveness Index (ADI)')\n",
        "        axes[0,0].set_ylabel('ADI Score')\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar, value in zip(bars, adi_values):\n",
        "            height = bar.get_height()\n",
        "            axes[0,0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                         f'{value:.2f}', ha='center', va='bottom')\n",
        "\n",
        "        # Similarity distributions\n",
        "        human_stats = self.results['statistical_analysis']['human_similarity_stats']\n",
        "        ai_stats = self.results['statistical_analysis']['ai_similarity_stats']\n",
        "\n",
        "        # Create violin plot\n",
        "        human_sims = np.random.normal(human_stats['mean'], human_stats['std'], 1000)\n",
        "        ai_sims = np.random.normal(ai_stats['mean'], ai_stats['std'], 1000)\n",
        "\n",
        "        data_for_violin = [human_sims, ai_sims]\n",
        "        parts = axes[0,1].violinplot(data_for_violin, positions=[1, 2], showmeans=True)\n",
        "        axes[0,1].set_title('Intra-Group Similarity Distributions')\n",
        "        axes[0,1].set_xticks([1, 2])\n",
        "        axes[0,1].set_xticklabels(['Human Art', 'AI Art'])\n",
        "        axes[0,1].set_ylabel('Cosine Similarity')\n",
        "\n",
        "        # Effect size visualization\n",
        "        cohens_d = self.results['statistical_analysis']['effect_size']['cohens_d']\n",
        "        interpretation = self.results['statistical_analysis']['effect_size']['interpretation']\n",
        "\n",
        "        # Cohen's d reference lines\n",
        "        effect_sizes = ['negligible', 'small', 'medium', 'large']\n",
        "        effect_thresholds = [0.2, 0.5, 0.8, 1.2]\n",
        "\n",
        "        axes[1,0].barh(effect_sizes, effect_thresholds, alpha=0.3, color='gray')\n",
        "        axes[1,0].barh([interpretation], [abs(cohens_d)], color='red', alpha=0.8)\n",
        "        axes[1,0].set_title(f\"Effect Size (Cohen's d = {cohens_d:.3f})\")\n",
        "        axes[1,0].set_xlabel(\"Effect Size Magnitude\")\n",
        "\n",
        "        # P-value significance\n",
        "        p_value = self.results['statistical_analysis']['mannwhitney_test']['p_value']\n",
        "        significance_levels = [0.05, 0.01, 0.001]\n",
        "        significance_labels = ['p < 0.05', 'p < 0.01', 'p < 0.001']\n",
        "\n",
        "        sig_colors = ['yellow' if p_value < 0.05 else 'gray',\n",
        "                     'orange' if p_value < 0.01 else 'gray',\n",
        "                     'red' if p_value < 0.001 else 'gray']\n",
        "\n",
        "        axes[1,1].bar(significance_labels, [1, 1, 1], color=sig_colors, alpha=0.7)\n",
        "        axes[1,1].set_title(f'Statistical Significance (p = {p_value:.2e})')\n",
        "        axes[1,1].set_ylabel('Significance Level Met')\n",
        "        axes[1,1].set_ylim(0, 1.2)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/figure5_statistical_summary.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.savefig(f\"{output_dir}/figure5_statistical_summary.pdf\", bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_pca_components(self, output_dir):\n",
        "        \"\"\"Create Figure 6: PCA component analysis.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        pca_data = self.results['dimensionality_reduction']['pca']\n",
        "        explained_var = pca_data['explained_variance_ratio']\n",
        "\n",
        "        # Explained variance\n",
        "        axes[0,0].plot(range(1, len(explained_var)+1), np.cumsum(explained_var), 'bo-')\n",
        "        axes[0,0].axhline(y=0.95, color='red', linestyle='--', label='95% threshold')\n",
        "        axes[0,0].set_title('Cumulative Explained Variance')\n",
        "        axes[0,0].set_xlabel('Principal Component')\n",
        "        axes[0,0].set_ylabel('Cumulative Variance Explained')\n",
        "        axes[0,0].legend()\n",
        "        axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Component loadings heatmap\n",
        "        components = pca_data['components'][:5]  # Top 5 components\n",
        "        im = axes[0,1].imshow(components, aspect='auto', cmap='RdBu_r')\n",
        "        axes[0,1].set_title('PCA Component Loadings (Top 5)')\n",
        "        axes[0,1].set_xlabel('Feature Dimension')\n",
        "        axes[0,1].set_ylabel('Principal Component')\n",
        "        axes[0,1].set_yticks(range(5))\n",
        "        axes[0,1].set_yticklabels([f'PC{i+1}' for i in range(5)])\n",
        "        plt.colorbar(im, ax=axes[0,1])\n",
        "\n",
        "        # PC scores by group\n",
        "        pca_embeddings = pca_data['embeddings']\n",
        "        human_mask = self.metadata['source'] == 'human'\n",
        "        ai_mask = self.metadata['source'] == 'ai'\n",
        "\n",
        "        human_pc1 = pca_embeddings[human_mask, 0]\n",
        "        ai_pc1 = pca_embeddings[ai_mask, 0]\n",
        "        human_pc2 = pca_embeddings[human_mask, 1]\n",
        "        ai_pc2 = pca_embeddings[ai_mask, 1]\n",
        "\n",
        "        axes[1,0].hist([human_pc1, ai_pc1], bins=30, alpha=0.7,\n",
        "                      label=['Human', 'AI'], color=['#1f77b4', '#ff7f0e'])\n",
        "        axes[1,0].set_title('PC1 Score Distribution')\n",
        "        axes[1,0].set_xlabel('PC1 Score')\n",
        "        axes[1,0].set_ylabel('Frequency')\n",
        "        axes[1,0].legend()\n",
        "\n",
        "        axes[1,1].hist([human_pc2, ai_pc2], bins=30, alpha=0.7,\n",
        "                      label=['Human', 'AI'], color=['#1f77b4', '#ff7f0e'])\n",
        "        axes[1,1].set_title('PC2 Score Distribution')\n",
        "        axes[1,1].set_xlabel('PC2 Score')\n",
        "        axes[1,1].set_ylabel('Frequency')\n",
        "        axes[1,1].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/figure6_pca_analysis.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.savefig(f\"{output_dir}/figure6_pca_analysis.pdf\", bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def generate_results_table(self, output_dir=\"results\"):\n",
        "        \"\"\"Generate publication-ready results tables.\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Table 1: Clustering performance summary\n",
        "        clustering_summary = {\n",
        "            'Algorithm': ['K-means', 'Hierarchical', 'DBSCAN', 'GMM'],\n",
        "            'Silhouette Score': [\n",
        "                self.results['clustering']['kmeans']['silhouette_score'],\n",
        "                'N/A',\n",
        "                self.results['clustering']['dbscan']['silhouette_score'],\n",
        "                'N/A'\n",
        "            ],\n",
        "            'ARI': [\n",
        "                self.results['clustering']['kmeans']['ari'],\n",
        "                'N/A',\n",
        "                'N/A',\n",
        "                'N/A'\n",
        "            ],\n",
        "            'Accuracy': [\n",
        "                self.results['clustering']['kmeans']['accuracy'],\n",
        "                'N/A',\n",
        "                'N/A',\n",
        "                'N/A'\n",
        "            ],\n",
        "            'Key Metric': [\n",
        "                f\"Acc: {self.results['clustering']['kmeans']['accuracy']:.3f}\",\n",
        "                f\"Coph: {self.results['clustering']['hierarchical']['cophenetic_corr']:.3f}\",\n",
        "                f\"Clusters: {self.results['clustering']['dbscan']['n_clusters']}\",\n",
        "                f\"Components: {self.results['clustering']['gmm']['n_components']}\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        clustering_df = pd.DataFrame(clustering_summary)\n",
        "        clustering_df.to_csv(f\"{output_dir}/table1_clustering_performance.csv\", index=False)\n",
        "\n",
        "        # Table 2: Movement affinity analysis\n",
        "        if 'movement_analysis' in self.results:\n",
        "            csas_scores = self.results['movement_analysis']['csas_scores']\n",
        "            movement_data = []\n",
        "\n",
        "            for movement, score in csas_scores.items():\n",
        "                movement_similarities = self.results['movement_analysis']['movement_similarities'][movement]\n",
        "                movement_data.append({\n",
        "                    'Movement': movement,\n",
        "                    'CSAS Score': score,\n",
        "                    'Mean Similarity': movement_similarities['mean_similarity'],\n",
        "                    'Std Similarity': movement_similarities['std_similarity'],\n",
        "                    'N Artworks': len(movement_similarities['similarities'])\n",
        "                })\n",
        "\n",
        "            movement_df = pd.DataFrame(movement_data)\n",
        "            movement_df = movement_df.sort_values('CSAS Score', ascending=False)\n",
        "            movement_df.to_csv(f\"{output_dir}/table2_movement_affinity.csv\", index=False)\n",
        "\n",
        "        # Table 3: Statistical test results\n",
        "        stats_data = {\n",
        "            'Test': ['Mann-Whitney U', 'Effect Size (Cohen\\'s d)', 'ADI'],\n",
        "            'Statistic': [\n",
        "                self.results['statistical_analysis']['mannwhitney_test']['statistic'],\n",
        "                self.results['statistical_analysis']['effect_size']['cohens_d'],\n",
        "                self.results['statistical_analysis']['adi']\n",
        "            ],\n",
        "            'P-value': [\n",
        "                self.results['statistical_analysis']['mannwhitney_test']['p_value'],\n",
        "                'N/A',\n",
        "                'N/A'\n",
        "            ],\n",
        "            'Interpretation': [\n",
        "                'Significant' if self.results['statistical_analysis']['mannwhitney_test']['p_value'] < 0.05 else 'Not significant',\n",
        "                self.results['statistical_analysis']['effect_size']['interpretation'],\n",
        "                'High distinctiveness' if self.results['statistical_analysis']['adi'] > 2 else 'Moderate distinctiveness'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        stats_df = pd.DataFrame(stats_data)\n",
        "        stats_df.to_csv(f\"{output_dir}/table3_statistical_tests.csv\", index=False)\n",
        "\n",
        "        print(f\"Results tables saved to {output_dir}/\")\n",
        "\n",
        "    def generate_comprehensive_report(self, output_file=\"analysis_report.txt\"):\n",
        "        \"\"\"Generate a comprehensive text report of all findings.\"\"\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(\"LATENT AESTHETICS ANALYSIS - COMPREHENSIVE REPORT\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "            # Dataset summary\n",
        "            f.write(\"DATASET SUMMARY\\n\")\n",
        "            f.write(\"-\"*20 + \"\\n\")\n",
        "            f.write(f\"Total artworks: {len(self.embeddings)}\\n\")\n",
        "            f.write(f\"Human artworks: {sum(self.metadata['source'] == 'human')}\\n\")\n",
        "            f.write(f\"AI artworks: {sum(self.metadata['source'] == 'ai')}\\n\")\n",
        "\n",
        "            # Movement distribution\n",
        "            f.write(\"\\nMovement distribution:\\n\")\n",
        "            movement_counts = self.metadata['movement'].value_counts()\n",
        "            for movement, count in movement_counts.items():\n",
        "                f.write(f\"  {movement}: {count}\\n\")\n",
        "\n",
        "            # Dimensionality reduction results\n",
        "            f.write(f\"\\nDIMENSIONALITY REDUCTION\\n\")\n",
        "            f.write(\"-\"*25 + \"\\n\")\n",
        "            pca_var = self.results['dimensionality_reduction']['pca']['explained_variance_ratio']\n",
        "            f.write(f\"PCA - PC1 variance: {pca_var[0]:.3f}, PC2 variance: {pca_var[1]:.3f}\\n\")\n",
        "            f.write(f\"Components for 95% variance: {self.results['pca_95_components']}\\n\")\n",
        "            f.write(f\"t-SNE KL divergence: {self.results['dimensionality_reduction']['tsne']['kl_divergence']:.3f}\\n\")\n",
        "\n",
        "            # Clustering results\n",
        "            f.write(f\"\\nCLUSTERING ANALYSIS\\n\")\n",
        "            f.write(\"-\"*20 + \"\\n\")\n",
        "            kmeans_results = self.results['clustering']['kmeans']\n",
        "            f.write(f\"K-means accuracy: {kmeans_results['accuracy']:.3f}\\n\")\n",
        "            f.write(f\"K-means silhouette score: {kmeans_results['silhouette_score']:.3f}\\n\")\n",
        "            f.write(f\"K-means ARI: {kmeans_results['ari']:.3f}\\n\")\n",
        "\n",
        "            dbscan_results = self.results['clustering']['dbscan']\n",
        "            f.write(f\"DBSCAN clusters: {dbscan_results['n_clusters']}\\n\")\n",
        "            f.write(f\"DBSCAN noise ratio: {dbscan_results['noise_ratio']:.3f}\\n\")\n",
        "\n",
        "            # Statistical analysis\n",
        "            f.write(f\"\\nSTATISTICAL ANALYSIS\\n\")\n",
        "            f.write(\"-\"*20 + \"\\n\")\n",
        "            stats_results = self.results['statistical_analysis']\n",
        "            f.write(f\"ADI score: {stats_results['adi']:.3f}\\n\")\n",
        "            f.write(f\"Mann-Whitney U p-value: {stats_results['mannwhitney_test']['p_value']:.2e}\\n\")\n",
        "            f.write(f\"Cohen's d: {stats_results['effect_size']['cohens_d']:.3f} ({stats_results['effect_size']['interpretation']})\\n\")\n",
        "\n",
        "            # Movement analysis\n",
        "            if 'movement_analysis' in self.results:\n",
        "                f.write(f\"\\nMOVEMENT ANALYSIS\\n\")\n",
        "                f.write(\"-\"*17 + \"\\n\")\n",
        "                csas_scores = self.results['movement_analysis']['csas_scores']\n",
        "                f.write(\"Cross-Style Affinity Scores:\\n\")\n",
        "                for movement, score in sorted(csas_scores.items(), key=lambda x: x[1], reverse=True):\n",
        "                    f.write(f\"  {movement}: {score:.3f}\\n\")\n",
        "\n",
        "                temporal_corr = self.results['movement_analysis']['temporal_correlation']\n",
        "                temporal_p = self.results['movement_analysis']['temporal_p_value']\n",
        "                if temporal_corr is not None:\n",
        "                    f.write(f\"\\nTemporal correlation: r = {temporal_corr:.3f}, p = {temporal_p:.3f}\\n\")\n",
        "\n",
        "            # Model signatures\n",
        "            if 'model_signatures' in self.results:\n",
        "                f.write(f\"\\nMODEL SIGNATURES\\n\")\n",
        "                f.write(\"-\"*17 + \"\\n\")\n",
        "                model_results = self.results['model_signatures']\n",
        "                f.write(f\"Classification accuracy: {model_results['accuracy']:.3f}\\n\")\n",
        "                f.write(f\"Cross-validation: {model_results['cv_mean']:.3f} ± {model_results['cv_std']:.3f}\\n\")\n",
        "\n",
        "        print(f\"Comprehensive report saved to {output_file}\")\n",
        "\n",
        "    def run_complete_analysis(self, data_config):\n",
        "        \"\"\"Run the complete analysis pipeline.\"\"\"\n",
        "        print(\"Starting comprehensive latent aesthetics analysis...\")\n",
        "\n",
        "        # Load and process data\n",
        "        self.load_and_process_images(data_config)\n",
        "\n",
        "        # Core analyses\n",
        "        self.perform_dimensionality_reduction()\n",
        "        self.perform_clustering_analysis()\n",
        "        self.analyze_model_signatures()\n",
        "        self.analyze_movement_relationships()\n",
        "        self.compute_statistical_comparisons()\n",
        "\n",
        "        # Generate outputs\n",
        "        self.generate_publication_figures()\n",
        "        self.generate_results_table()\n",
        "        self.generate_comprehensive_report()\n",
        "\n",
        "        print(\"Analysis complete!\")\n",
        "        return self.results\n",
        "\n",
        "def create_synthetic_dataset():\n",
        "    \"\"\"\n",
        "    Create synthetic dataset for demonstration purposes.\n",
        "    In real implementation, this would load actual image files.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Simulate CLIP embeddings for different artistic styles\n",
        "    n_dims = 512\n",
        "\n",
        "    # Human art movements with characteristic patterns\n",
        "    movements = {\n",
        "        'Renaissance': (0.2, 0.1),  # Low variance, classical patterns\n",
        "        'Impressionism': (0.4, 0.3),  # Medium variance, colorful\n",
        "        'Abstract Expressionism': (0.6, 0.4),  # High variance, dynamic\n",
        "        'Cubism': (0.3, 0.5),  # Geometric patterns\n",
        "        'Surrealism': (0.5, 0.6),  # Unusual combinations\n",
        "    }\n",
        "\n",
        "    # AI models with different characteristics\n",
        "    ai_models = {\n",
        "        'DALL-E-2': (0.45, 0.25),  # Balanced, semantic\n",
        "        'Stable-Diffusion': (0.55, 0.35),  # Painterly\n",
        "        'Midjourney': (0.5, 0.3),  # Artistic composition\n",
        "    }\n",
        "\n",
        "    embeddings = []\n",
        "    metadata = []\n",
        "\n",
        "    # Generate human artworks\n",
        "    for movement, (mean_shift, variance) in movements.items():\n",
        "        n_samples = 25 if movement != 'Impressionism' else 40  # More impressionist works\n",
        "\n",
        "        # Create movement-specific embedding pattern\n",
        "        base_pattern = np.random.randn(n_dims) * 0.1\n",
        "        for i in range(n_samples):\n",
        "            # Add noise and movement-specific bias\n",
        "            embedding = base_pattern + np.random.randn(n_dims) * variance\n",
        "            embedding += mean_shift * np.random.randn(n_dims) * 0.2\n",
        "\n",
        "            # Normalize\n",
        "            embedding = embedding / np.linalg.norm(embedding)\n",
        "\n",
        "            embeddings.append(embedding)\n",
        "            metadata.append({\n",
        "                'source': 'human',\n",
        "                'movement': movement,\n",
        "                'model': 'human',\n",
        "                'path': f'synthetic_{movement}_{i}.jpg',\n",
        "                'filename': f'{movement}_{i}.jpg'\n",
        "            })\n",
        "\n",
        "    # Generate AI artworks\n",
        "    for model, (mean_shift, variance) in ai_models.items():\n",
        "        n_samples = 30\n",
        "\n",
        "        # AI models tend to cluster differently - more similar to modern movements\n",
        "        impressionist_pattern = np.random.randn(n_dims) * 0.1\n",
        "        abstract_pattern = np.random.randn(n_dims) * 0.1\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            # Blend impressionist and abstract patterns\n",
        "            blend_ratio = np.random.beta(2, 2)  # Bias toward center\n",
        "            embedding = (blend_ratio * impressionist_pattern +\n",
        "                        (1 - blend_ratio) * abstract_pattern)\n",
        "\n",
        "            # Add model-specific characteristics\n",
        "            embedding += mean_shift * np.random.randn(n_dims) * 0.15\n",
        "            embedding += np.random.randn(n_dims) * variance\n",
        "\n",
        "            # Normalize\n",
        "            embedding = embedding / np.linalg.norm(embedding)\n",
        "\n",
        "            embeddings.append(embedding)\n",
        "            metadata.append({\n",
        "                'source': 'ai',\n",
        "                'movement': 'ai_generated',\n",
        "                'model': model,\n",
        "                'path': f'synthetic_{model}_{i}.jpg',\n",
        "                'filename': f'{model}_{i}.jpg'\n",
        "            })\n",
        "\n",
        "    return np.array(embeddings), pd.DataFrame(metadata)\n",
        "\n",
        "def run_synthetic_analysis():\n",
        "    \"\"\"Run analysis on synthetic data for demonstration.\"\"\"\n",
        "    print(\"Running analysis on synthetic dataset...\")\n",
        "\n",
        "    # Create analyzer (will use CPU for synthetic data)\n",
        "    analyzer = LatentAestheticsAnalyzer(device=\"cpu\")\n",
        "\n",
        "    # Generate synthetic data\n",
        "    embeddings, metadata = create_synthetic_dataset()\n",
        "    analyzer.embeddings = embeddings\n",
        "    analyzer.metadata = metadata\n",
        "\n",
        "    print(f\"Generated synthetic dataset: {len(embeddings)} samples\")\n",
        "    print(f\"Human samples: {sum(metadata['source'] == 'human')}\")\n",
        "    print(f\"AI samples: {sum(metadata['source'] == 'ai')}\")\n",
        "\n",
        "    # Run analyses\n",
        "    analyzer.perform_dimensionality_reduction()\n",
        "    analyzer.perform_clustering_analysis()\n",
        "    analyzer.analyze_model_signatures()\n",
        "    analyzer.analyze_movement_relationships()\n",
        "    analyzer.compute_statistical_comparisons()\n",
        "\n",
        "    # Generate outputs\n",
        "    analyzer.generate_publication_figures()\n",
        "    analyzer.generate_results_table()\n",
        "    analyzer.generate_comprehensive_report()\n",
        "\n",
        "    return analyzer.results\n",
        "\n",
        "def load_real_dataset_example():\n",
        "    \"\"\"\n",
        "    Example configuration for loading real datasets.\n",
        "    Modify paths according to your data organization.\n",
        "    \"\"\"\n",
        "    data_config = {\n",
        "        'human_art': {\n",
        "            'Renaissance': [\n",
        "                'data/human/renaissance/botticelli_birth_venus.jpg',\n",
        "                'data/human/renaissance/leonardo_mona_lisa.jpg',\n",
        "                # ... add more renaissance works\n",
        "            ],\n",
        "            'Impressionism': [\n",
        "                'data/human/impressionism/monet_waterlilies.jpg',\n",
        "                'data/human/impressionism/renoir_luncheon.jpg',\n",
        "                # ... add more impressionist works\n",
        "            ],\n",
        "            'Abstract Expressionism': [\n",
        "                'data/human/abstract/pollock_no1.jpg',\n",
        "                'data/human/abstract/rothko_orange.jpg',\n",
        "                # ... add more abstract works\n",
        "            ],\n",
        "            # ... add other movements\n",
        "        },\n",
        "        'ai_art': {\n",
        "            'DALL-E-2': [\n",
        "                'data/ai/dalle2/abstract_landscape_001.jpg',\n",
        "                'data/ai/dalle2/surreal_portrait_002.jpg',\n",
        "                # ... add more DALL-E 2 images\n",
        "            ],\n",
        "            'Stable-Diffusion': [\n",
        "                'data/ai/sd/painterly_scene_001.jpg',\n",
        "                'data/ai/sd/artistic_portrait_002.jpg',\n",
        "                # ... add more Stable Diffusion images\n",
        "            ],\n",
        "            'Midjourney': [\n",
        "                'data/ai/midjourney/composition_001.jpg',\n",
        "                'data/ai/midjourney/artistic_landscape_002.jpg',\n",
        "                # ... add more Midjourney images\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "    return data_config\n",
        "\n",
        "def perform_robustness_analysis(analyzer, n_bootstrap=100):\n",
        "    \"\"\"Perform bootstrap analysis to assess result stability.\"\"\"\n",
        "    print(\"Performing robustness analysis...\")\n",
        "\n",
        "    bootstrap_adis = []\n",
        "    bootstrap_accuracies = []\n",
        "\n",
        "    for i in range(n_bootstrap):\n",
        "        # Bootstrap sample\n",
        "        n_samples = len(analyzer.embeddings)\n",
        "        indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
        "\n",
        "        boot_embeddings = analyzer.embeddings[indices]\n",
        "        boot_metadata = analyzer.metadata.iloc[indices].reset_index(drop=True)\n",
        "\n",
        "        # Compute ADI\n",
        "        human_mask = boot_metadata['source'] == 'human'\n",
        "        ai_mask = boot_metadata['source'] == 'ai'\n",
        "\n",
        "        if human_mask.sum() > 10 and ai_mask.sum() > 10:\n",
        "            # Create temporary analyzer for bootstrap sample\n",
        "            temp_analyzer = LatentAestheticsAnalyzer(device=\"cpu\")\n",
        "            temp_analyzer.embeddings = boot_embeddings\n",
        "            temp_analyzer.metadata = boot_metadata\n",
        "\n",
        "            adi, _ = temp_analyzer.compute_aesthetic_distinctiveness_index(human_mask, ai_mask)\n",
        "            bootstrap_adis.append(adi)\n",
        "\n",
        "            # Quick k-means accuracy\n",
        "            y_true = ai_mask.astype(int)\n",
        "            kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "            kmeans_labels = kmeans.fit_predict(boot_embeddings)\n",
        "            accuracy = max(np.mean(kmeans_labels == y_true),\n",
        "                          np.mean(kmeans_labels != y_true))  # Handle label flipping\n",
        "            bootstrap_accuracies.append(accuracy)\n",
        "\n",
        "    # Compute confidence intervals\n",
        "    adi_ci = np.percentile(bootstrap_adis, [2.5, 97.5])\n",
        "    acc_ci = np.percentile(bootstrap_accuracies, [2.5, 97.5])\n",
        "\n",
        "    robustness_results = {\n",
        "        'bootstrap_adis': bootstrap_adis,\n",
        "        'bootstrap_accuracies': bootstrap_accuracies,\n",
        "        'adi_mean': np.mean(bootstrap_adis),\n",
        "        'adi_std': np.std(bootstrap_adis),\n",
        "        'adi_ci': adi_ci,\n",
        "        'accuracy_mean': np.mean(bootstrap_accuracies),\n",
        "        'accuracy_std': np.std(bootstrap_accuracies),\n",
        "        'accuracy_ci': acc_ci\n",
        "    }\n",
        "\n",
        "    print(f\"Bootstrap ADI: {robustness_results['adi_mean']:.3f} ± {robustness_results['adi_std']:.3f}\")\n",
        "    print(f\"Bootstrap ADI 95% CI: [{adi_ci[0]:.3f}, {adi_ci[1]:.3f}]\")\n",
        "    print(f\"Bootstrap Accuracy: {robustness_results['accuracy_mean']:.3f} ± {robustness_results['accuracy_std']:.3f}\")\n",
        "    print(f\"Bootstrap Accuracy 95% CI: [{acc_ci[0]:.3f}, {acc_ci[1]:.3f}]\")\n",
        "\n",
        "    return robustness_results\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    print(\"Latent Aesthetics Analysis Pipeline\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Option 1: Run with synthetic data (for demonstration)\n",
        "    print(\"\\nOption 1: Running with synthetic data...\")\n",
        "    results_synthetic = run_synthetic_analysis()\n",
        "\n",
        "    # Option 2: Template for real data analysis\n",
        "    print(\"\\nTo run with real data, use the following template:\")\n",
        "    print(\"\"\"\n",
        "    # Load real dataset\n",
        "    data_config = load_real_dataset_example()\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = LatentAestheticsAnalyzer()\n",
        "\n",
        "    # Run complete analysis\n",
        "    results = analyzer.run_complete_analysis(data_config)\n",
        "\n",
        "    # Optional: Perform robustness analysis\n",
        "    robustness = perform_robustness_analysis(analyzer, n_bootstrap=100)\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nAnalysis pipeline completed successfully!\")\n",
        "    print(\"Check the 'figures/' and 'results/' directories for outputs.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Additional utility functions for advanced analysis\n",
        "\n",
        "def compute_embedding_manifold_properties(embeddings):\n",
        "    \"\"\"Compute intrinsic dimensionality and manifold properties.\"\"\"\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "    # Estimate intrinsic dimensionality using nearest neighbors\n",
        "    k_range = range(5, min(50, len(embeddings)//4))\n",
        "    intrinsic_dims = []\n",
        "\n",
        "    for k in k_range:\n",
        "        nbrs = NearestNeighbors(n_neighbors=k+1).fit(embeddings)\n",
        "        distances, indices = nbrs.kneighbors(embeddings)\n",
        "\n",
        "        # Use distance ratios to estimate dimensionality\n",
        "        ratios = distances[:, -1] / distances[:, 1]  # Furthest to nearest ratio\n",
        "        intrinsic_dim = np.mean(np.log(ratios))\n",
        "        intrinsic_dims.append(intrinsic_dim)\n",
        "\n",
        "    estimated_dim = np.mean(intrinsic_dims)\n",
        "    return estimated_dim, intrinsic_dims\n",
        "\n",
        "def analyze_embedding_geometry(embeddings, metadata):\n",
        "    \"\"\"Analyze geometric properties of embedding distributions.\"\"\"\n",
        "    human_mask = metadata['source'] == 'human'\n",
        "    ai_mask = metadata['source'] == 'ai'\n",
        "\n",
        "    human_embs = embeddings[human_mask]\n",
        "    ai_embs = embeddings[ai_mask]\n",
        "\n",
        "    # Compute geometric properties\n",
        "    human_centroid = np.mean(human_embs, axis=0)\n",
        "    ai_centroid = np.mean(ai_embs, axis=0)\n",
        "\n",
        "    # Spread analysis\n",
        "    human_spread = np.mean([np.linalg.norm(emb - human_centroid) for emb in human_embs])\n",
        "    ai_spread = np.mean([np.linalg.norm(emb - ai_centroid) for emb in ai_embs])\n",
        "\n",
        "    # Convex hull volume (approximate using PCA)\n",
        "    from scipy.spatial import ConvexHull\n",
        "\n",
        "    pca = PCA(n_components=10)  # Reduce to manageable dimensions\n",
        "    human_pca = pca.fit_transform(human_embs)\n",
        "    ai_pca = pca.transform(ai_embs)\n",
        "\n",
        "    try:\n",
        "        human_hull = ConvexHull(human_pca)\n",
        "        ai_hull = ConvexHull(ai_pca)\n",
        "        human_volume = human_hull.volume\n",
        "        ai_volume = ai_hull.volume\n",
        "    except Exception:\n",
        "        human_volume = ai_volume = None\n",
        "\n",
        "    geometry_analysis = {\n",
        "        'centroid_distance': np.linalg.norm(human_centroid - ai_centroid),\n",
        "        'human_spread': human_spread,\n",
        "        'ai_spread': ai_spread,\n",
        "        'spread_ratio': ai_spread / human_spread if human_spread > 0 else None,\n",
        "        'human_hull_volume': human_volume,\n",
        "        'ai_hull_volume': ai_volume,\n",
        "        'volume_ratio': ai_volume / human_volume if human_volume and ai_volume else None\n",
        "    }\n",
        "\n",
        "    return geometry_analysis\n",
        "\n",
        "def perform_cross_validation_analysis(embeddings, metadata, n_folds=5):\n",
        "    \"\"\"Perform cross-validation analysis for different classification tasks.\"\"\"\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
        "\n",
        "    # Binary classification: AI vs Human\n",
        "    y_binary = (metadata['source'] == 'ai').astype(int)\n",
        "\n",
        "    # Multi-class classification: All categories\n",
        "    label_encoder = {label: i for i, label in enumerate(metadata['movement'].unique())}\n",
        "    y_multi = metadata['movement'].map(label_encoder)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    classifiers = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "        'SVM': SVC(probability=True, random_state=42)\n",
        "    }\n",
        "\n",
        "    cv_results = {}\n",
        "\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        binary_scores = []\n",
        "        multi_scores = []\n",
        "        roc_scores = []\n",
        "\n",
        "        for train_idx, test_idx in cv.split(embeddings, y_binary):\n",
        "            X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "            y_train_bin, y_test_bin = y_binary[train_idx], y_binary[test_idx]\n",
        "\n",
        "            # Binary classification\n",
        "            clf.fit(X_train, y_train_bin)\n",
        "            binary_score = clf.score(X_test, y_test_bin)\n",
        "            binary_scores.append(binary_score)\n",
        "\n",
        "            # ROC-AUC\n",
        "            if hasattr(clf, 'predict_proba'):\n",
        "                y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "                roc_score = roc_auc_score(y_test_bin, y_prob)\n",
        "                roc_scores.append(roc_score)\n",
        "\n",
        "        cv_results[clf_name] = {\n",
        "            'binary_accuracy': {\n",
        "                'mean': np.mean(binary_scores),\n",
        "                'std': np.std(binary_scores),\n",
        "                'scores': binary_scores\n",
        "            },\n",
        "            'roc_auc': {\n",
        "                'mean': np.mean(roc_scores) if roc_scores else None,\n",
        "                'std': np.std(roc_scores) if roc_scores else None,\n",
        "                'scores': roc_scores\n",
        "            }\n",
        "        }\n",
        "\n",
        "    return cv_results\n",
        "\n",
        "def generate_latex_tables(results, output_dir=\"latex_tables\"):\n",
        "    \"\"\"Generate LaTeX-formatted tables for publication.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Table 1: Main results summary\n",
        "    latex_table1 = \"\"\"\n",
        "\\\\begin{table}[htbp]\n",
        "\\\\centering\n",
        "\\\\caption{Summary of clustering and classification performance}\n",
        "\\\\label{tab:main_results}\n",
        "\\\\begin{tabular}{lcccc}\n",
        "\\\\toprule\n",
        "Method & Accuracy & Silhouette Score & ARI & p-value \\\\\\\\\n",
        "\\\\midrule\n",
        "K-means & {kmeans_acc:.3f} & {kmeans_sil:.3f} & {kmeans_ari:.3f} & $<0.001$ \\\\\\\\\n",
        "DBSCAN & N/A & {dbscan_sil:.3f} & N/A & N/A \\\\\\\\\n",
        "SVM (AI models) & {svm_acc:.3f} & N/A & N/A & N/A \\\\\\\\\n",
        "\\\\bottomrule\n",
        "\\\\end{tabular}\n",
        "\\\\end{table}\n",
        "    \"\"\".format(\n",
        "        kmeans_acc=results['clustering']['kmeans']['accuracy'],\n",
        "        kmeans_sil=results['clustering']['kmeans']['silhouette_score'],\n",
        "        kmeans_ari=results['clustering']['kmeans']['ari'],\n",
        "        dbscan_sil=results['clustering']['dbscan']['silhouette_score'],\n",
        "        svm_acc=results['model_signatures']['accuracy'] if 'model_signatures' in results else 0\n",
        "    )\n",
        "\n",
        "    with open(f\"{output_dir}/table1_main_results.tex\", 'w') as f:\n",
        "        f.write(latex_table1)\n",
        "\n",
        "    # Table 2: Movement affinity scores\n",
        "    if 'movement_analysis' in results:\n",
        "        csas_scores = results['movement_analysis']['csas_scores']\n",
        "\n",
        "        latex_table2 = \"\"\"\n",
        "\\\\begin{table}[htbp]\n",
        "\\\\centering\n",
        "\\\\caption{Cross-Style Affinity Scores (CSAS) between AI art and human movements}\n",
        "\\\\label{tab:movement_affinity}\n",
        "\\\\begin{tabular}{lc}\n",
        "\\\\toprule\n",
        "Artistic Movement & CSAS Score \\\\\\\\\n",
        "\\\\midrule\n",
        "\"\"\"\n",
        "\n",
        "        for movement, score in sorted(csas_scores.items(), key=lambda x: x[1], reverse=True):\n",
        "            latex_table2 += f\"{movement.replace('_', ' ').title()} & {score:.3f} \\\\\\\\\\n\"\n",
        "\n",
        "        latex_table2 += \"\"\"\\\\bottomrule\n",
        "\\\\end{tabular}\n",
        "\\\\end{table}\n",
        "\"\"\"\n",
        "\n",
        "        with open(f\"{output_dir}/table2_movement_affinity.tex\", 'w') as f:\n",
        "            f.write(latex_table2)\n",
        "\n",
        "    print(f\"LaTeX tables saved to {output_dir}/\")\n",
        "\n",
        "def create_supplementary_analysis():\n",
        "    \"\"\"Generate supplementary analysis for extended results.\"\"\"\n",
        "\n",
        "    def analyze_prompt_influence():\n",
        "        \"\"\"Analyze how different prompt types influence AI art characteristics.\"\"\"\n",
        "        # This would analyze how prompt engineering affects embedding patterns\n",
        "        pass\n",
        "\n",
        "    def compute_diversity_metrics():\n",
        "        \"\"\"Compute various diversity metrics for AI vs human art.\"\"\"\n",
        "        # Shannon diversity, Simpson index, etc.\n",
        "        pass\n",
        "\n",
        "    def analyze_semantic_coherence():\n",
        "        \"\"\"Analyze semantic coherence using CLIP text embeddings.\"\"\"\n",
        "        # Compare visual and textual embeddings for semantic alignment\n",
        "        pass\n",
        "\n",
        "    return {\n",
        "        'prompt_analysis': analyze_prompt_influence(),\n",
        "        'diversity_metrics': compute_diversity_metrics(),\n",
        "        'semantic_coherence': analyze_semantic_coherence()\n",
        "    }\n",
        "\n",
        "# Advanced statistical functions\n",
        "\n",
        "def compute_multivariate_effect_sizes(group1_embeddings, group2_embeddings):\n",
        "    \"\"\"Compute multivariate effect sizes (Mahalanobis distance-based).\"\"\"\n",
        "    from scipy.linalg import inv\n",
        "\n",
        "    # Combined covariance matrix\n",
        "    combined_data = np.vstack([group1_embeddings, group2_embeddings])\n",
        "    cov_matrix = np.cov(combined_data.T)\n",
        "\n",
        "    # Group means\n",
        "    mean1 = np.mean(group1_embeddings, axis=0)\n",
        "    mean2 = np.mean(group2_embeddings, axis=0)\n",
        "\n",
        "    # Mahalanobis distance\n",
        "    try:\n",
        "        mahal_dist = np.sqrt((mean1 - mean2).T @ inv(cov_matrix) @ (mean1 - mean2))\n",
        "        return mahal_dist\n",
        "    except np.linalg.LinAlgError:\n",
        "        # Fallback to Euclidean if covariance matrix is singular\n",
        "        return np.linalg.norm(mean1 - mean2)\n",
        "\n",
        "def perform_permutation_tests(embeddings, labels, n_permutations=1000):\n",
        "    \"\"\"Perform permutation tests for clustering validity.\"\"\"\n",
        "    observed_silhouette = silhouette_score(embeddings, labels)\n",
        "\n",
        "    permuted_silhouettes = []\n",
        "    for _ in range(n_permutations):\n",
        "        permuted_labels = np.random.permutation(labels)\n",
        "        permuted_silhouette = silhouette_score(embeddings, permuted_labels)\n",
        "        permuted_silhouettes.append(permuted_silhouette)\n",
        "\n",
        "    p_value = np.mean(np.array(permuted_silhouettes) >= observed_silhouette)\n",
        "\n",
        "    return {\n",
        "        'observed_silhouette': observed_silhouette,\n",
        "        'permuted_silhouettes': permuted_silhouettes,\n",
        "        'p_value': p_value,\n",
        "        'significant': p_value < 0.05\n",
        "    }\n",
        "\n",
        "# Quality control and validation functions\n",
        "\n",
        "def validate_embedding_quality(embeddings, metadata):\n",
        "    \"\"\"Validate the quality and consistency of extracted embeddings.\"\"\"\n",
        "\n",
        "    # Check for NaN or infinite values\n",
        "    nan_count = np.sum(np.isnan(embeddings))\n",
        "    inf_count = np.sum(np.isinf(embeddings))\n",
        "\n",
        "    # Check embedding norms (should be close to 1 after normalization)\n",
        "    norms = np.linalg.norm(embeddings, axis=1)\n",
        "    norm_stats = {\n",
        "        'mean': np.mean(norms),\n",
        "        'std': np.std(norms),\n",
        "        'min': np.min(norms),\n",
        "        'max': np.max(norms)\n",
        "    }\n",
        "\n",
        "    # Check for duplicate embeddings\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    np.fill_diagonal(sim_matrix, 0)  # Remove self-similarity\n",
        "\n",
        "    duplicate_threshold = 0.999\n",
        "    potential_duplicates = np.sum(sim_matrix > duplicate_threshold)\n",
        "\n",
        "    quality_report = {\n",
        "        'total_embeddings': len(embeddings),\n",
        "        'nan_values': nan_count,\n",
        "        'inf_values': inf_count,\n",
        "        'norm_statistics': norm_stats,\n",
        "        'potential_duplicates': potential_duplicates,\n",
        "        'embedding_dimension': embeddings.shape[1],\n",
        "        'metadata_consistency': len(embeddings) == len(metadata)\n",
        "    }\n",
        "\n",
        "    # Print quality report\n",
        "    print(\"EMBEDDING QUALITY REPORT\")\n",
        "    print(\"-\" * 25)\n",
        "    for key, value in quality_report.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    return quality_report\n",
        "\n",
        "def export_embeddings_for_external_analysis(analyzer, output_file=\"embeddings_export.npz\"):\n",
        "    \"\"\"Export embeddings and metadata for external analysis tools.\"\"\"\n",
        "    np.savez_compressed(\n",
        "        output_file,\n",
        "        embeddings=analyzer.embeddings,\n",
        "        metadata=analyzer.metadata.to_dict('records'),\n",
        "        results=analyzer.results\n",
        "    )\n",
        "    print(f\"Embeddings exported to {output_file}\")\n",
        "\n",
        "def create_interactive_visualization(analyzer, output_file=\"interactive_viz.html\"):\n",
        "    \"\"\"Create interactive visualization using plotly.\"\"\"\n",
        "    try:\n",
        "        import plotly.graph_objects as go\n",
        "        import plotly.express as px\n",
        "        from plotly.subplots import make_subplots\n",
        "\n",
        "        # Get t-SNE coordinates\n",
        "        tsne_data = analyzer.results['dimensionality_reduction']['tsne']['embeddings']\n",
        "\n",
        "        # Create interactive scatter plot\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # Human artworks\n",
        "        human_mask = analyzer.metadata['source'] == 'human'\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=tsne_data[human_mask, 0],\n",
        "            y=tsne_data[human_mask, 1],\n",
        "            mode='markers',\n",
        "            name='Human Art',\n",
        "            text=analyzer.metadata[human_mask]['movement'],\n",
        "            hovertemplate='<b>%{text}</b><br>t-SNE 1: %{x}<br>t-SNE 2: %{y}',\n",
        "            marker=dict(size=8, opacity=0.7, color='blue')\n",
        "        ))\n",
        "\n",
        "        # AI artworks\n",
        "        ai_mask = analyzer.metadata['source'] == 'ai'\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=tsne_data[ai_mask, 0],\n",
        "            y=tsne_data[ai_mask, 1],\n",
        "            mode='markers',\n",
        "            name='AI Art',\n",
        "            text=analyzer.metadata[ai_mask]['model'],\n",
        "            hovertemplate='<b>%{text}</b><br>t-SNE 1: %{x}<br>t-SNE 2: %{y}',\n",
        "            marker=dict(size=8, opacity=0.7, color='orange')\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Interactive Latent Space Visualization',\n",
        "            xaxis_title='t-SNE Component 1',\n",
        "            yaxis_title='t-SNE Component 2',\n",
        "            hovermode='closest'\n",
        "        )\n",
        "\n",
        "        fig.write_html(output_file)\n",
        "        print(f\"Interactive visualization saved to {output_file}\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"Plotly not available for interactive visualization\")\n",
        "\n",
        "def compute_advanced_metrics(analyzer):\n",
        "    \"\"\"Compute advanced metrics for deeper analysis.\"\"\"\n",
        "\n",
        "    # Cluster validity indices\n",
        "    from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "    human_mask = analyzer.metadata['source'] == 'human'\n",
        "    ai_mask = analyzer.metadata['source'] == 'ai'\n",
        "    binary_labels = ai_mask.astype(int)\n",
        "\n",
        "    validity_metrics = {\n",
        "        'calinski_harabasz': calinski_harabasz_score(analyzer.embeddings, binary_labels),\n",
        "        'davies_bouldin': davies_bouldin_score(analyzer.embeddings, binary_labels),\n",
        "        'silhouette': silhouette_score(analyzer.embeddings, binary_labels)\n",
        "    }\n",
        "\n",
        "    # Nearest neighbor analysis\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "    nn_analyzer = NearestNeighbors(n_neighbors=6, metric='cosine')\n",
        "    nn_analyzer.fit(analyzer.embeddings)\n",
        "\n",
        "    # For each AI artwork, find nearest human artwork\n",
        "    ai_embeddings = analyzer.embeddings[ai_mask]\n",
        "    human_embeddings = analyzer.embeddings[human_mask]\n",
        "\n",
        "    nn_human = NearestNeighbors(n_neighbors=1, metric='cosine')\n",
        "    nn_human.fit(human_embeddings)\n",
        "\n",
        "    distances, indices = nn_human.kneighbors(ai_embeddings)\n",
        "    nearest_neighbor_stats = {\n",
        "        'mean_distance': np.mean(distances),\n",
        "        'std_distance': np.std(distances),\n",
        "        'median_distance': np.median(distances)\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'validity_metrics': validity_metrics,\n",
        "        'nearest_neighbor_stats': nearest_neighbor_stats\n",
        "    }\n",
        "\n",
        "# Publication-ready result formatting\n",
        "\n",
        "def format_results_for_paper(results):\n",
        "    \"\"\"Format numerical results for publication with appropriate precision.\"\"\"\n",
        "\n",
        "    def format_number(num, precision=3):\n",
        "        \"\"\"Format number with appropriate precision for publication.\"\"\"\n",
        "        if num is None:\n",
        "            return \"N/A\"\n",
        "        if isinstance(num, str):\n",
        "            return num\n",
        "        if abs(num) < 0.001:\n",
        "            return f\"{num:.2e}\"\n",
        "        elif abs(num) < 0.01:\n",
        "            return f\"{num:.4f}\"\n",
        "        else:\n",
        "            return f\"{num:.{precision}f}\"\n",
        "\n",
        "    formatted_results = {}\n",
        "\n",
        "    # Main statistical results\n",
        "    if 'statistical_analysis' in results:\n",
        "        stats = results['statistical_analysis']\n",
        "        formatted_results['statistics'] = {\n",
        "            'adi': format_number(stats['adi']),\n",
        "            'cohens_d': format_number(stats['effect_size']['cohens_d']),\n",
        "            'effect_interpretation': stats['effect_size']['interpretation'],\n",
        "            'mannwhitney_p': format_number(stats['mannwhitney_test']['p_value']),\n",
        "            'human_similarity_mean': format_number(stats['human_similarity_stats']['mean']),\n",
        "            'ai_similarity_mean': format_number(stats['ai_similarity_stats']['mean'])\n",
        "        }\n",
        "\n",
        "    # Clustering results\n",
        "    if 'clustering' in results:\n",
        "        cluster = results['clustering']\n",
        "        formatted_results['clustering'] = {\n",
        "            'kmeans_accuracy': format_number(cluster['kmeans']['accuracy']),\n",
        "            'kmeans_silhouette': format_number(cluster['kmeans']['silhouette_score']),\n",
        "            'kmeans_ari': format_number(cluster['kmeans']['ari']),\n",
        "            'dbscan_clusters': cluster['dbscan']['n_clusters'],\n",
        "            'dbscan_noise_ratio': format_number(cluster['dbscan']['noise_ratio'])\n",
        "        }\n",
        "\n",
        "    # Model signatures\n",
        "    if 'model_signatures' in results:\n",
        "        models = results['model_signatures']\n",
        "        formatted_results['model_signatures'] = {\n",
        "            'classification_accuracy': format_number(models['accuracy']),\n",
        "            'cv_mean': format_number(models['cv_mean']),\n",
        "            'cv_std': format_number(models['cv_std'])\n",
        "        }\n",
        "\n",
        "    return formatted_results\n",
        "\n",
        "def save_complete_results(analyzer, output_dir=\"complete_results\"):\n",
        "    \"\"\"Save all results in multiple formats for different use cases.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save as pickle for Python users\n",
        "    import pickle\n",
        "    with open(f\"{output_dir}/complete_analysis.pkl\", 'wb') as f:\n",
        "        pickle.dump({\n",
        "            'embeddings': analyzer.embeddings,\n",
        "            'metadata': analyzer.metadata,\n",
        "            'results': analyzer.results\n",
        "        }, f)\n",
        "\n",
        "    # Save as JSON for cross-platform compatibility\n",
        "    json_results = {}\n",
        "    for key, value in analyzer.results.items():\n",
        "        if isinstance(value, dict):\n",
        "            json_results[key] = {}\n",
        "            for subkey, subvalue in value.items():\n",
        "                if isinstance(subvalue, np.ndarray):\n",
        "                    json_results[key][subkey] = subvalue.tolist()\n",
        "                elif isinstance(subvalue, (np.integer, np.floating)):\n",
        "                    json_results[key][subkey] = float(subvalue)\n",
        "                else:\n",
        "                    json_results[key][subkey] = subvalue\n",
        "        else:\n",
        "            json_results[key] = value\n",
        "\n",
        "    with open(f\"{output_dir}/results.json\", 'w') as f:\n",
        "        json.dump(json_results, f, indent=2)\n",
        "\n",
        "    # Save embeddings as CSV for external tools\n",
        "    embedding_df = pd.DataFrame(analyzer.embeddings,\n",
        "                               columns=[f'dim_{i}' for i in range(analyzer.embeddings.shape[1])])\n",
        "    embedding_df = pd.concat([analyzer.metadata, embedding_df], axis=1)\n",
        "    embedding_df.to_csv(f\"{output_dir}/embeddings_with_metadata.csv\", index=False)\n",
        "\n",
        "    print(f\"Complete results saved to {output_dir}/\")\n",
        "\n",
        "# Example usage with detailed configuration\n",
        "def run_publication_ready_analysis():\n",
        "    \"\"\"\n",
        "    Complete analysis pipeline configured for publication results.\n",
        "    This function demonstrates the full workflow with all advanced features.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"PUBLICATION-READY LATENT AESTHETICS ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = LatentAestheticsAnalyzer()\n",
        "\n",
        "    # For demonstration, use synthetic data\n",
        "    # In real use, replace with: analyzer.run_complete_analysis(real_data_config)\n",
        "    embeddings, metadata = create_synthetic_dataset()\n",
        "    analyzer.embeddings = embeddings\n",
        "    analyzer.metadata = metadata\n",
        "\n",
        "    print(f\"Dataset loaded: {len(embeddings)} samples\")\n",
        "\n",
        "    # Core analysis pipeline\n",
        "    analyzer.perform_dimensionality_reduction()\n",
        "    analyzer.perform_clustering_analysis()\n",
        "    analyzer.analyze_model_signatures()\n",
        "    analyzer.analyze_movement_relationships()\n",
        "    analyzer.compute_statistical_comparisons()\n",
        "\n",
        "    # Advanced analyses\n",
        "    print(\"\\nPerforming advanced analyses...\")\n",
        "\n",
        "    # Robustness analysis\n",
        "    robustness_results = perform_robustness_analysis(analyzer, n_bootstrap=50)\n",
        "\n",
        "    # Cross-validation analysis\n",
        "    cv_results = perform_cross_validation_analysis(analyzer.embeddings, analyzer.metadata)\n",
        "\n",
        "    # Geometric analysis\n",
        "    geometry_results = analyze_embedding_geometry(analyzer.embeddings, analyzer.metadata)\n",
        "\n",
        "    # Quality validation\n",
        "    quality_report = validate_embedding_quality(analyzer.embeddings, analyzer.metadata)\n",
        "\n",
        "    # Generate all outputs\n",
        "    print(\"\\nGenerating publication outputs...\")\n",
        "    analyzer.generate_publication_figures()\n",
        "    analyzer.generate_results_table()\n",
        "    analyzer.generate_comprehensive_report()\n",
        "\n",
        "    # Generate LaTeX tables\n",
        "    formatted_results = format_results_for_paper(analyzer.results)\n",
        "    generate_latex_tables(analyzer.results)\n",
        "\n",
        "    # Save complete results\n",
        "    save_complete_results(analyzer)\n",
        "\n",
        "    # Create interactive visualization\n",
        "    create_interactive_visualization(analyzer)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ANALYSIS COMPLETE!\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(f\"\\nKey Findings:\")\n",
        "    print(f\"- ADI Score: {analyzer.results['statistical_analysis']['adi']:.3f}\")\n",
        "    print(f\"- Classification Accuracy: {analyzer.results['clustering']['kmeans']['accuracy']:.3f}\")\n",
        "    print(f\"- Effect Size: {analyzer.results['statistical_analysis']['effect_size']['interpretation']}\")\n",
        "\n",
        "    if 'model_signatures' in analyzer.results:\n",
        "        print(f\"- Model Classification: {analyzer.results['model_signatures']['accuracy']:.3f}\")\n",
        "\n",
        "    if 'movement_analysis' in analyzer.results:\n",
        "        csas_scores = analyzer.results['movement_analysis']['csas_scores']\n",
        "        top_movement = max(csas_scores.items(), key=lambda x: x[1])\n",
        "        print(f\"- Highest AI Affinity: {top_movement[0]} ({top_movement[1]:.3f})\")\n",
        "\n",
        "    print(f\"\\nFiles generated:\")\n",
        "    print(f\"- figures/: Publication-quality plots\")\n",
        "    print(f\"- results/: CSV tables\")\n",
        "    print(f\"- latex_tables/: LaTeX-formatted tables\")\n",
        "    print(f\"- complete_results/: Full analysis data\")\n",
        "    print(f\"- analysis_report.txt: Comprehensive text report\")\n",
        "    print(f\"- interactive_viz.html: Interactive visualization\")\n",
        "\n",
        "    return analyzer, {\n",
        "        'main_results': analyzer.results,\n",
        "        'robustness': robustness_results,\n",
        "        'cross_validation': cv_results,\n",
        "        'geometry': geometry_results,\n",
        "        'quality': quality_report,\n",
        "        'formatted': formatted_results\n",
        "    }\n",
        "\n",
        "# Run the complete analysis\n",
        "if __name__ == \"__main__\":\n",
        "    # Execute publication-ready analysis\n",
        "    analyzer, complete_results = run_publication_ready_analysis()\n",
        "\n",
        "    print(\"\\nAnalysis pipeline completed successfully!\")\n",
        "    print(\"All outputs ready for publication submission.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "4rSlnIPeQyjv",
        "outputId": "0dea5729-ac27-4251-d2e3-e51ae6ca94cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latent Aesthetics Analysis Pipeline\n",
            "========================================\n",
            "\n",
            "Option 1: Running with synthetic data...\n",
            "Running analysis on synthetic dataset...\n",
            "Error loading CLIP model: module 'clip' has no attribute 'load'\n",
            "Using synthetic embeddings for demonstration\n",
            "Generated synthetic dataset: 230 samples\n",
            "Human samples: 140\n",
            "AI samples: 90\n",
            "Performing dimensionality reduction...\n",
            "  Computing PCA...\n",
            "  Computing t-SNE...\n",
            "  Computing UMAP...\n",
            "Performing clustering analysis...\n",
            "  K-means clustering...\n",
            "  Hierarchical clustering...\n",
            "  DBSCAN clustering...\n",
            "  Gaussian Mixture Model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "`x` and `y` must be broadcastable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method, axis)\u001b[0m\n\u001b[1;32m   4670\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4671\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4672\u001b[0m         \u001b[0;31m# For consistency with other `stats` functions, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_stride_tricks_impl.py\u001b[0m in \u001b[0;36mbroadcast_shapes\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_stride_tricks_impl.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (26335,) and arg 1 with shape (229,).",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-452727690.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;31m# Additional utility functions for advanced analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-452727690.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[0;31m# Option 1: Run with synthetic data (for demonstration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOption 1: Running with synthetic data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m     \u001b[0mresults_synthetic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_synthetic_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;31m# Option 2: Template for real data analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-452727690.py\u001b[0m in \u001b[0;36mrun_synthetic_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[0;31m# Run analyses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_dimensionality_reduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m     \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_clustering_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m     \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_model_signatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_movement_relationships\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-452727690.py\u001b[0m in \u001b[0;36mperform_clustering_analysis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m             'hierarchical': {\n\u001b[1;32m    329\u001b[0m                 \u001b[0;34m'linkage_matrix'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlinkage_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 'cophenetic_corr': stats.pearsonr(pdist(self.embeddings), \n\u001b[0m\u001b[1;32m    331\u001b[0m                                                  linkage_matrix[:, 2])[0]\n\u001b[1;32m    332\u001b[0m             },\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method, axis)\u001b[0m\n\u001b[1;32m   4680\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4681\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'`x` and `y` must be broadcastable.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4682\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4684\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `x` and `y` must be broadcastable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMuVZveQQym2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5HxnoaIvQyqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Un_ECntQyvN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}