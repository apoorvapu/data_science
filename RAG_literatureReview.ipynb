{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq3zIOCofySQ"
   },
   "source": [
    "Generative AI in Research: using Large Language Models (LLMs) to enhance and streamline the academic literature review process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_-IHuLTAh-u"
   },
   "source": [
    "leverage RAG Techniques for summarizing papers, identifying connections across papers (authors, references, methods), uncovering key themes in them.\n",
    "\n",
    "Download 2 papers (related to diffusion model) and convert them to .txt files in a directory named \"data\". Use these .txt files as input papers and evaluate if the RAG technique is giving good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbRT1J6xiGMC"
   },
   "source": [
    "### download any 2 papers of diffusion model and convert their pdf to .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2006.11239\n",
      "Converted to text: data/2006.11239.txt\n",
      "Downloaded 2105.05233\n",
      "Converted to text: data/2105.05233.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Sample arXiv paper IDs related to diffusion models\n",
    "arxiv_ids = [\n",
    "    \"2006.11239\",  # Denoising Diffusion Probabilistic Models\n",
    "    \"2105.05233\",  # Improved Denoising Diffusion Probabilistic Models\n",
    "]\n",
    "\n",
    "def download_pdf(arxiv_id, output_folder):\n",
    "    url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "    pdf_path = os.path.join(output_folder, f\"{arxiv_id}.pdf\")\n",
    "    response = requests.get(url)\n",
    "    with open(pdf_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded {arxiv_id}\")\n",
    "    return pdf_path\n",
    "\n",
    "def pdf_to_text(pdf_path, txt_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    print(f\"Converted to text: {txt_path}\")\n",
    "\n",
    "def main():\n",
    "    data_dir = \"data\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    for arxiv_id in arxiv_ids:\n",
    "        pdf_path = download_pdf(arxiv_id, data_dir)\n",
    "        txt_path = os.path.join(data_dir, f\"{arxiv_id}.txt\")\n",
    "        pdf_to_text(pdf_path, txt_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/*.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install langchain langchain_community faiss-cpu sentence-transformers transformers networkx matplotlib spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import gc\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "gc.collect()\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad7fc45e6f6465aaf68bac8a8c047a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "<ipython-input-7-ae6dbeb04d27>:48: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  return HuggingFacePipeline(pipeline=pipe)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Processing: data/2105.05233.txt\n",
      "\n",
      "🔍 Summary:\n",
      "We show that diffusion models can achieve image sample quality superior to the current stateoftheart generative models. We achieve this on unconditional im age synthesis by nding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classier guidance: a simple, computeefcient method for trading off diversity for delity using gradients from a classier. We achieve an FID of 2.97 on ImageNet 128128, 4.59 on ImageNet 256256, and 7.72 on ImageNet 512512, and we match BigGANdeep even with as few as 25 forward passes per sample. Finally, we nd that classier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256256 and 3.85 on ImageNet 512512. We release our code at 1 Introduction\n",
      "\n",
      "🔍 Connections:\n",
      "ImageNet 512512 images, they are not yet capable of producing highquality images.\n",
      "\n",
      "🔍 Themes:\n",
      "Image Synthesis\n",
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We introduce a new class of likelihoodbased models called diffusion models, which are able to produce highquality images while capturing more diversity than GANs. We show that these models can be trained to produce images with a wallclock time of .\n",
      "\n",
      "🔍 Connections:\n",
      "is based on a stationary objective.\n",
      "\n",
      "🔍 Themes:\n",
      "GANs, VAEs, Diffusion Models\n",
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We introduce a new stateoftheart model for diffusion models, based on the architectures of GANs. We achieve a new stateoftheart, surpassing GANs on several different metrics and datasets.\n",
      "\n",
      "🔍 Connections:\n",
      "Diffusion models are a class of models that produce samples from a distribution by removing noise from a signal.\n",
      "\n",
      "🔍 Themes:\n",
      "Diffusion models for generating images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We introduce a new architecture for diffusion models that improves FID and enables a classier to guide the model during sampling. We show that our architecture achieves stateoftheart on unconditional image synthesis tasks and with classier guidance achieve stateoftheart on conditional image synthesis.\n",
      "\n",
      "🔍 Connections:\n",
      "We use a gradient from a classier to guide a diffusion model during sampling.\n",
      "\n",
      "🔍 Themes:\n",
      "We improve the architecture of diffusion models by introducing a new architecture that combines a classier with a gradient guide.\n",
      "\n",
      "🔍 Summary:\n",
      "--- with some noise where the signal to noise ratio is determined by the timestep t. For the remainder of this paper, we assume that the noise is drawn from a diagonal Gaussian distribution, which works well for natural images and simplies various derivations. 2 A diffusion model learns to produce a slightly more denoised xt1 from xt. To train these models, each sample in a minibatch is produced by randomly drawing a data sample x0, a timestep t, and noise , which gives rise to a noisy sample xt Equation 17. The training objective is then xt, t 2, i.e. a simple meansquared error loss between the true noise and the predicted noise Equation 18. It is not immediately obvious how to sample from a noise predictor xt, t. Recall that diffusion sampling proceeds by repeatedly predicting xt1 from xt, starting from xT . Ho et al. show that, under reasonable assumptions, we can model the distribution pxt1xt of xt1 given xt as a diagonal Gaussian Nxt1; xt, t, xt, t, where the mean xt, t can be calculated as a function of xt, t Equation 19. Ho et al. observe that the simple meansqaured error objective, Lsimple, works better in practice than the more complex Lsimple objective, Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple + Lsimple\n",
      "\n",
      "🔍 Connections:\n",
      "Lsimple, and that the variance of the Gaussian distribution can be learned with a separate neural network head.\n",
      "\n",
      "🔍 Themes:\n",
      "--- Diffusion sampling with noise predictors\n",
      "\n",
      "🔍 Summary:\n",
      "--- Main contribution: We propose a new model for denoising diffusion models that is a hybrid of Ho et al. 's and Nichol and Dhariwal 's models. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We also train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a hybrid objective and parameterization, and use a weighted sum Lsimple Lvlb for training both xt, t and xt, t. We train the model with a\n",
      "\n",
      "🔍 Connections:\n",
      "Nichol and Dhariwal 's t and t to train the reverse process variances.\n",
      "\n",
      "🔍 Themes:\n",
      "Denoising Diffus sion Models\n",
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We propose a new sampling approach for generative models, based on DDIM. We use DDIM when sampling with fewer than 50 sampling steps. We evaluate sample quality using the following metrics: Inception Score IS Frchet Inception Distance FID\n",
      "\n",
      "🔍 Connections:\n",
      ", and it measures how well a model captures the full distribution of a class while still producing individual samples that are convincing examples of a single class.\n",
      "\n",
      "🔍 Themes:\n",
      "DDPM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DDIM DD\n",
      "\n",
      "🔍 Summary:\n",
      "--- InceptionV3 dataset used for evaluation. --- Inception Distance (FID) is the de facto standard metric for generative models. --- Precision or IS is used to measure delity. --- Recall is used to measure diversity. ---\n",
      "\n",
      "🔍 Connections:\n",
      "We use FID as our default metric for overall sample quality comparisons as it captures both diversity and delity and has been the de facto standard metric for stateoftheart generative modeling work . We use Precision or IS to measure delity, and Recall to measure diversity or distribution coverage. When comparing against other methods, we recompute these metrics using public samples or models whenever\n",
      "\n",
      "🔍 Themes:\n",
      "--- Inception Distance FID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID sFID\n",
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We show that architecture can indeed give a substantial boost to sample quality on much larger and more diverse datasets at a higher resolution.\n",
      "\n",
      "🔍 Connections:\n",
      "Ho et al. introduced the UNet architecture for diffusion models. Song et al. found that further changes to the UNet architecture improved performance on the CIFAR10 and CelebA64 datasets.\n",
      "\n",
      "🔍 Themes:\n",
      "--- Architecture Improvements\n",
      "\n",
      "🔍 Summary:\n",
      "--- We explore architecture changes to improve FID and efciency of a deep neural network. We train models with the following architecture changes: Increasing depth versus width, holding model size relatively constant. Increasing the number of attention heads. Using attention at 3232, 1616, and 88 resolutions rather than only at 1616. Rescaling residual connections with 1 2, following . For all comparisons, we train models on ImageNet 128128 with batch size 256, and sample using 250 sampling steps. We train models with the above architecture changes and compare 4 Number of heads Channels per head FID 1 14.08 2 0.50 4 0.97 8 1.17 32 1.36 64 1.03 128 1.08 Table 2: Ablation of various attention congurations. More heads or lower channels per heads both lead to improved FID. 40 60 80 100 120 140 160 180 time hrs 14 16 18 20 22 24 26 FID 1 head 2 heads 4 heads 8 heads 32 head channels 64 head channels 128 head channels Figure 2: Ablation of various architecture changes, showing FID as a function of wallclock time. FID evaluated over 10k samples instead of 50k for efciency. Operation FID AdaGN 13.06 Addition GroupNorm 15.08\n",
      "\n",
      "🔍 Connections:\n",
      "FID\n",
      "\n",
      "🔍 Themes:\n",
      "--- Using BigGAN for upsampling and downsampling the activations\n",
      "\n",
      "📄 Processing: data/2006.11239.txt\n",
      "\n",
      "🔍 Summary:\n",
      "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models nat urally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a stateoftheart FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.\n",
      "\n",
      "🔍 Connections:\n",
      "Denoising Diffusion Probabilistic Models\n",
      "\n",
      "🔍 Themes:\n",
      "Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Deno\n",
      "\n",
      "🔍 Summary:\n",
      "This paper presents progress in diffusion probabilistic models . A diffusion probabilistic model which we will call a diffusion model for brevity is a parameterized Markov chain trained using variational inference to produce samples matching the data after nite time. Transitions of this chain are learned to reverse a diffusion process, which is a Markov chain that gradually adds noise to the data in the opposite direction of sampling until signal is destroyed. When the diffusion consists of small amounts of Gaussian noise, it is sufcient to set the sampling chain transitions to conditional Gaussians too, allowing for a particularly simple neural network parameterization. We show that diffusion models actually are capable of generating high quality samples, sometimes better than the published results on other types of generative models Section 4.\n",
      "\n",
      "🔍 Connections:\n",
      "We show that a certain parameterization of diffusion models reveals an equivalence with denoising score matching over multiple noise levels during training and with annealed Langevin dynamics during sampling\n",
      "\n",
      "🔍 Themes:\n",
      "Diffusion Probabilistic Models\n",
      "\n",
      "🔍 Summary:\n",
      "--- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with annealed Langevin dynamics during sampling --- with anne\n",
      "\n",
      "🔍 Connections:\n",
      ", is a continuous function of the x0:T , and the forward qx1:T x0 is a continuous function of the x0:T , where x0:T is the x0:T , and x0:T is the x0:T .\n",
      "\n",
      "🔍 Themes:\n",
      "Diffusion models with annealed Langevin dynamics during sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We introduce a new method for learning the posterior of a forward process from a pxt1xt model. The forward process is xed to a Markov chain that gradually adds Gaussian noise to the data according to a variance schedule 1, . . ., T: qx1:T x0 : T Y t1 qxtxt1, qxtxt1 : Nxt; p1 txt1, tI 2 Training is performed by optimizing the usual variational bound on negative log likelihood: E log px0 Eq log px0:T qx1:T x0 Eq log pxT X t1 log pxt1xt qxtxt1 : L 3 The forward process variances t can be learned by reparameterization or held constant as hyperparameters, and expressiveness of the reverse process is ensured in part by the choice of Gaussian conditionals in pxt1xt, because both processes have the same functional form when t is small . Equation 5 uses KL divergence to directly compare pxt1xt against forward process posteriors, which are tractable when conditioned on x0: qxt1xt, x0 Nxt1; txt, x0, tI, where txt, x0: t1t 1 t x0 t1 t1 1 t xt and t : 1 t1 1 t t\n",
      "\n",
      "🔍 Connections:\n",
      "---\n",
      "\n",
      "🔍 Themes:\n",
      "Forward and Reverse Processes\n",
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We introduce a new explicit connection between diffusion models and denoising score matching. We use this connection to guide our model design. We discuss our choices in pxt1xt Nxt1; xt, t, xt, t for 1 t T. First, we set xt, t 2 t I to untrained time dependent constants. Experimentally, both 2 t t and 2 t t 1t1 1t t had similar results. The rst choice is optimal for x0 N0, I, t.\n",
      "\n",
      "🔍 Connections:\n",
      "--- all KL divergences in Eq. 5 are comparisons between Gaussians, so they can be calculated in a RaoBlackwellized fashion with closed form expressions instead of high variance Monte Carlo estimates.\n",
      "\n",
      "🔍 Themes:\n",
      "Diffusion models and denoising autoencoders\n",
      "\n",
      "🔍 Summary:\n",
      "Main contribution: We propose a novel method for estimating the mean of a reverse process. We show that the mean is a function of the txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt, txt,\n",
      "\n",
      "🔍 Connections:\n",
      "entropy of the forward process is a function approximating the entropy of the reverse process.\n",
      "\n",
      "🔍 Themes:\n",
      "--- Reverse process entropy for data with coordinatewise unit variance\n",
      "\n",
      "🔍 Summary:\n",
      "Data scaling, reverse process decoder, and L0 We assume that the image data consists of integers in 0, 1, . . . , 255 scaled linearly to 1, 1. This ensures that the neural network reverse process operates on consistently scaled data.\n",
      "\n",
      "🔍 Connections:\n",
      "data.\n",
      "\n",
      "🔍 Themes:\n",
      "Data scaling, reverse process decoder, and L0\n",
      "\n",
      "🔍 Summary:\n",
      "--- Reverse process and discrete decoder for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods. --- Variational bound for discrete log likelihoods.\n",
      "\n",
      "🔍 Connections:\n",
      "EBM 6.78 38.2 PixelIQN 5.29 49.46 EBM 6.78 38.2\n",
      "\n",
      "🔍 Themes:\n",
      "Variational bounds for discrete log likelihoods\n",
      "\n",
      "🔍 Summary:\n",
      "--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---\n",
      "\n",
      "🔍 Connections:\n",
      "---\n",
      "\n",
      "🔍 Themes:\n",
      "Variational bound for a reconstructed image\n",
      "\n",
      "🔍 Summary:\n",
      "--- of reconstruction compared to the standard variational bound . In particular, our diffusion process setup in Section 4 causes the simplied objective to downweight loss terms corresponding to small t. These terms train the network to denoise data with very small amounts of noise, so it is benecial to downweight them so that the network can focus on more difcult denoising tasks at larger t terms. We will see in our experiments that this reweighting leads to better sample quality.\n",
      "\n",
      "🔍 Connections:\n",
      "Inception score is .\n",
      "\n",
      "🔍 Themes:\n",
      "--- reweighting loss terms corresponding to small t\n",
      "Error generating final Summary: CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 150.12 MiB is free. Process 340999 has 14.59 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 26.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Final Summary:\n",
      "Error\n",
      "\n",
      "Final Connections Across Papers:\n",
      "Diffusion models are a class of models that produce samples from a distribution by removing noise from a signal. We use a gradient from a classier to guide a diffusion model during sampling. FID is the de facto standard metric for stateoftheart generative modeling work . We use Precision or IS to measure delity, and Recall to measure diversity or distribution coverage. When comparing against other methods, we recompute these metrics using public samples or models whenever Ho et al. introduced the UNet architecture for diffusion models. Song et al. found that further changes to the UNet architecture improved performance on the CIFAR10 and CelebA64 datasets. FID Denoising Diffusion Probabilistic Models\n",
      "\n",
      "Final Themes:\n",
      "Image Synthesis Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Denoising Deno\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    # Remove inline citations like [14], [14, 27]\n",
    "    text = re.sub(r\"\\[[0-9,\\s]+\\]\", \"\", text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", text)\n",
    "    # Remove LaTeX math expressions\n",
    "    text = re.sub(r\"\\$.*?\\$\", \"\", text)\n",
    "    # Remove repeated words\n",
    "    text = re.sub(r\"\\b(\\w+)( \\1\\b)+\", r\"\\1\", text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,;:?!\\s]\", \"\", text)\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Load a document and return its content\n",
    "def load_document(file_path):\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    for doc in docs:\n",
    "        doc.page_content = clean_text(doc.page_content)  # Apply cleaning here\n",
    "    return docs\n",
    "\n",
    "# Split the document into chunks ensuring each chunk is under the token limit\n",
    "def split_document(docs, chunk_size=1500, chunk_overlap=50):\n",
    "    # Make sure docs is always a list\n",
    "    if not isinstance(docs, list):\n",
    "        docs = [docs]\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "# Vector store (use sentence embeddings)\n",
    "def create_faiss_index(docs):\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    return FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Load HuggingFace LLM\n",
    "def load_llm():\n",
    "    model_id = \"google/flan-t5-xl\"  # Better GPU utilization, faster than flan-t5-large\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(\"cuda\")  # Move model to GPU\n",
    "    #pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "    pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0, max_new_tokens=512)\n",
    "\n",
    "    return HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "# Build RAG chain\n",
    "def build_qa_chain(llm, vectorstore):\n",
    "    return RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), chain_type=\"stuff\")\n",
    "\n",
    "# Analyze a single document in chunks and store results with a chunk limit\n",
    "def analyze_document(llm, docs, batch_size=1, max_chunks=10):\n",
    "    results = {\"Summary\": [], \"Connections\": [], \"Themes\": []}\n",
    "    chunks = split_document(docs)\n",
    "    chunks = chunks[:max_chunks]\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "\n",
    "        for label, q in [\n",
    "            (\"Summary\", \"Summarize the following scientific paper text in concise bullet points. Include: Main contribution, Dataset used, method, Evaluation metrics and Key results.\"),\n",
    "            (\"Connections\", \"You are reading several research papers. Based on the passage below, what connections or similarities can you identify with other papers on diffusion models? Mention common techniques, models, datasets, or evaluation strategies.\"),\n",
    "            (\"Themes\", \"What are the central *research themes* in the following paper? List them as concise topics.\")\n",
    "        ]:\n",
    "            prompts = [f\"{q}\\n\\n---\\n{chunk.page_content.strip()}\" for chunk in batch]\n",
    "            try:\n",
    "                responses = llm.pipeline(prompts)\n",
    "                for response in responses:\n",
    "                    text = response['generated_text'].strip()\n",
    "                    results[label].append(text)\n",
    "                    print(f\"\\n🔍 {label}:\\n{text}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during {label} batch: {e}\")\n",
    "                results[label].extend([\"Error\"] * len(batch))\n",
    "\n",
    "        del batch\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Main pipeline\n",
    "def process_all_documents(data_dir=\"data\", max_chunks=10):\n",
    "    files = glob.glob(os.path.join(data_dir, \"*.txt\"))\n",
    "    results = {\"Summary\": [], \"Connections\": [], \"Themes\": []}\n",
    "\n",
    "    llm = load_llm()\n",
    "\n",
    "    for file_path in files:\n",
    "        print(f\"\\n📄 Processing: {file_path}\")\n",
    "        # Load and clean the document\n",
    "        doc = load_document(file_path)\n",
    "\n",
    "        # Process the document in chunks\n",
    "        doc_results = analyze_document(llm, docs=doc, max_chunks=max_chunks)\n",
    "\n",
    "        # Collect results\n",
    "        for label in results:\n",
    "            results[label].extend(doc_results.get(label, []))\n",
    "\n",
    "        # Free up GPU memory after processing each document\n",
    "        del doc\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  # Run garbage collection to free memory\n",
    "\n",
    "    # Clean-up results (e.g., remove empty strings or redundant entries)\n",
    "    for label in results:\n",
    "        flat = [str(item).strip() for sublist in results[label] for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "        cleaned = [s for s in flat if s and s.lower() != \"error\"]\n",
    "        combined_text = \"\\n\".join(cleaned)\n",
    "\n",
    "        if label == \"Themes\":\n",
    "          final_theme = summarize_combined_output(llm, combined_text, label) # Remove duplicates\n",
    "          themes = list(dict.fromkeys([line.strip() for line in final_theme.split(\"\\n\") if line.strip()]))\n",
    "          results[label] = \"\\n\".join(themes)\n",
    "        else:\n",
    "          results[label] = summarize_combined_output(llm, combined_text, label)\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "# Summarize combined chunk outputs into a single final output\n",
    "def summarize_combined_output(llm, text, label):\n",
    "    prompts = {\n",
    "        \"Summary\": \"You are a helpful scientific assistant. Based on the following combined summaries of a scientific paper, provide a single concise overall summary. Mention the main contribution, dataset used, method, evaluation metrics, and key results.\",\n",
    "        \"Connections\": \"You are reading several research papers. Based on the following notes, summarize the common connections or similarities across papers, focusing on shared techniques, datasets, or models.\",\n",
    "        \"Themes\": \"Summarize the central research themes mentioned in the combined text below. List them as concise, broad topics.\"\n",
    "    }\n",
    "    prompt = f\"{prompts[label]}\\n\\n{text}\"\n",
    "    try:\n",
    "        response = llm.pipeline(prompt)\n",
    "        return response[0][\"generated_text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating final {label}: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "# Main execution\n",
    "results = process_all_documents(data_dir=\"data\", max_chunks=10)  # Limit the number of chunks for faster processing\n",
    "# Final outputs\n",
    "final_connections = results.get(\"Connections\", \"\")\n",
    "final_themes = results.get(\"Themes\", \"\")\n",
    "final_summary = results.get(\"Summary\", \"\")\n",
    "\n",
    "# Display summaries\n",
    "print(\"\\nFinal Summary:\")\n",
    "print(final_summary)\n",
    "print(\"\\nFinal Connections Across Papers:\")\n",
    "print(final_connections)\n",
    "print(\"\\nFinal Themes:\")\n",
    "print(final_themes)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
