{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Gemma2 for multilingual translation\n",
    "\n",
    "The goal of this notebook submission for the [Google - Unlock Global Communication with Gemma](https://www.kaggle.com/competitions/gemma-language-tuning) competition is to demonstrate how to finetune Gemma2 for the task of translating between multiple languages (currently 8), using a curated bible dataset.\n",
    "\n",
    "\n",
    "\n",
    "# Bible Dataset\n",
    "\n",
    "Here we load in a multilingual dataset of full text bibles, which we'll use for finetuning on a translation tasks in various languages. \n",
    "\n",
    "I'm using the Multilingual Full Text Bible dataset which can be found [here](https://www.kaggle.com/datasets/jordanyoung993/multi-lingual-full-text-bible). \n",
    "\n",
    "This dataset was created by myself using [pybible](https://github.com/Jordan-M-Young/pybible) a custom built python library that I also authored myself. \n",
    "\n",
    "This library wraps the API exposed by https://scripture.api.bible/ a bible repository website. Bible texts are compiled by this library and then merged by verse. \n",
    "\n",
    "The following table shows which languagues are currently supported by this dataset.\n",
    "\n",
    "- English\n",
    "- Polish\n",
    "- Czech\n",
    "- Thai\n",
    "- Persian\n",
    "- Italian\n",
    "- Gujarati\n",
    "- Swahili\n",
    "\n",
    "\n",
    "\n",
    "# Why the Bible?\n",
    "\n",
    "Aside from any artistic and historic merits, the bible is a lexically diverse text containing ~ 14,000 unique words (in English) . The bible is also a very structured text, it is organized into books, chapters, and at its most granular, verses. Verses are the atoms that compose a bible and each specific verse, regardless of bible version, contains essentially the same nugget of information. This makes the bible a useful tool as bible verses provide discrete chunks of text that convey more or less the same semantic information regardless of language. Thus we use the bible here to fine-tune gemma2 on translation tasks.\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "Aside from qualitative assesments, this notebook will also quantitatively evaluate the responses of the base model and the finetuned respectively. I will use the following metrics to do this: \n",
    "- Jaccard similarity\n",
    "- [BLEU](https://en.wikipedia.org/wiki/BLEU)\n",
    "- [METEOR](https://en.wikipedia.org/wiki/METEOR)\n",
    "- [NIST](https://en.wikipedia.org/wiki/NIST_(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-15T21:24:06.519578Z",
     "iopub.status.busy": "2024-10-15T21:24:06.519031Z",
     "iopub.status.idle": "2024-10-15T21:24:07.263957Z",
     "shell.execute_reply": "2024-10-15T21:24:07.262668Z",
     "shell.execute_reply.started": "2024-10-15T21:24:06.519505Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:24:07.267358Z",
     "iopub.status.busy": "2024-10-15T21:24:07.266792Z",
     "iopub.status.idle": "2024-10-15T21:25:33.239219Z",
     "shell.execute_reply": "2024-10-15T21:25:33.237602Z",
     "shell.execute_reply.started": "2024-10-15T21:24:07.267305Z"
    }
   },
   "outputs": [],
   "source": [
    "#By Gabriel Preda https://www.kaggle.com/code/gpreda/fine-tuning-gemma-2-model-using-lora-and-keras/notebook\n",
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "!pip install -q -U kagglehub --upgrade\n",
    "!pip install tqdm\n",
    "!pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:25:33.242258Z",
     "iopub.status.busy": "2024-10-15T21:25:33.241732Z",
     "iopub.status.idle": "2024-10-15T21:25:35.486098Z",
     "shell.execute_reply": "2024-10-15T21:25:35.483575Z",
     "shell.execute_reply.started": "2024-10-15T21:25:33.242202Z"
    }
   },
   "outputs": [],
   "source": [
    "# get bible text data\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "with open(\"/kaggle/input/multi-lingual-full-text-bible/merged_bibles.json\",'r',encoding='utf-8') as jfile:\n",
    "    data = json.loads(jfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:25:35.489495Z",
     "iopub.status.busy": "2024-10-15T21:25:35.488839Z",
     "iopub.status.idle": "2024-10-15T21:25:35.502434Z",
     "shell.execute_reply": "2024-10-15T21:25:35.500623Z",
     "shell.execute_reply.started": "2024-10-15T21:25:35.489442Z"
    }
   },
   "outputs": [],
   "source": [
    "# check data loaded...\n",
    "\n",
    "data['GEN.1.1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:25:35.50806Z",
     "iopub.status.busy": "2024-10-15T21:25:35.507522Z",
     "iopub.status.idle": "2024-10-15T21:25:40.43886Z",
     "shell.execute_reply": "2024-10-15T21:25:40.436779Z",
     "shell.execute_reply.started": "2024-10-15T21:25:35.50801Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate sentence pair rows\n",
    "def generate_sentence_pairs(data: dict):\n",
    "    forward_pairs = []\n",
    "    reverse_pairs = []\n",
    "    for verse_id, verse_texts in data.items():\n",
    "        for idx, verse in enumerate(verse_texts):\n",
    "            for jdx, verse2 in enumerate(verse_texts):\n",
    "                if idx >= jdx:\n",
    "                    continue\n",
    "                \n",
    "                lang_a = list(verse.keys())[0]\n",
    "                text_a = list(verse.values())[0]\n",
    "                \n",
    "                lang_b = list(verse2.keys())[0]\n",
    "                text_b = list(verse2.values())[0]\n",
    "                \n",
    "                row_a = [verse_id, lang_a,text_a, lang_b, text_b]\n",
    "                row_b =  [verse_id, lang_b, text_b, lang_a, text_a]\n",
    "                \n",
    "                forward_pairs.append(row_a)\n",
    "                reverse_pairs.append(row_b)\n",
    "                \n",
    "    return forward_pairs, reverse_pairs\n",
    "\n",
    "\n",
    "\n",
    "forward_pairs, reverse_pairs = generate_sentence_pairs(data)\n",
    "\n",
    "print(\"Forward Pair:\",forward_pairs[0])\n",
    "print(\"Reverse Pair:\",reverse_pairs[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:25:40.441679Z",
     "iopub.status.busy": "2024-10-15T21:25:40.440743Z",
     "iopub.status.idle": "2024-10-15T21:25:40.845019Z",
     "shell.execute_reply": "2024-10-15T21:25:40.84286Z",
     "shell.execute_reply.started": "2024-10-15T21:25:40.441598Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "train_queries = []\n",
    "for pair in forward_pairs[:300]:\n",
    "    \n",
    "    language_a = pair[1].split()[0].replace(\",\",\"\")\n",
    "    language_b = pair[3].split()[0].replace(\",\",\"\")\n",
    "    text_a = pair[2]\n",
    "    text_b = pair[4]\n",
    "    query = f\"Translate: {text_a}\\nFrom {language_a} to {language_b}\\nResponse:\\n{text_b}\"\n",
    "    train_queries.append(query)\n",
    "    \n",
    "# del(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:25:40.847984Z",
     "iopub.status.busy": "2024-10-15T21:25:40.84737Z",
     "iopub.status.idle": "2024-10-15T21:25:48.873079Z",
     "shell.execute_reply": "2024-10-15T21:25:48.87166Z",
     "shell.execute_reply.started": "2024-10-15T21:25:40.847901Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"\"\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "#Make yours and Add copy to clipboard\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "secret_value_1 = user_secrets.get_secret(\"username\")\n",
    "\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(777)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:25:48.876253Z",
     "iopub.status.busy": "2024-10-15T21:25:48.875175Z",
     "iopub.status.idle": "2024-10-15T21:27:32.739512Z",
     "shell.execute_reply": "2024-10-15T21:27:32.738455Z",
     "shell.execute_reply.started": "2024-10-15T21:25:48.876185Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "gemma_causal_lm = keras_nlp.models.GemmaCausalLM.from_preset('gemma2_2b_en')\n",
    "gemma_causal_lm.backbone.enable_lora(rank=4)\n",
    "\n",
    "\n",
    "gemma_causal_lm.preprocessor.sequence_length = 100\n",
    "\n",
    "gemma_causal_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a small test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:27:32.742302Z",
     "iopub.status.busy": "2024-10-15T21:27:32.74121Z",
     "iopub.status.idle": "2024-10-15T21:27:32.785211Z",
     "shell.execute_reply": "2024-10-15T21:27:32.784058Z",
     "shell.execute_reply.started": "2024-10-15T21:27:32.742242Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate a small test set\n",
    "count = 0\n",
    "test_queries = []\n",
    "test_answers = []\n",
    "l = len(forward_pairs)\n",
    "for pair in forward_pairs[500:l-1]:\n",
    "    language_a = pair[1].split()[0].replace(\",\",\"\")\n",
    "    if language_a != \"English\":\n",
    "\n",
    "        continue\n",
    "    language_b = pair[3].split()[0].replace(\",\",\"\")\n",
    "    text_a = pair[2]\n",
    "    text_b = pair[4]\n",
    "    query = f\"Translate: {text_a}\\nFrom {language_a} to {language_b}\\nResponse:\"\n",
    "    target_answer = text_b\n",
    "    test_queries.append(query)\n",
    "    test_answers.append(target_answer)\n",
    "    count += 1\n",
    "    \n",
    "    if count == 7:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:27:32.787125Z",
     "iopub.status.busy": "2024-10-15T21:27:32.786733Z",
     "iopub.status.idle": "2024-10-15T21:35:37.562284Z",
     "shell.execute_reply": "2024-10-15T21:35:37.561014Z",
     "shell.execute_reply.started": "2024-10-15T21:27:32.787077Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate translation completions with base model\n",
    "\n",
    "responses = gemma_causal_lm.generate(\n",
    "            test_queries,\n",
    "            max_length=100)\n",
    "\n",
    "base_predict_answers = []\n",
    "for response in responses:\n",
    "    \n",
    "    answer = response.split(\"Response:\")[-1].replace(\"\\n\",\"\")\n",
    "    base_predict_answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting evaluation metrics for base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:35:37.564525Z",
     "iopub.status.busy": "2024-10-15T21:35:37.564156Z",
     "iopub.status.idle": "2024-10-15T21:35:39.056816Z",
     "shell.execute_reply": "2024-10-15T21:35:39.055589Z",
     "shell.execute_reply.started": "2024-10-15T21:35:37.564485Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.translate import nist_score, bleu_score\n",
    "\n",
    "def jaccard_similarity(set_a: set, set_b: set) -> float:\n",
    "    return len(set_a.intersection(set_b)) / len(set_a.union(set_b))\n",
    "\n",
    "\n",
    "base_evaluation_data = []\n",
    "chencherry = bleu_score.SmoothingFunction()\n",
    "for idx, target_answer in enumerate(test_answers):\n",
    "    set_a = set(base_predict_answers[idx].split())\n",
    "    set_b = set(target_answer.split())\n",
    "    try:\n",
    "        x = nist_score.sentence_nist([base_predict_answers[idx].split()],target_answer.split())\n",
    "        y = bleu_score.sentence_bleu([base_predict_answers[idx].split()],target_answer.split(),smoothing_function=chencherry.method1)\n",
    "        z = jaccard_similarity(set_a, set_b)\n",
    "        base_evaluation_data.append({\"query\":test_queries[idx],\"bleu\":y,\"nist\":x,\"jacc\":z})\n",
    "        \n",
    "        print(\"Jaccard Similarity\",z, \"NIST\",x, \"BLEU\",y)\n",
    "    except:\n",
    "        z = jaccard_similarity(set_a, set_b)\n",
    "        print(\"Jaccard Similarity\",z)\n",
    "        base_evaluation_data.append({\"query\":test_queries[idx],\"bleu\":0,\"nist\":0,\"jacc\":z})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:35:39.060054Z",
     "iopub.status.busy": "2024-10-15T21:35:39.058692Z",
     "iopub.status.idle": "2024-10-15T21:35:39.068177Z",
     "shell.execute_reply": "2024-10-15T21:35:39.066943Z",
     "shell.execute_reply.started": "2024-10-15T21:35:39.059993Z"
    }
   },
   "outputs": [],
   "source": [
    "# qualitative look at base model performance\n",
    "for idx, target_answer in enumerate(test_answers):\n",
    "    print(\"TARGET_RESPONSE:\",target_answer)\n",
    "    print(\"PREDICT_RESPONSE:\",base_predict_answers[idx],\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T21:35:39.071148Z",
     "iopub.status.busy": "2024-10-15T21:35:39.070074Z",
     "iopub.status.idle": "2024-10-15T23:51:43.603255Z",
     "shell.execute_reply": "2024-10-15T23:51:43.600274Z",
     "shell.execute_reply.started": "2024-10-15T21:35:39.071102Z"
    }
   },
   "outputs": [],
   "source": [
    "#train model\n",
    "hist = gemma_causal_lm.fit(train_queries, epochs=2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T23:51:43.623527Z",
     "iopub.status.busy": "2024-10-15T23:51:43.622956Z",
     "iopub.status.idle": "2024-10-15T23:54:45.872535Z",
     "shell.execute_reply": "2024-10-15T23:54:45.871199Z",
     "shell.execute_reply.started": "2024-10-15T23:51:43.623462Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"../tmp\"):\n",
    "    os.mkdir(\"../tmp\")\n",
    "gemma_causal_lm.save('../tmp/gemma2_multilingual_translation_task_v1',zipped=False)\n",
    "\n",
    "MODEL_SLUG = \"gemma2\"\n",
    "VARIATION_SLUG = 'multilingual_translation'\n",
    "kagglehub.model_upload(\n",
    "  handle = f\"jordanyoung993/{MODEL_SLUG}/keras/{VARIATION_SLUG}\",\n",
    "  local_model_dir = \"../tmp/gemma2_multilingual_translation_task_v1\",\n",
    "  version_notes = 'Update 2024-10-15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T23:54:45.874906Z",
     "iopub.status.busy": "2024-10-15T23:54:45.874403Z",
     "iopub.status.idle": "2024-10-15T23:54:46.311901Z",
     "shell.execute_reply": "2024-10-15T23:54:46.310719Z",
     "shell.execute_reply.started": "2024-10-15T23:54:45.874851Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list(range(len(hist.history['loss']))),hist.history['loss'])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T23:54:46.313998Z",
     "iopub.status.busy": "2024-10-15T23:54:46.31361Z",
     "iopub.status.idle": "2024-10-15T23:54:46.615132Z",
     "shell.execute_reply": "2024-10-15T23:54:46.613987Z",
     "shell.execute_reply.started": "2024-10-15T23:54:46.313952Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(hist.history['loss']))),hist.history['sparse_categorical_accuracy'])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Sparse Categorical Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T23:54:46.617995Z",
     "iopub.status.busy": "2024-10-15T23:54:46.617465Z",
     "iopub.status.idle": "2024-10-16T00:01:24.427445Z",
     "shell.execute_reply": "2024-10-16T00:01:24.424389Z",
     "shell.execute_reply.started": "2024-10-15T23:54:46.617938Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "responses = gemma_causal_lm.generate(\n",
    "            test_queries,\n",
    "            max_length=100)\n",
    "\n",
    "finetuned_predict_answers = []\n",
    "for response in responses:\n",
    "    answer = response.split(\"Response:\")[-1].replace(\"\\n\",\"\")\n",
    "    finetuned_predict_answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting evaluation metrics for finetuned model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T00:01:24.432724Z",
     "iopub.status.busy": "2024-10-16T00:01:24.431884Z",
     "iopub.status.idle": "2024-10-16T00:01:24.466904Z",
     "shell.execute_reply": "2024-10-16T00:01:24.465119Z",
     "shell.execute_reply.started": "2024-10-16T00:01:24.432649Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.translate import nist_score, bleu_score\n",
    "\n",
    "finetuned_evaluation_data = []\n",
    "\n",
    "# evaulate trained model on translation task.\n",
    "for idx, target_answer in enumerate(test_answers):\n",
    "    set_a = set(finetuned_predict_answers[idx].split())\n",
    "    set_b = set(target_answer.split())\n",
    "    try:\n",
    "        x = nist_score.sentence_nist([finetuned_predict_answers[idx].split()],target_answer.split())\n",
    "        y = bleu_score.sentence_bleu([finetuned_predict_answers[idx].split()],target_answer.split(),smoothing_function=chencherry.method1)\n",
    "        z = jaccard_similarity(set_a, set_b)\n",
    "        print(\"Jaccard Similarity\",z, \"NIST\",x, \"BLEU\",y)\n",
    "        finetuned_evaluation_data.append({\"query\":test_queries[idx],\"bleu\":y,\"nist\":x,\"jacc\":z})\n",
    "    except:\n",
    "        z = jaccard_similarity(set_a, set_b)\n",
    "        print(\"Jaccard Similarity\",z)\n",
    "        finetuned_evaluation_data.append({\"query\":test_queries[idx],\"bleu\":0,\"nist\":0,\"jacc\":z})\n",
    "\n",
    "# print(finetuned_evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T00:01:24.470362Z",
     "iopub.status.busy": "2024-10-16T00:01:24.469726Z",
     "iopub.status.idle": "2024-10-16T00:01:24.485511Z",
     "shell.execute_reply": "2024-10-16T00:01:24.484044Z",
     "shell.execute_reply.started": "2024-10-16T00:01:24.470296Z"
    }
   },
   "outputs": [],
   "source": [
    "# qualitative analysis of trained model performance\n",
    "for idx, target_answer in enumerate(test_answers):\n",
    "    print(\"TARGET_RESPONSE:\",target_answer)\n",
    "    print(\"PREDICT_RESPONSE:\",finetuned_predict_answers[idx],\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T00:01:24.488575Z",
     "iopub.status.busy": "2024-10-16T00:01:24.487974Z",
     "iopub.status.idle": "2024-10-16T00:01:24.513321Z",
     "shell.execute_reply": "2024-10-16T00:01:24.511794Z",
     "shell.execute_reply.started": "2024-10-16T00:01:24.488509Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "languages = []\n",
    "for query in base_evaluation_data:\n",
    "    query = query['query']\n",
    "    language = query.split(\"\\n\")[1]\n",
    "    language = language.replace(\"From\",\"\").replace(\" to \",\"-\")\n",
    "    languages.append(language.replace(\"English-\",\"\"))\n",
    "    \n",
    "    \n",
    "\n",
    "jaccard_scores = {\n",
    "    \"base\":[],\n",
    "    \"fine\":[]\n",
    "}\n",
    "\n",
    "bleu_scores = {\n",
    "    \"base\":[],\n",
    "    \"fine\":[]\n",
    "}\n",
    "\n",
    "nist_scores = {\n",
    "    \"base\":[],\n",
    "    \"fine\":[]\n",
    "}\n",
    "\n",
    "    \n",
    "for idx, query in enumerate(base_evaluation_data):\n",
    "    base_jacc = query['jacc']\n",
    "    base_bleu = query['bleu']\n",
    "    base_nist = query['nist']\n",
    "    \n",
    "    fine_jacc = finetuned_evaluation_data[idx]['jacc']\n",
    "    fine_bleu = finetuned_evaluation_data[idx]['bleu']\n",
    "    fine_nist = finetuned_evaluation_data[idx]['nist']\n",
    "    \n",
    "    jaccard_scores['base'].append(round(base_jacc,2))\n",
    "    bleu_scores['base'].append(round(base_bleu,2))\n",
    "    nist_scores['base'].append(round(base_nist,2))\n",
    "\n",
    "    jaccard_scores['fine'].append(round(fine_jacc,2))\n",
    "    bleu_scores['fine'].append(round(fine_bleu,2))\n",
    "    nist_scores['fine'].append(round(fine_nist,2))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T00:01:24.517357Z",
     "iopub.status.busy": "2024-10-16T00:01:24.516343Z",
     "iopub.status.idle": "2024-10-16T00:01:25.159248Z",
     "shell.execute_reply": "2024-10-16T00:01:25.157821Z",
     "shell.execute_reply.started": "2024-10-16T00:01:24.517281Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_barchart(x_labels: list, data: dict, metric: str, y_lim: float = 1):\n",
    "\n",
    "    x = np.arange(len(x_labels))  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "    for attribute, measurement in data.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, padding=3)\n",
    "        multiplier += 1\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel(f\"{metric}\")\n",
    "    ax.set_title(f\"{metric} By Translation\")\n",
    "    ax.set_xticks(x + width, x_labels)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    ax.set_ylim(0, y_lim)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_barchart(languages, jaccard_scores, \"Jaccard Similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T00:01:25.162072Z",
     "iopub.status.busy": "2024-10-16T00:01:25.161593Z",
     "iopub.status.idle": "2024-10-16T00:01:25.746827Z",
     "shell.execute_reply": "2024-10-16T00:01:25.745142Z",
     "shell.execute_reply.started": "2024-10-16T00:01:25.16202Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_barchart(languages, bleu_scores, \"BLEU\",y_lim=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T00:01:25.749894Z",
     "iopub.status.busy": "2024-10-16T00:01:25.749285Z",
     "iopub.status.idle": "2024-10-16T00:01:26.358424Z",
     "shell.execute_reply": "2024-10-16T00:01:26.356954Z",
     "shell.execute_reply.started": "2024-10-16T00:01:25.749822Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_barchart(languages, nist_scores, \"NIST\", y_lim=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T00:01:26.360809Z",
     "iopub.status.busy": "2024-10-16T00:01:26.360384Z",
     "iopub.status.idle": "2024-10-16T00:01:26.369896Z",
     "shell.execute_reply": "2024-10-16T00:01:26.36754Z",
     "shell.execute_reply.started": "2024-10-16T00:01:26.360767Z"
    }
   },
   "outputs": [],
   "source": [
    "print(nist_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Based on data compiled during the evaluation of each model, it seems that finetuning gemma2 on a translation task  improves the model's ability to translate english for some languages. Large improvements are observed in Italian, Polish, and Persian. Middling improvements were seen in Swahili. Little change and perhaps some regression was seen for Czech. The data compiled above is displayed below. Qualitatively, the model seems to have improved at all languages; The base model had trouble generating responses in most of the target languages and was only able to return a poor translation for the Italian language. The translations of the finetuned while not amazing, were at least in the target languages and contained some of the correct words, which suggests the model is in fact learning something about the languages.\n",
    "\n",
    "# Jaccard Similarity\n",
    "\n",
    "| Model | English-Italian | English-Swahili  | English-Thai| English-Gujarati| English-Czech| English-Polish| English-Persian|\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "|Base|0.07|0.0|0.0|0.0|0.04|0.0|0.0|\n",
    "|Finetuned|0.46|0.42|0.0|0.27|0.04|0.31|0.45|\n",
    "\n",
    "\n",
    "# BLEU\n",
    "\n",
    "| Model | English-Italian | English-Swahili  | English-Thai| English-Gujarati| English-Czech| English-Polish| English-Persian|\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "|Base|0.02|0.0|0.0|0.0|0.01|0.0|0.0|\n",
    "|Finetuned|0.26|0.03|0.0|0.03|0.01|0.11|0.06|\n",
    "\n",
    "\n",
    "# NIST\n",
    "\n",
    "| Model | English-Italian | English-Swahili  | English-Thai| English-Gujarati| English-Czech| English-Polish| English-Persian|\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "|Base|0.19|0.0|0.0|0.0|0.16|0.0|0.0|\n",
    "|Finetuned|1.86|0.22|0.0|0.19|0.14|1.11|1.65|\n",
    "\n",
    "\n",
    "It should be noted that the data displayed here has several limitations (1) only a small subset of the full text bible dataset was used for training (~300 samples) (2) only a small subset of the dataset was used for testing; each category only has one sample so the current results are hardly statistically relevant. (3) Due to the rules of the language it is difficult to measure the efficacy of the finetuned model on the Thai language.\n",
    "\n",
    "In anycase the data show some minor improvements to the model's ability to translate post finetune; given a larger training set these improvements would likely be much more pronounced. I also used a small (4) LoRA value when compiling the model. Increasing the number of parameters available would also increase translation performance. Stay tuned for updates to this notebook.\n",
    "\n",
    "--Jordan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 5853544,
     "sourceId": 9596003,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72244,
     "sourceId": 85984,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
