{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIwB7gI1FCRR63f9IB6oCk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorvapu/data_science/blob/main/drug_activity_prediction_belka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRZbYurSJtI1",
        "outputId": "36219fbe-1a44-4969-ccea-ac089ac65b2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"HugeParquetProcessor\").getOrCreate()"
      ],
      "metadata": {
        "id": "qmMaM-zwJxXg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define filename\n",
        "dataset_url = \"https://huggingface.co/datasets/HoangHa/belka-smiles-train-raw/resolve/main/data/train.parquet\"\n",
        "filename = \"train.parquet\"\n",
        "!wget -O $filename $dataset_url\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNdrjJxfKRnR",
        "outputId": "d7188d9b-c8fb-4c9a-91ff-d0cc0fe0e631"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-17 23:28:42--  https://huggingface.co/datasets/HoangHa/belka-smiles-train-raw/resolve/main/data/train.parquet\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.34, 13.35.202.40, 13.35.202.97, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/4f/88/4f882ffde40c5b68f15d4d499c1455831a17d74d14834e270757fbff6f6e08f5/3330782a1855d4d18467fc84e4f2248992d5362fced0f1a2e483d545c642355d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27train.parquet%3B+filename%3D%22train.parquet%22%3B&Expires=1742257722&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjI1NzcyMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzg4LzRmODgyZmZkZTQwYzViNjhmMTVkNGQ0OTljMTQ1NTgzMWExN2Q3NGQxNDgzNGUyNzA3NTdmYmZmNmY2ZTA4ZjUvMzMzMDc4MmExODU1ZDRkMTg0NjdmYzg0ZTRmMjI0ODk5MmQ1MzYyZmNlZDBmMWEyZTQ4M2Q1NDVjNjQyMzU1ZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=fPVlBfUURJVQ8v3yIhQlY9YtheCHEUxg5MYRaiZvQhgnxfs54RearpK4DiSfCkHWzk4dgXsfXQ4nwvEQvQHUzJNjajJvnNLdETAejtnnPf-CbulRXiTDgncdtqDTSbc2fgDpcdZIsE70ZZ5lf4dyesPJUFXGdNzZ4nkLSaelDwcEDzWBvNm3VkldV3F57QWPdCtntBOFFnk0C9FGm53S2EyHM0jU7Cu7ZohCMg6F33OxRC9Ojsi8pEUpPrHKdR0faH5NU86spHCp75gfda990cFOhCx%7EuMRhYt3gsT9OtYu-SHFny0MQJbjrZ7cnDh0PAT%7EATuTunZ7VbWaVI4u5Tw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-03-17 23:28:42--  https://cdn-lfs-us-1.hf.co/repos/4f/88/4f882ffde40c5b68f15d4d499c1455831a17d74d14834e270757fbff6f6e08f5/3330782a1855d4d18467fc84e4f2248992d5362fced0f1a2e483d545c642355d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27train.parquet%3B+filename%3D%22train.parquet%22%3B&Expires=1742257722&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjI1NzcyMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzg4LzRmODgyZmZkZTQwYzViNjhmMTVkNGQ0OTljMTQ1NTgzMWExN2Q3NGQxNDgzNGUyNzA3NTdmYmZmNmY2ZTA4ZjUvMzMzMDc4MmExODU1ZDRkMTg0NjdmYzg0ZTRmMjI0ODk5MmQ1MzYyZmNlZDBmMWEyZTQ4M2Q1NDVjNjQyMzU1ZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=fPVlBfUURJVQ8v3yIhQlY9YtheCHEUxg5MYRaiZvQhgnxfs54RearpK4DiSfCkHWzk4dgXsfXQ4nwvEQvQHUzJNjajJvnNLdETAejtnnPf-CbulRXiTDgncdtqDTSbc2fgDpcdZIsE70ZZ5lf4dyesPJUFXGdNzZ4nkLSaelDwcEDzWBvNm3VkldV3F57QWPdCtntBOFFnk0C9FGm53S2EyHM0jU7Cu7ZohCMg6F33OxRC9Ojsi8pEUpPrHKdR0faH5NU86spHCp75gfda990cFOhCx%7EuMRhYt3gsT9OtYu-SHFny0MQJbjrZ7cnDh0PAT%7EATuTunZ7VbWaVI4u5Tw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.170.229.84, 3.170.229.54, 3.170.229.100, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.170.229.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3757779095 (3.5G) [binary/octet-stream]\n",
            "Saving to: ‘train.parquet’\n",
            "\n",
            "train.parquet       100%[===================>]   3.50G  21.6MB/s    in 2m 45s  \n",
            "\n",
            "2025-03-17 23:31:28 (21.7 MB/s) - ‘train.parquet’ saved [3757779095/3757779095]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet(\"train.parquet\")\n",
        "# Check schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "6jl4_zxtJ0dl",
        "outputId": "07c721a7-285c-473f-955f-ea27156f6a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- buildingblock1_smiles: string (nullable = true)\n",
            " |-- buildingblock2_smiles: string (nullable = true)\n",
            " |-- buildingblock3_smiles: string (nullable = true)\n",
            " |-- molecule_smiles: string (nullable = true)\n",
            " |-- protein_name: string (nullable = true)\n",
            " |-- binds: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('id','buildingblock1_smiles',\t'buildingblock2_smiles',\t'buildingblock3_smiles')\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "0i1UdOHXPt4s",
        "outputId": "2e03a8ae-59b2-4986-b6b8-42367d2799fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "id": "9tqdrXylPBsS",
        "outputId": "47916e6c-e402-4d48-9d6b-200bfc71f18f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import ArrayType, FloatType"
      ],
      "metadata": {
        "id": "k2KPrEwSLmCy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert SMILES to DenseVector\n",
        "def smiles_to_dense_fp(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=512)\n",
        "        return Vectors.dense([float(x) for x in fp])  # Convert to DenseVector\n",
        "    return Vectors.dense([0.0] * 512)  # Return zero vector for invalid SMILES\n",
        "\n",
        "# Register the UDF with VectorUDT to handle DenseVector serialization\n",
        "fp_udf = udf(smiles_to_dense_fp, VectorUDT())\n",
        "\n",
        "# Apply function to create fingerprint column\n",
        "df = df.withColumn(\"Fingerprint\", fp_udf(col(\"molecule_smiles\")))\n"
      ],
      "metadata": {
        "id": "dy-_EVBWExba"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "# Convert Protein names to numerical indices\n",
        "indexer = StringIndexer(inputCol=\"protein_name\", outputCol=\"Protein_Index\")\n",
        "df = indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "TwOOqXqYPSw8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "id": "iO8-OmHCSkIh",
        "outputId": "a2abc649-2787-4e9b-913f-2b3a749da3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+-----+--------------------+-------------+\n",
            "|     molecule_smiles|protein_name|binds|         Fingerprint|Protein_Index|\n",
            "+--------------------+------------+-----+--------------------+-------------+\n",
            "|C#CCOc1ccc(CNc2nc...|        BRD4|    0|[0.0,1.0,0.0,0.0,...|          0.0|\n",
            "|C#CCOc1ccc(CNc2nc...|         HSA|    0|[0.0,1.0,0.0,0.0,...|          1.0|\n",
            "|C#CCOc1ccc(CNc2nc...|         sEH|    0|[0.0,1.0,0.0,0.0,...|          2.0|\n",
            "|C#CCOc1ccc(CNc2nc...|        BRD4|    0|[0.0,1.0,0.0,0.0,...|          0.0|\n",
            "|C#CCOc1ccc(CNc2nc...|         HSA|    0|[0.0,1.0,0.0,0.0,...|          1.0|\n",
            "+--------------------+------------+-----+--------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"Fingerprint\", \"Protein_Index\"], outputCol=\"features\")\n",
        "df = assembler.transform(df).select(\"features\", col(\"binds\").alias(\"label\"))\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "W8inePOSPkHE",
        "outputId": "514b03e8-29be-4337-d9b8-8ed094870cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "id": "pLjzOX2RU1S9",
        "outputId": "067a33e0-f0f0-4b0c-bdf6-1b1454dc429b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(513,[1,4,15,16,1...|    0|\n",
            "|(513,[1,4,15,16,1...|    0|\n",
            "|(513,[1,4,15,16,1...|    0|\n",
            "|(513,[1,15,27,38,...|    0|\n",
            "|(513,[1,15,27,38,...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Split into training (80%) and test (20%) sets\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "1WUdiP78PmhH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest Classifier\n",
        "rf = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=1)\n",
        "model = rf.fit(train_df)"
      ],
      "metadata": {
        "id": "Cq0eGfBUYgH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "predictions = model.transform(test_df)\n",
        "predictions.select(\"label\", \"prediction\", \"probability\").show(5)\n"
      ],
      "metadata": {
        "id": "IVEItItET8ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"Test AUC: {auc:.3f}\")\n"
      ],
      "metadata": {
        "id": "V5zrf6ulPo2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdcIqWQvYpjt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}